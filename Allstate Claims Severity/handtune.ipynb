{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat))\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: np.nan if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RANDOM_STATE = 2016\\nparams = {\\n    'min_child_weight': 1,\\n    'eta': 0.01,\\n    'colsample_bytree': 0.5,\\n    'max_depth': 12,\\n    'subsample': 0.8,\\n    'alpha': 1,\\n    'gamma': 1,\\n    'silent': 1,\\n    'verbose_eval': True,\\n    'seed': RANDOM_STATE,\\n    'nthread':10\\n}\\n\\nxgtrain = xgb.DMatrix(X, label=y)\\nxgtest = xgb.DMatrix(X_test)\\n\\nmodel = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1148.9639894 {'reg_alpha': 0.13614510960026047, 'colsample_bytree': 0.48613283826428166, 'scale_pos_weight': 1, 'learning_rate': 0.018415349849039475, 'nthread': 10, 'min_child_weight': 3, 'subsample': 0.8045758877474857, 'max_depth': 16, 'gamma': 3.738381824865164}\n",
    "'''RANDOM_STATE = 2016\n",
    "params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_params={'colsample_bytree': 0.6, 'learning_rate': 0.1, \n",
    "            'nthread': 10, 'min_child_weight': 6, 'n_estimators': 500, \n",
    "            'subsample': 0.9, 'objective': 'reg:linear', \n",
    "             'max_depth': 9, 'gamma': 0.4,'reg_alpha': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bst_cv1 = xgb.cv(xgb_params, xgtrain, num_boost_round=2000, nfold=5, seed=0, stratified=True,\n",
    "                    feval=evalerror, maximize=False, early_stopping_rounds=None)\n",
    "\n",
    "print 'CV score:', bst_cv1.iloc[-1,:]['test-mae-mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.set_title('100 rounds of training')\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "ax1.plot(bst_cv1[['train-mae-mean', 'test-mae-mean']])\n",
    "ax1.legend(['Training Loss', 'Test Loss'])\n",
    "\n",
    "ax2.set_title('60 last rounds of training')\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.grid(True)\n",
    "ax2.plot(bst_cv1.iloc[40:][['train-mae-mean', 'test-mae-mean']])\n",
    "ax2.legend(['Training Loss', 'Test Loss'])\n",
    "fig.set_size_inches(16,4)\n",
    "#fig.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "Xt = np.zeros((1000,100))\n",
    "t = np.ones((1000,100))\n",
    "yt=np.concatenate((np.zeros(500),np.ones(500)))\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "for train_index, test_index in skf.split(Xt, yt):\n",
    "    t[test_index] = 0\n",
    "np.where(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To follow conventional function names in sklearn, we implement fit and predict functions\n",
    "class XGBoostRegressor(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.params = kwargs\n",
    "        self.num_boost_round = self.params.get('num_boost_round',120)\n",
    "        self.early_stopping_rounds = self.params.get('early_stopping_rounds',10)\n",
    "        self.params.update({'silent': 1, 'objective': 'reg:linear', 'seed': 0})\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        dtrain = xgb.DMatrix(x_train, y_train)\n",
    "        self.bst = xgb.train(params=self.params, dtrain=dtrain, \n",
    "                             num_boost_round=self.num_boost_round,\n",
    "                             feval=evalerror, maximize=False,early_stopping_rounds=None)\n",
    "        return self.bst\n",
    "        \n",
    "    def predict(self, x_pred):\n",
    "        dpred = xgb.DMatrix(x_pred)\n",
    "        return self.bst.predict(dpred)\n",
    "    \n",
    "    def kfold(self, x_train, y_train, nfold=5):\n",
    "        dtrain = xgb.DMatrix(x_train, y_train)\n",
    "        cv_rounds = xgb.cv(params=self.params, dtrain=dtrain, num_boost_round=self.num_boost_round,\n",
    "                           nfold=nfold, feval=evalerror, maximize=False, early_stopping_rounds=10)\n",
    "        return cv_rounds.iloc[-1,:]\n",
    "    \n",
    "    def plot_feature_importances(self):\n",
    "        feat_imp = pd.Series(self.bst.get_fscore()).sort_values(ascending=False)\n",
    "        feat_imp.plot(title='Feature Importances')\n",
    "        plt.ylabel('Feature Importance Score')\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return self.params\n",
    " \n",
    "    def set_params(self, **params):\n",
    "        self.params.update(params)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1157.47329818\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.5, 'objective': 'reg:linear', 'num_boost_round': 50, 'max_depth': 9, 'gamma': 0}\n",
      "CPU times: user 12min, sys: 6.41 s, total: 12min 7s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.5],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[50]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1156.26686109\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.5, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 43min 4s, sys: 23.3 s, total: 43min 27s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[ 0.1 * i for i in range(0,5)],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.5],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 9h 6min 51s, sys: 4min 47s, total: 9h 11min 39s\n",
      "Wall time: 57min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[i/10.0 for i in range(1,10)],\n",
    "     'colsample_bytree':[i/10.0 for i in range(1,10)],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 500, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 11min 42s, sys: 37 s, total: 1h 12min 19s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.5,0.4,0.3,0.2,0.1,0.075,0.05,0.04,0.03],\n",
    "    'n_estimators':[500],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1149.84640685\n",
      "{'reg_alpha': 0.0001, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 5min 45s, sys: 34.6 s, total: 1h 6min 19s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_alpha':[1e-5,1e-4,1e-3, 1e-2, 0.1, 1,10,100],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

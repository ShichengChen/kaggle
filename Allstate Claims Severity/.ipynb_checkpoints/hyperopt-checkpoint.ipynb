{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'Vladimir Iglovikov'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114.model                                                my_model.hyperopt\r\n",
      "Santhosh SharmaExploratory study on ML algorithms?.ipynb  params.txt\r\n",
      "Vladimir Iglovikovxgb 1114?.py                            sub_v.csv\r\n",
      "\u001b[0m\u001b[01;34mallstate_capstone-master\u001b[0m/                                 submission.csv\r\n",
      "handtune.ipynb                                            test.csv\r\n",
      "hyperopt.ipynb                                            train.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socre:1156.8227052, params:{'reg_alpha': 0.26995003848906524, 'colsample_bytree': 0.2266549861816051, 'scale_pos_weight': 1, 'learning_rate': 0.05344032085694122, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.48379887781040276, 'seed': 20, 'max_depth': 16, 'gamma': 0.402588613598941}socre:1149.3825198, params:{'reg_alpha': 0.9999978085959014, 'colsample_bytree': 0.2502484001654734, 'scale_pos_weight': 1, 'learning_rate': 0.03509717328153762, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.6409135720554807, 'seed': 20, 'max_depth': 16, 'gamma': 0.1306661498079924}"
     ]
    }
   ],
   "source": [
    "%cat params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: np.nan if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time0= time.time()\n",
    "cv = StratifiedKFold(n_splits=5,random_state=42)\n",
    "space4xgb = {\n",
    "    'max_depth': hp.choice('max_depth', range(3,20)),\n",
    "    'learning_rate': hp.loguniform('learning_rate', -2.5*np.log(10), -1*np.log(10)),\n",
    "    'min_child_weight':hp.choice('min_child_weight',range(1,7)),\n",
    "    'scale_pos_weight': hp.choice('scale_pos_weight', [1]), \n",
    "    'reg_alpha': hp.uniform('reg_alpha',0.1,1),\n",
    "    'gamma': hp.uniform('gamma',0,0.5),\n",
    "    \n",
    "    'subsample': hp.uniform('subsample',0.1,0.9),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree',0.1,1),\n",
    "    \n",
    "    'nthread': hp.choice('nthread', [10])\n",
    "}\n",
    "minacc=1160\n",
    "#{'reg_alpha': 0.8673861702351379, 'colsample_bytree': 0.8759854865376723, 'scale_pos_weight': 1, 'learning_rate': 0.06925571303753118, 'nthread': 20, 'min_child_weight': 1, 'subsample': 0.629375884543008, 'max_depth': 7, 'gamma': 0.19254932932610697}\n",
    "def optf(params): \n",
    "    params['nthread']=10\n",
    "    params['seed']=20\n",
    "    #clf = xgb.XGBRegressor(**params)\n",
    "    #acc = cross_val_score(clf, X, y,cv=cv,n_jobs=1,scoring=evalerror).mean()\n",
    "    bst = xgb.cv(params, xgtrain, num_boost_round=500, nfold=5, seed=7, \n",
    "                    feval=evalerror,early_stopping_rounds=10)\n",
    "    acc = bst.iloc[-1,:]['test-mae-mean']\n",
    "    print time.time()-time0\n",
    "    print acc\n",
    "    global minacc\n",
    "    if acc < minacc:\n",
    "        minacc = acc\n",
    "        print 'new best:', minacc, params\n",
    "        \n",
    "        with open(\"params.txt\", \"a\") as text_file:\n",
    "            text_file.write('socre:{}, params:{}\\n'.format(minacc,params))\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning from 353 trials to 354 (+1) trials\n",
      "205.044909954\n",
      "2091.0032714\n",
      "Rerunning from 354 trials to 355 (+1) trials\n",
      "357.92079401\n",
      "2469.3193358\n",
      "Rerunning from 355 trials to 356 (+1) trials\n",
      "488.391077042\n",
      "1677.0664306\n",
      "Rerunning from 356 trials to 357 (+1) trials\n",
      "715.206483126\n",
      "1790.186914\n",
      "Rerunning from 357 trials to 358 (+1) trials\n",
      "832.859982967\n",
      "1161.454956\n",
      "Rerunning from 358 trials to 359 (+1) trials\n",
      "1010.66010094\n",
      "2241.1940432\n",
      "Rerunning from 359 trials to 360 (+1) trials\n",
      "1144.06762505\n",
      "2581.3344236\n",
      "Rerunning from 360 trials to 361 (+1) trials\n",
      "1330.87800407\n",
      "1161.4091552\n",
      "Rerunning from 361 trials to 362 (+1) trials\n",
      "1460.34931517\n",
      "1156.8227052\n",
      "new best: 1156.8227052 {'reg_alpha': 0.26995003848906524, 'colsample_bytree': 0.2266549861816051, 'scale_pos_weight': 1, 'learning_rate': 0.05344032085694122, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.48379887781040276, 'seed': 20, 'max_depth': 16, 'gamma': 0.402588613598941}\n",
      "Rerunning from 362 trials to 363 (+1) trials\n",
      "1735.93543005\n",
      "1924.710962\n",
      "Rerunning from 363 trials to 364 (+1) trials\n",
      "1987.98688006\n",
      "1237.963623\n",
      "Rerunning from 364 trials to 365 (+1) trials\n",
      "2127.88710093\n",
      "1207.7811768\n",
      "Rerunning from 365 trials to 366 (+1) trials\n",
      "2256.13246298\n",
      "1494.3129392\n",
      "Rerunning from 366 trials to 367 (+1) trials\n",
      "2330.50193906\n",
      "1158.3987792\n",
      "Rerunning from 367 trials to 368 (+1) trials\n",
      "2451.61317515\n",
      "2663.347998\n",
      "Rerunning from 368 trials to 369 (+1) trials\n",
      "2725.24330997\n",
      "2345.4625978\n",
      "Rerunning from 369 trials to 370 (+1) trials\n",
      "2854.74804401\n",
      "2143.1172364\n",
      "Rerunning from 370 trials to 371 (+1) trials\n",
      "3212.57765913\n",
      "1554.765039\n",
      "Rerunning from 371 trials to 372 (+1) trials\n",
      "3419.38958001\n",
      "1354.8396242\n",
      "Rerunning from 372 trials to 373 (+1) trials\n",
      "3558.01684403\n",
      "2519.7672852\n",
      "Rerunning from 373 trials to 374 (+1) trials\n",
      "3693.69839597\n",
      "1904.5840086\n",
      "Rerunning from 374 trials to 375 (+1) trials\n",
      "3919.23747802\n",
      "1149.3825198\n",
      "new best: 1149.3825198 {'reg_alpha': 0.9999978085959014, 'colsample_bytree': 0.2502484001654734, 'scale_pos_weight': 1, 'learning_rate': 0.03509717328153762, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.6409135720554807, 'seed': 20, 'max_depth': 16, 'gamma': 0.1306661498079924}\n",
      "Rerunning from 375 trials to 376 (+1) trials\n",
      "4073.19771194\n",
      "2443.4808594\n",
      "Rerunning from 376 trials to 377 (+1) trials\n",
      "4199.47586799\n",
      "2661.8023924\n",
      "Rerunning from 377 trials to 378 (+1) trials\n"
     ]
    }
   ],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"/home/phe002/shicheng/kaggle/Allstate Claims Severity/my_model.hyperopt\", \"rb\"))\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn=optf, space=space4xgb, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "    # save the trials object\n",
    "    with open(\"my_model.hyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "\n",
    "# loop indefinitely and stop whenever you like\n",
    "while True:\n",
    "    run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1148.9639894 {'reg_alpha': 0.13614510960026047, 'colsample_bytree': 0.48613283826428166, 'scale_pos_weight': 1, 'learning_rate': 0.018415349849039475, 'nthread': 10, 'min_child_weight': 3, 'subsample': 0.8045758877474857, 'max_depth': 16, 'gamma': 3.738381824865164}\n",
    "'''RANDOM_STATE = 2016\n",
    "params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_model('1114.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

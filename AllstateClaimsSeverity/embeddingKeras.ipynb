{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from keras.layers import Dense, Activation, concatenate, Reshape,Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import selu\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ntrain = len(train)\n",
    "ids = test['id']\n",
    "test['loss'] = np.nan\n",
    "dataset = pd.DataFrame()\n",
    "joined = pd.concat([train, test])\n",
    "f_num = [f for f in train.columns if 'cont' in f]\n",
    "f_cat = [f for f in train.columns if 'cat' in f]\n",
    "for column in f_cat:\n",
    "    if (train[column].nunique() != test[column].nunique()\n",
    "        or (train[column].unique() != test[column].unique()).any()):\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        \n",
    "        remove = ((set_train - set_test)|(set_test - set_train))\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "        myfilter = lambda x: np.nan if x in remove else x\n",
    "        joined[column] = joined[column].apply(filter_cat, 1)\n",
    "\n",
    "    dataset[column] = pd.factorize(joined[column].values, sort=True)[0] + 1\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "#train_y = np.log(train['loss'] + shift)\n",
    "train_y=train['loss']\n",
    "train_x = train.drop(['loss', 'id'], 1)\n",
    "test = test.drop(['loss', 'id'], 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "contx = scaler.fit_transform(train_x[f_num])\n",
    "catx = pd.get_dummies(data=train_x[f_cat],columns=f_cat,dummy_na=False)\n",
    "test = pd.get_dummies(data=test,columns=f_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat116_MU</th>\n",
       "      <th>cat116_MV</th>\n",
       "      <th>cat116_MW</th>\n",
       "      <th>cat116_O</th>\n",
       "      <th>cat116_Q</th>\n",
       "      <th>cat116_R</th>\n",
       "      <th>cat116_S</th>\n",
       "      <th>cat116_T</th>\n",
       "      <th>cat116_U</th>\n",
       "      <th>cat116_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.290813</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268622</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0  0.321594  0.299102  0.246911  0.402922  0.281143  0.466591  0.317681   \n",
       "1  0.634734  0.620805  0.654310  0.946616  0.836443  0.482425  0.443760   \n",
       "2  0.290813  0.737068  0.711159  0.412789  0.718531  0.212308  0.325779   \n",
       "3  0.268622  0.681761  0.592681  0.354893  0.397069  0.369930  0.342355   \n",
       "4  0.553846  0.299102  0.263570  0.696873  0.302678  0.398862  0.391833   \n",
       "\n",
       "     cont8    cont9   cont10    ...     cat116_MU  cat116_MV  cat116_MW  \\\n",
       "0  0.61229  0.34365  0.38016    ...             0          0          0   \n",
       "1  0.71330  0.51890  0.60401    ...             0          0          0   \n",
       "2  0.29758  0.34365  0.30529    ...             0          0          0   \n",
       "3  0.40028  0.33237  0.31480    ...             0          0          0   \n",
       "4  0.23688  0.43731  0.50556    ...             0          0          0   \n",
       "\n",
       "   cat116_O  cat116_Q  cat116_R  cat116_S  cat116_T  cat116_U  cat116_Y  \n",
       "0         0         0         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0         0  \n",
       "2         0         0         0         0         0         0         0  \n",
       "3         0         0         0         0         0         0         0  \n",
       "4         0         0         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 1079 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in catx.columns:\n",
    "    a = catx[i].sum()\n",
    "    b = test[i].sum()\n",
    "    if(a < 100 | b < 100):\n",
    "        del catx[i]\n",
    "        del test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1065) (188318, 14)\n",
      "(188318, 1079)\n",
      "(125546, 1079)\n",
      "(188318,)\n"
     ]
    }
   ],
   "source": [
    "print (catx.shape,contx.shape)\n",
    "test = test.values\n",
    "train_x = np.concatenate((contx,catx.values),axis=1)\n",
    "\n",
    "print (train_x.shape)\n",
    "print (test.shape)\n",
    "print (train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true)-K.exp(y_pred)), axis=-1)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
    "                             verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://cs231n.github.io/neural-networks-3/\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "class ExponentialMovingAverage(Callback):\n",
    "    \"\"\"create a copy of trainable weights which gets updated at every\n",
    "       batch using exponential weight decay. The moving average weights along\n",
    "       with the other states of original model(except original model trainable\n",
    "       weights) will be saved at every epoch if save_mv_ave_model is True.\n",
    "       If both save_mv_ave_model and save_best_only are True, the latest\n",
    "       best moving average model according to the quantity monitored\n",
    "       will not be overwritten. Of course, save_best_only can be True\n",
    "       only if there is a validation set.\n",
    "       This is equivalent to save_best_only mode of ModelCheckpoint\n",
    "       callback with similar code. custom_objects is a dictionary\n",
    "       holding name and Class implementation for custom layers.\n",
    "       At end of every batch, the update is as follows:\n",
    "       mv_weight -= (1 - decay) * (mv_weight - weight)\n",
    "       where weight and mv_weight is the ordinal model weight and the moving\n",
    "       averaged weight respectively. At the end of the training, the moving\n",
    "       averaged weights are transferred to the original model.\n",
    "       \"\"\"\n",
    "    def __init__(self, decay=0.999, filepath='model2/model{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                 save_mv_ave_model=False, verbose=0,\n",
    "                 save_best_only=False, monitor='val_loss', mode='auto',\n",
    "                 save_weights_only=False, custom_objects={}):\n",
    "        self.decay = decay\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_mv_ave_model = save_mv_ave_model\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.save_best_only = save_best_only\n",
    "        self.monitor = monitor\n",
    "        self.custom_objects = custom_objects  # dictionary of custom layers\n",
    "        self.sym_trainable_weights = None  # trainable weights of model\n",
    "        self.mv_trainable_weights_vals = None  # moving averaged values\n",
    "        self.epochs = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor:\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.sym_trainable_weights = self.model.trainable_weights\n",
    "        # Initialize moving averaged weights using original model values\n",
    "        self.mv_trainable_weights_vals = {x.name: K.get_value(x).copy() for x in\n",
    "                                          self.sym_trainable_weights}\n",
    "        if self.verbose:\n",
    "            print('Created a copy of model weights to initialize moving averaged weights.')\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''old = K.get_value(self.model.trainable_weights[0])\n",
    "        name = self.model.trainable_weights[0].name\n",
    "        assert((old != self.mv_trainable_weights_vals[name]).any())'''\n",
    "        \n",
    "        for weight in self.sym_trainable_weights:\n",
    "            K.set_value(weight, self.mv_trainable_weights_vals[weight.name])\n",
    "\n",
    "        '''old = K.get_value(self.model.trainable_weights[0])\n",
    "        name = self.model.trainable_weights[0].name\n",
    "        assert((old == self.mv_trainable_weights_vals[name]).all())'''\n",
    "            \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.epochs + 5 > self.params['epochs']):\n",
    "            for weight in self.sym_trainable_weights:\n",
    "                old_val = self.mv_trainable_weights_vals[weight.name].copy()\n",
    "                self.mv_trainable_weights_vals[weight.name] = \\\n",
    "                    old_val * self.decay + (1.0 - self.decay) * K.get_value(weight).copy()\n",
    "            #assert((old_val == self.mv_trainable_weights_vals[weight.name]).all())\n",
    "            #assert((old_val == K.get_value(weight)).all())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epochs += 1\n",
    "        if(self.epochs + 5 > self.params['epochs']):\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            self.model.save(filepath, overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10   ...    \\\n",
       "0     1     2     1     2     1     1     1     1     2      1   ...     \n",
       "1     1     2     1     1     1     1     1     1     2      2   ...     \n",
       "2     1     2     1     1     2     1     1     1     2      2   ...     \n",
       "3     2     2     1     2     1     1     1     1     2      1   ...     \n",
       "4     1     2     1     2     1     1     1     1     2      2   ...     \n",
       "\n",
       "   cat107  cat108  cat109  cat110  cat111  cat112  cat113  cat114  cat115  \\\n",
       "0      10       7      39      27       3      20      54       1      15   \n",
       "1      11      11      30      59       1      23      37       1      15   \n",
       "2       6       1       3      79       1      29       5       1       9   \n",
       "3      11      11      30      61       3      40       4       1      15   \n",
       "4       7       2      57      45       3      51      37       1      11   \n",
       "\n",
       "   cat116  \n",
       "0     239  \n",
       "1      74  \n",
       "2     135  \n",
       "3      68  \n",
       "4      44  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetX = dataset.iloc[:ntrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 116)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 14)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_list = []\n",
    "\n",
    "X_list.append(contx)\n",
    "for i in f_cat:\n",
    "    X_list.append(datasetX[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Merge\n",
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyper_model(seed = None):\n",
    "    models = []\n",
    "\n",
    "    cur = Sequential()\n",
    "    cur.add(Dense(13, input_dim=14,kernel_initializer='glorot_normal',kernel_regularizer=l2(0.01)))\n",
    "    cur.add(BatchNormalization())\n",
    "    models.append(cur)\n",
    "    input_shape = 7\n",
    "    for i in f_cat:\n",
    "        cur = Sequential()\n",
    "        num = dataset[i].nunique()\n",
    "        cur.add(Embedding(num, num // 2, input_length=1))\n",
    "        input_shape += num // 2\n",
    "        cur.add(Flatten())\n",
    "        models.append(cur)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Merge(models, mode='concat'))\n",
    "    '''model.add(Dense(437, kernel_initializer=he_normal(seed = seed)\n",
    "                    ,kernel_regularizer=l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.536))'''\n",
    "    \n",
    "    model.add(Dense(300, kernel_initializer='glorot_normal',kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(73, kernel_initializer='glorot_normal',kernel_regularizer=l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.233))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='glorot_normal',kernel_regularizer=l2(0.01)))\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #model.compile(optimizer='adadelta',loss = 'mae',metrics = [mae_score])\n",
    "    model.compile(optimizer=adam,loss = 'mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150654 samples, validate on 37664 samples\n",
      "Epoch 1/30\n",
      "150654/150654 [==============================] - 40s 267us/step - loss: 3014.4508 - val_loss: 2951.7708\n",
      "Epoch 2/30\n",
      "150654/150654 [==============================] - 36s 239us/step - loss: 2877.5393 - val_loss: 2771.1379\n",
      "Epoch 3/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 2614.5349 - val_loss: 2472.4463\n",
      "Epoch 4/30\n",
      "150654/150654 [==============================] - 35s 235us/step - loss: 2286.0198 - val_loss: 2072.3309\n",
      "Epoch 5/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 2085.5115 - val_loss: 2069.2152\n",
      "Epoch 6/30\n",
      "150654/150654 [==============================] - 36s 236us/step - loss: 1923.5672 - val_loss: 1971.4767\n",
      "Epoch 7/30\n",
      "150654/150654 [==============================] - 35s 235us/step - loss: 1824.0327 - val_loss: 1869.5227\n",
      "Epoch 8/30\n",
      "150654/150654 [==============================] - 36s 239us/step - loss: 1772.5982 - val_loss: 1739.4178\n",
      "Epoch 9/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1744.7464 - val_loss: 2237.3476\n",
      "Epoch 10/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1747.9015 - val_loss: 1757.1596\n",
      "Epoch 11/30\n",
      "150654/150654 [==============================] - 35s 235us/step - loss: 1718.7625 - val_loss: 1724.8472\n",
      "Epoch 12/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1694.9476 - val_loss: 2273.6349\n",
      "Epoch 13/30\n",
      "150654/150654 [==============================] - 36s 236us/step - loss: 1572.8638 - val_loss: 5300.6481\n",
      "Epoch 14/30\n",
      "150654/150654 [==============================] - 35s 234us/step - loss: 1450.3615 - val_loss: 44482.2951\n",
      "Epoch 15/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1404.7079 - val_loss: 21156.0549\n",
      "Epoch 16/30\n",
      "150654/150654 [==============================] - 36s 238us/step - loss: 1430.0382 - val_loss: 216719.1622\n",
      "Epoch 17/30\n",
      "150654/150654 [==============================] - 37s 245us/step - loss: 1396.5496 - val_loss: 53683.6239\n",
      "Epoch 18/30\n",
      "150654/150654 [==============================] - 37s 247us/step - loss: 1388.2827 - val_loss: 490644.2670\n",
      "Epoch 19/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1569.5279 - val_loss: 1748.6793\n",
      "Epoch 20/30\n",
      "150654/150654 [==============================] - 36s 236us/step - loss: 1543.2307 - val_loss: 2850.3350\n",
      "Epoch 21/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1449.3847 - val_loss: 264051.8042\n",
      "Epoch 22/30\n",
      "150654/150654 [==============================] - 36s 236us/step - loss: 1537.2154 - val_loss: 4859.7269\n",
      "Epoch 23/30\n",
      "150654/150654 [==============================] - 35s 234us/step - loss: 1428.8150 - val_loss: 151470.2284\n",
      "Epoch 24/30\n",
      "150654/150654 [==============================] - 36s 237us/step - loss: 1395.9823 - val_loss: 2099.8827\n",
      "Epoch 25/30\n",
      "150654/150654 [==============================] - 36s 236us/step - loss: 1379.7182 - val_loss: 2054.8094\n",
      "Epoch 26/30\n",
      "150654/150654 [==============================] - 35s 235us/step - loss: 1356.0526 - val_loss: 2116.2889\n",
      "Epoch 27/30\n",
      "150654/150654 [==============================] - 36s 242us/step - loss: 1373.0013 - val_loss: 2052.8060\n",
      "Epoch 28/30\n",
      "150654/150654 [==============================] - 36s 242us/step - loss: 1437.3554 - val_loss: 5415.6521\n",
      "Epoch 29/30\n",
      "150654/150654 [==============================] - 38s 249us/step - loss: 1569.3279 - val_loss: 1779.4294\n",
      "Epoch 30/30\n",
      "150654/150654 [==============================] - 37s 247us/step - loss: 1554.3793 - val_loss: 1663.3009\n"
     ]
    }
   ],
   "source": [
    "f = hyper_model(seed = 0)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "fit = f.fit(X_list, train_y, validation_split=0.2, batch_size=256,\n",
    "              epochs=30, verbose=1)#, callbacks=[ExponentialMovingAverage()])\n",
    "pred =f.predict(X_list, batch_size=1024)\n",
    "#score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "score = mean_absolute_error(train_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnmodel={}\n",
    "nnmodel.clear()\n",
    "def cross_validate_mlp(mlp_func, nfolds=10,nbags=5):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nbags,))\n",
    "    stack_train = np.zeros((nbags,len(train_y)))\n",
    "    stack_test = np.zeros((nbags,len(test)))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        for bag in range(nbags):\n",
    "            nnmodel['nn%d',k*10+bag*1] = mlp_func(seed = k*10+bag*1)\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            fit = nnmodel['nn%d',k*10+bag*1].fit(xtr, ytr, validation_split=0.2, batch_size=128,\n",
    "                          epochs=30, verbose=1, callbacks=[ExponentialMovingAverage()])\n",
    "            pred = nnmodel['nn%d',k*10+bag*1].predict(xte, batch_size=1024)\n",
    "            #score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "            score = mean_absolute_error(yte, pred)\n",
    "            val_scores[bag] += score\n",
    "            #stack_train[bag][test_index] = pred[:,0]\n",
    "            print (\"nfold:{},bag:{}\".format(k,bag),score)\n",
    "    for bag in range(nbags):\n",
    "        val_scores[bag] = val_scores[bag] / float(nfolds)\n",
    "    \n",
    "    \n",
    "    return val_scores\n",
    "\n",
    "cv_score = cross_validate_mlp(hyper_model)\n",
    "print (\"CV score for the final model:\", cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this model is not adapted for mere 30 epochs of training, nor for 3-fold CV (I used 5-fold on Kaggle), even though this is a single unbagged model which has been cross-validated on three folds only, we see a very good score:\n",
    "`CV = 1150` (your score may vary a little).\n",
    "\n",
    "By the way, this single model, bagged, 5-fold CVed, scored 1116.28 on Kaggle LB.\n",
    "\n",
    "As we see, this model is considerably better than any other models we had so far. We now take it as the second part of our final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'l3-nn': {\n",
    "        'predictions': l2_predictions,\n",
    "        'n_bags': 4,\n",
    "        'model': Keras(nn_lr, lambda: {'l1': 1e-5, 'l2': 1e-5, 'n_epoch': 30, 'batch_size': 128, 'optimizer': SGD(3e-2, momentum=0.8, nesterov=True, decay=3e-5), 'callbacks': [ExponentialMovingAverage(save_mv_ave_model=False)]}),\n",
    "    },\n",
    "     'optimizer': SGD(1e-4, momentum=0.9, nesterov=True, decay=5e-5)\n",
    "            'optimizer': SGD(1e-5, momentum=0.9, nesterov=True, decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, \n",
    " 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 73, 'optimizer': 'adadelta',\n",
    " 'wdecay': 0.0020300000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=3):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nfolds,))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        mlp = mlp_func()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        fit = mlp.fit(xtr, ytr, validation_split=0.1, batch_size=128, \n",
    "                      epochs=10, verbose=0, callbacks=[early_stopping])\n",
    "        pred = mlp.predict(xte, batch_size=512)\n",
    "        score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "        val_scores[k] += score\n",
    "        print ('Fold {}, MAE: {}'.format(k, score))\n",
    "    avg_score = np.sum(val_scores) / float(nfolds)\n",
    "    print ('{}-fold CV score: {}'.format(nfolds, avg_score))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 463, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 155, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 20, 'optimizer': 'adam', 'wdecay': 0.0012891891891891893}\n",
      "Fold 0, MAE: 1664.3154518123333\n",
      "Fold 1, MAE: 1789.6478768193072\n",
      "Fold 2, MAE: 2230.6679431902985\n",
      "3-fold CV score: 1894.877090607313\n",
      "Model Testing: {'hidden1_dropout': 0.50526315789473686, 'hidden1_units': 308, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 244, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 28, 'optimizer': 'adadelta', 'wdecay': 0.0075522522522522527}\n",
      "Fold 0, MAE: 2663.589775993532\n",
      "Fold 1, MAE: 2550.3793884253055\n",
      "Fold 2, MAE: 2698.309167392798\n",
      "3-fold CV score: 2637.426110603878\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 394, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 120, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 65, 'optimizer': 'adam', 'wdecay': 0.0076711711711711711}\n",
      "Fold 0, MAE: 1349.8792955749364\n",
      "Fold 1, MAE: 1348.0942437736849\n",
      "Fold 2, MAE: 1365.2535296867036\n",
      "3-fold CV score: 1354.409023011775\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 541, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 258, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 51, 'optimizer': 'adadelta', 'wdecay': 0.0024189189189189188}\n",
      "Fold 0, MAE: 2598.4352573980386\n",
      "Fold 1, MAE: 2447.588075147961\n",
      "Fold 2, MAE: 2721.9736304441863\n",
      "3-fold CV score: 2589.332320996729\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 472, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 217, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 71, 'optimizer': 'adadelta', 'wdecay': 0.0055603603603603608}\n",
      "Fold 0, MAE: 1613.5498840747402\n",
      "Fold 1, MAE: 1411.0097020300386\n",
      "Fold 2, MAE: 1711.7215931226579\n",
      "3-fold CV score: 1578.7603930758123\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 429, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 224, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 36, 'optimizer': 'adam', 'wdecay': 0.0053720720720720726}\n",
      "Fold 0, MAE: 1803.0232709901081\n",
      "Fold 1, MAE: 2716.749151946116\n",
      "Fold 2, MAE: 2137.6247824488005\n",
      "3-fold CV score: 2219.1324017950083\n",
      "Model Testing: {'hidden1_dropout': 0.55789473684210522, 'hidden1_units': 308, 'hidden2_dropout': 0.5, 'hidden2_units': 148, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 69, 'optimizer': 'adam', 'wdecay': 0.0020225225225225223}\n",
      "Fold 0, MAE: 2290.4482287011933\n",
      "Fold 1, MAE: 1908.4728142537497\n",
      "Fold 2, MAE: 1895.8826351188964\n",
      "3-fold CV score: 2031.6012260246132\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 481, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 127, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 28, 'optimizer': 'adam', 'wdecay': 0.0085432432432432422}\n",
      "Fold 0, MAE: 1813.761108549234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-f3e899cfd5b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# UNCOMMENT THE NEXT LINE TO LAUNCH HYPEROPT:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperopt_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-252-f3e899cfd5b2>\u001b[0m in \u001b[0;36mhyperopt_search\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-50776d6fa3b5>\u001b[0m in \u001b[0;36mcross_validate_mlp\u001b[0;34m(mlp_func, nfolds)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         fit = mlp.fit(xtr, ytr, validation_split=0.1, batch_size=128, \n\u001b[0;32m---> 12\u001b[0;31m                       epochs=10, verbose=0, callbacks=[early_stopping])\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# VERSION 4. Insights:\n",
    "# – why not to test 4-layer architectures?\n",
    "# — we need to introduce new optimizers\n",
    "# — adding batch normalization (https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "# Describing the search space\n",
    "space = {'hidden1_dropout': hp.choice('hidden1_dropout', np.linspace(0.4,0.6,20)),\n",
    "        'hidden2_dropout': hp.choice('hidden2_dropout', np.linspace(0.2,0.5,10)),\n",
    "        'hidden3_dropout': hp.choice('hidden3_dropout', np.linspace(0.1,0.5,10)),\n",
    "         'hidden1_units': hp.choice('hidden1_units', np.linspace(300,550,30,dtype='int32')),\n",
    "         'hidden2_units': hp.choice('hidden2_units', np.linspace(100,300,30,dtype='int32')),\n",
    "         'hidden3_units': hp.choice('hidden3_units', np.linspace(20,80,30,dtype='int32')),\n",
    "         'optimizer': hp.choice('optimizer', ['adadelta','adam']),\n",
    "         'wdecay':hp.choice('wdecay', np.linspace(0.0001,0.01,1000)),\n",
    "        }\n",
    "\n",
    "# Implementing a function to minimize\n",
    "def hyperopt_search(params):\n",
    "    print ('Model Testing:', params)\n",
    "    def mlp_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(params['hidden1_units'], input_dim=train_x.shape[1], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden1_dropout']))\n",
    "        \n",
    "        model.add(Dense(params['hidden2_units'], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden2_dropout']))\n",
    "\n",
    "        model.add(Dense(params['hidden3_units'], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay']))) \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden3_dropout']))\n",
    "        \n",
    "        model.add(Dense(1, kernel_initializer='he_normal',kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.compile(loss=mae_score,metrics=[mae_score], optimizer=params['optimizer'])\n",
    "        return model\n",
    "    \n",
    "    cv_score = cross_validate_mlp(mlp_model)\n",
    "    return {'loss': cv_score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# UNCOMMENT THE NEXT LINE TO LAUNCH HYPEROPT:\n",
    "best = fmin(hyperopt_search, space, algo=tpe.suggest, max_evals = 100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: 116\n",
      "Numerical features: 14\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "cat_features = [x for x in train.select_dtypes(\n",
    "        include=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "num_features = [x for x in train.select_dtypes(\n",
    "        exclude=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "print \"Categorical features:\", len(cat_features)\n",
    "print \"Numerical features:\", len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188318 entries, 0 to 188317\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(15), int64(1), object(116)\n",
      "memory usage: 189.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels)),False\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat)),False\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n",
      "[-1  0  1]\n",
      "[0 1 2]\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A':[np.nan,'type1','type2'],\n",
    "                   'B':['type1','type2','type3'],\n",
    "                   'C':['type1','type3','type3']})\n",
    "print pd.factorize(df['A'].values, sort=True)[0]\n",
    "print pd.factorize(df['A'].values)[0]\n",
    "print pd.factorize(df['B'].values, sort=True)[0]\n",
    "print pd.factorize(df['C'].values, sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: 'np.nan' if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "lgtrain = lgb.Dataset(X, label=y,categorical_feature=cat_features,free_raw_data=False)\n",
    "lgtest = lgb.Dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:1002: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "#1148.9639894 {'reg_alpha': 0.13614510960026047, 'colsample_bytree': 0.48613283826428166, 'scale_pos_weight': 1, 'learning_rate': 0.018415349849039475, 'nthread': 10, 'min_child_weight': 3, 'subsample': 0.8045758877474857, 'max_depth': 16, 'gamma': 3.738381824865164}\n",
    "RANDOM_STATE = 0\n",
    "'''params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}'''\n",
    "params={'colsample_bytree': 0.6, 'learning_rate': 0.01, \n",
    "             'min_child_weight': 6, #'n_estimators': 100, \n",
    "            'nthread': 10,\n",
    "            'subsample': 0.9, 'objective': 'regression', \n",
    "             'max_depth': 9, 'min_split_gain': 0.4,'reg_alpha': 0.0001,'seed':0}\n",
    "model = lgb.train(params, lgtrain, 10, feval=evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta_list  = [0.1]*100 + [0.05]*200 + [0.02]*400\n",
    "#model = xgb.train(params, xgtrain, 700, feval=evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params={'colsample_bytree': 0.6, 'learning_rate': 0.01, \n",
    "            'min_child_weight': 6,\n",
    "            'nthread': 5, \n",
    "            'subsample': 0.9, 'objective':'regression',\n",
    "             'max_depth': 9, 'min_split_gain': 0.4,'reg_alpha': 0.0001,'seed':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params={ 'nthread': 10, \n",
    "            'num_leaves':120,'min_data_in_leaf':100,'max_depth':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412.44216116\n",
      "('\\nBest num_boost_round:', 10)\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "cv_result_lgb = lgb.cv(lgb_params, lgtrain, num_boost_round=10, nfold=5, seed=0, stratified=False,\n",
    "                    feval=evalerror, early_stopping_rounds=None)\n",
    "print cv_result_lgb['mae-mean'][-1]\n",
    "print('\\nBest num_boost_round:', len(cv_result_lgb['mae-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192.46133299\n",
      "('\\nBest num_boost_round:', 3000)\n"
     ]
    }
   ],
   "source": [
    "print cv_result_lgb['mae-mean'][-1]\n",
    "print('\\nBest num_boost_round:', len(cv_result_lgb['mae-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.set_title('100 rounds of training')\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "ax1.plot(bst_cv1[['train-mae-mean', 'test-mae-mean']])\n",
    "ax1.legend(['Training Loss', 'Test Loss'])\n",
    "\n",
    "ax2.set_title('60 last rounds of training')\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.grid(True)\n",
    "ax2.plot(bst_cv1.iloc[1750:][['train-mae-mean', 'test-mae-mean']])\n",
    "ax2.legend(['Training Loss', 'Test Loss'])\n",
    "fig.set_size_inches(16,4)\n",
    "#fig.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "Xt = np.zeros((1000,100))\n",
    "t = np.ones((1000,100))\n",
    "yt=np.concatenate((np.zeros(500),np.ones(500)))\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "for train_index, test_index in skf.split(Xt, yt):\n",
    "    t[test_index] = 0\n",
    "np.where(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plottrend(grid=grid,bins=bins):    \n",
    "    test_scores_mean = grid.cv_results_['mean_test_score']\n",
    "    test_scores_std = grid.cv_results_['std_test_score']\n",
    "    plt.grid()\n",
    "    plt.fill_between(bins, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,color=\"r\")\n",
    "    plt.plot(bins, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bins = range(10,230,1)\n",
    "lgb_params = {\n",
    "    'min_data_in_leaf': bins,\n",
    "    'num_leaves':[100],\n",
    "     'max_depth':[9],\n",
    "    'num_threads':[10],\n",
    "}\n",
    "clf=lgb.LGBMRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=lgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plottrend(grid=grid,bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1156.26686109\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.5, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 43min 4s, sys: 23.3 s, total: 43min 27s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[ 0.1 * i for i in range(0,5)],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.5],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 9h 6min 51s, sys: 4min 47s, total: 9h 11min 39s\n",
      "Wall time: 57min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[i/10.0 for i in range(1,10)],\n",
    "     'colsample_bytree':[i/10.0 for i in range(1,10)],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 500, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 11min 42s, sys: 37 s, total: 1h 12min 19s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.5,0.4,0.3,0.2,0.1,0.075,0.05,0.04,0.03],\n",
    "    'n_estimators':[500],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1149.84640685\n",
      "{'reg_alpha': 0.0001, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 5min 45s, sys: 34.6 s, total: 1h 6min 19s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_alpha':[1e-5,1e-4,1e-3, 1e-2, 0.1, 1,10,100],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

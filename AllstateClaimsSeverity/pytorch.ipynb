{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 28676482.497397907\n",
      "1 23965886.513415992\n",
      "2 22325888.37118727\n",
      "3 20731011.705596924\n",
      "4 17847816.391861275\n",
      "5 13883854.525408119\n",
      "6 9767455.885037675\n",
      "7 6414076.239766388\n",
      "8 4092013.3348313724\n",
      "9 2641972.8625509217\n",
      "10 1775440.718993708\n",
      "11 1260306.2472379066\n",
      "12 945316.8950593267\n",
      "13 743279.6286606714\n",
      "14 606025.4083582858\n",
      "15 507312.80104036536\n",
      "16 432588.91402549896\n",
      "17 373713.2110443465\n",
      "18 325887.5516153921\n",
      "19 286245.2655545585\n",
      "20 252803.9054976724\n",
      "21 224280.73082003754\n",
      "22 199765.48642932487\n",
      "23 178605.7378738626\n",
      "24 160161.6341203244\n",
      "25 144013.17119445\n",
      "26 129820.38772125915\n",
      "27 117301.48726840303\n",
      "28 106212.94149942398\n",
      "29 96366.5003723845\n",
      "30 87617.34100141125\n",
      "31 79799.08400147843\n",
      "32 72800.44314587783\n",
      "33 66517.18179420824\n",
      "34 60863.207229801505\n",
      "35 55765.85595006904\n",
      "36 51164.157019722625\n",
      "37 47003.92187125696\n",
      "38 43230.296387947164\n",
      "39 39804.59908503918\n",
      "40 36686.374989989876\n",
      "41 33845.139319745984\n",
      "42 31252.292023138405\n",
      "43 28885.436604435825\n",
      "44 26724.955145384905\n",
      "45 24752.215563279417\n",
      "46 22943.388876296034\n",
      "47 21281.93868752111\n",
      "48 19757.57646058973\n",
      "49 18354.676282595232\n",
      "50 17061.344976263834\n",
      "51 15869.622975351574\n",
      "52 14769.16330619398\n",
      "53 13752.377458657045\n",
      "54 12812.473314659212\n",
      "55 11942.61614719267\n",
      "56 11137.508761270557\n",
      "57 10391.756268067016\n",
      "58 9699.949930114793\n",
      "59 9058.532588312264\n",
      "60 8463.410809176108\n",
      "61 7910.601560098743\n",
      "62 7397.116287492008\n",
      "63 6920.639108385632\n",
      "64 6476.996862683092\n",
      "65 6063.708822089084\n",
      "66 5678.68946819369\n",
      "67 5320.2923780645015\n",
      "68 4986.818056260767\n",
      "69 4675.544083269606\n",
      "70 4385.066201214905\n",
      "71 4113.803965503357\n",
      "72 3860.3064185321464\n",
      "73 3623.345444553669\n",
      "74 3401.813224750139\n",
      "75 3194.578669146019\n",
      "76 3000.826072348591\n",
      "77 2819.4793736032257\n",
      "78 2649.7662403445693\n",
      "79 2490.7257772406974\n",
      "80 2341.777681550751\n",
      "81 2202.1655622401277\n",
      "82 2071.261834314832\n",
      "83 1948.5193700882403\n",
      "84 1833.4099847047542\n",
      "85 1725.4170439680934\n",
      "86 1624.0491097738686\n",
      "87 1528.9509686597994\n",
      "88 1439.667107310995\n",
      "89 1355.779991925099\n",
      "90 1276.9912567210913\n",
      "91 1202.9916671913015\n",
      "92 1133.4601496925109\n",
      "93 1068.1249196292574\n",
      "94 1006.6798504024292\n",
      "95 948.9094392719462\n",
      "96 894.6822377890885\n",
      "97 843.7073218326669\n",
      "98 795.7397403788223\n",
      "99 750.6034583076898\n",
      "100 708.1228015103568\n",
      "101 668.1270341328451\n",
      "102 630.4657138961352\n",
      "103 594.9969724054167\n",
      "104 561.5967733439829\n",
      "105 530.1283659483871\n",
      "106 500.4873118888884\n",
      "107 472.56603872753146\n",
      "108 446.2454941977496\n",
      "109 421.42175281105153\n",
      "110 398.0207066470763\n",
      "111 375.9585627922297\n",
      "112 355.15370648968377\n",
      "113 335.5340388668775\n",
      "114 317.0259642365191\n",
      "115 299.568310933197\n",
      "116 283.10170364560406\n",
      "117 267.5609759348514\n",
      "118 252.89445083125636\n",
      "119 239.05672809376682\n",
      "120 225.99264367512205\n",
      "121 213.66433685080167\n",
      "122 202.0245801635956\n",
      "123 191.0302062175694\n",
      "124 180.64870220997017\n",
      "125 170.84735403484876\n",
      "126 161.5915360253466\n",
      "127 152.84788597552262\n",
      "128 144.5864612622065\n",
      "129 136.7842286665389\n",
      "130 129.41000712654164\n",
      "131 122.44199136586633\n",
      "132 115.85710933755625\n",
      "133 109.63560332989499\n",
      "134 103.75400412968689\n",
      "135 98.193178047158\n",
      "136 92.93978861846128\n",
      "137 87.9755003781669\n",
      "138 83.27636148870354\n",
      "139 78.83295831048693\n",
      "140 74.6331462254491\n",
      "141 70.65939942210065\n",
      "142 66.90360651832901\n",
      "143 63.34994261623859\n",
      "144 59.988460064996346\n",
      "145 56.80672376820982\n",
      "146 53.79771039389412\n",
      "147 50.952848996221306\n",
      "148 48.25905319304658\n",
      "149 45.71237778232809\n",
      "150 43.30026269904191\n",
      "151 41.017700390868626\n",
      "152 38.85678165989681\n",
      "153 36.812396708950445\n",
      "154 34.87661718542604\n",
      "155 33.04382377863551\n",
      "156 31.309826894403518\n",
      "157 29.668078474345307\n",
      "158 28.11302753472627\n",
      "159 26.641009330328302\n",
      "160 25.24746603623753\n",
      "161 23.928448334385767\n",
      "162 22.677967921997183\n",
      "163 21.494326296307765\n",
      "164 20.37342589117648\n",
      "165 19.31166383892632\n",
      "166 18.30598474387563\n",
      "167 17.35337990881\n",
      "168 16.45034760175321\n",
      "169 15.596182238909435\n",
      "170 14.785981574420465\n",
      "171 14.019197452800256\n",
      "172 13.291797271013898\n",
      "173 12.60248918608767\n",
      "174 11.950759754125176\n",
      "175 11.331813069712968\n",
      "176 10.745834984412202\n",
      "177 10.191117385647946\n",
      "178 9.664580563579065\n",
      "179 9.165697609256227\n",
      "180 8.693336066695895\n",
      "181 8.244395811730419\n",
      "182 7.8200254550426465\n",
      "183 7.417274601334448\n",
      "184 7.035123772951805\n",
      "185 6.673483967872812\n",
      "186 6.330461442577431\n",
      "187 6.00548993142115\n",
      "188 5.697188759396541\n",
      "189 5.404707370667062\n",
      "190 5.12779751323442\n",
      "191 4.86466586080847\n",
      "192 4.615749127332826\n",
      "193 4.37921147113164\n",
      "194 4.15497822157106\n",
      "195 3.9425387787644617\n",
      "196 3.7409240195032396\n",
      "197 3.5498775281266397\n",
      "198 3.3683611864727467\n",
      "199 3.196686082029519\n",
      "200 3.0332868050605377\n",
      "201 2.878779032306504\n",
      "202 2.732083098302959\n",
      "203 2.5929357091735\n",
      "204 2.4609930778227955\n",
      "205 2.335538558999243\n",
      "206 2.216717500921825\n",
      "207 2.104088737169027\n",
      "208 1.9971494783040313\n",
      "209 1.895701200988814\n",
      "210 1.7994451108915612\n",
      "211 1.708169050433604\n",
      "212 1.621525792403813\n",
      "213 1.5393049881407705\n",
      "214 1.4611777749484292\n",
      "215 1.3871686513678974\n",
      "216 1.316951079215837\n",
      "217 1.250420881103306\n",
      "218 1.187022195932209\n",
      "219 1.1270146416151496\n",
      "220 1.0700050186442605\n",
      "221 1.0159058121383353\n",
      "222 0.9646001473345596\n",
      "223 0.9158619851530823\n",
      "224 0.8696032607006154\n",
      "225 0.8257521502642824\n",
      "226 0.7841263349625147\n",
      "227 0.7446589952169833\n",
      "228 0.7070966345494378\n",
      "229 0.6715143852247296\n",
      "230 0.6376752091419542\n",
      "231 0.6055007974076867\n",
      "232 0.5751059566871861\n",
      "233 0.5461865804262596\n",
      "234 0.5187586839386009\n",
      "235 0.4927111241038995\n",
      "236 0.4679004426112927\n",
      "237 0.4444424764625774\n",
      "238 0.42214625143032003\n",
      "239 0.4009344440142124\n",
      "240 0.38080022829295235\n",
      "241 0.3616859379392068\n",
      "242 0.3435907987975011\n",
      "243 0.32640498601275425\n",
      "244 0.3100877294880071\n",
      "245 0.2944855690793995\n",
      "246 0.27975908918497794\n",
      "247 0.26582561428440243\n",
      "248 0.2524340997657406\n",
      "249 0.2398807703885142\n",
      "250 0.22788482545863786\n",
      "251 0.21651638920717176\n",
      "252 0.20566161151153128\n",
      "253 0.19540371734605344\n",
      "254 0.1856442974122885\n",
      "255 0.17634700461111752\n",
      "256 0.16756820106890125\n",
      "257 0.15921044139216178\n",
      "258 0.1513145935223994\n",
      "259 0.1437904310548559\n",
      "260 0.13658859958814595\n",
      "261 0.12978421019128827\n",
      "262 0.12332326730460341\n",
      "263 0.11722358559673562\n",
      "264 0.11135352571230417\n",
      "265 0.10585592824429924\n",
      "266 0.10059919323883726\n",
      "267 0.09560608520620661\n",
      "268 0.09085527262262172\n",
      "269 0.08633653884538894\n",
      "270 0.08203595675641395\n",
      "271 0.07798436191502045\n",
      "272 0.07410236074568477\n",
      "273 0.07041030770290835\n",
      "274 0.06691620257567843\n",
      "275 0.06359796690193809\n",
      "276 0.06044193698298207\n",
      "277 0.05746557046282974\n",
      "278 0.05460794168377969\n",
      "279 0.051916692245792984\n",
      "280 0.04933363409442659\n",
      "281 0.04688432832086842\n",
      "282 0.044574809018006256\n",
      "283 0.042380254604706846\n",
      "284 0.04029620009582857\n",
      "285 0.0382945201292231\n",
      "286 0.03641973319754854\n",
      "287 0.034625577876461144\n",
      "288 0.032912749587371365\n",
      "289 0.03129696685407435\n",
      "290 0.029749661227375046\n",
      "291 0.028287739029249474\n",
      "292 0.02691312765005721\n",
      "293 0.025581182005934178\n",
      "294 0.02433447744625239\n",
      "295 0.023141524772823274\n",
      "296 0.022005324783716418\n",
      "297 0.020923395787027177\n",
      "298 0.019911930091702834\n",
      "299 0.018937223251691115\n",
      "300 0.018016125687713824\n",
      "301 0.017136794439256642\n",
      "302 0.016302944806061648\n",
      "303 0.015498711050312919\n",
      "304 0.014753437832439653\n",
      "305 0.014041262015958511\n",
      "306 0.013357090020847284\n",
      "307 0.012719311748090878\n",
      "308 0.012106371241475733\n",
      "309 0.011528814470098736\n",
      "310 0.010973587744829594\n",
      "311 0.010442702325392794\n",
      "312 0.009943812855455647\n",
      "313 0.009465916830970311\n",
      "314 0.009013367420574403\n",
      "315 0.008583159066891888\n",
      "316 0.008173812550158921\n",
      "317 0.007779872003285837\n",
      "318 0.007410181919735026\n",
      "319 0.007065009641106679\n",
      "320 0.006731323223614194\n",
      "321 0.006418448334802651\n",
      "322 0.0061180333731916114\n",
      "323 0.0058316053869622575\n",
      "324 0.005559013684052427\n",
      "325 0.0053054243132603235\n",
      "326 0.005056932900370292\n",
      "327 0.004822520528776686\n",
      "328 0.004602808862486596\n",
      "329 0.004390726386674593\n",
      "330 0.0041894676795193875\n",
      "331 0.0040044699145562745\n",
      "332 0.0038197310284339703\n",
      "333 0.003647744496725891\n",
      "334 0.0034899217851434017\n",
      "335 0.0033309337805984135\n",
      "336 0.003184083811963438\n",
      "337 0.0030455006263388484\n",
      "338 0.0029124692148814746\n",
      "339 0.0027824397294641257\n",
      "340 0.002660672362982508\n",
      "341 0.002546496454251479\n",
      "342 0.00243670283387884\n",
      "343 0.0023310965969167152\n",
      "344 0.0022351170594197\n",
      "345 0.0021409098628574763\n",
      "346 0.0020524729861102764\n",
      "347 0.0019657998121036524\n",
      "348 0.0018851765570334078\n",
      "349 0.0018067317643384317\n",
      "350 0.0017330010287383013\n",
      "351 0.0016622508470285347\n",
      "352 0.0015939365339123768\n",
      "353 0.001531321994762913\n",
      "354 0.0014696686410615167\n",
      "355 0.001410585257860364\n",
      "356 0.0013557641424549738\n",
      "357 0.0013011189398887957\n",
      "358 0.0012537668397355484\n",
      "359 0.0012057491720374736\n",
      "360 0.0011602672155756055\n",
      "361 0.0011138748208976007\n",
      "362 0.0010729395927988883\n",
      "363 0.001031987081598032\n",
      "364 0.0009933642880880778\n",
      "365 0.0009569643531011918\n",
      "366 0.0009214871101754698\n",
      "367 0.0008888849882986855\n",
      "368 0.0008568163404461537\n",
      "369 0.0008250983842204573\n",
      "370 0.0007966762899087043\n",
      "371 0.0007685840700459856\n",
      "372 0.0007423387936428827\n",
      "373 0.0007154134094953246\n",
      "374 0.0006913215252228634\n",
      "375 0.000666791960834745\n",
      "376 0.0006452265353771303\n",
      "377 0.0006245271172700684\n",
      "378 0.0006036928557613397\n",
      "379 0.0005841512497180568\n",
      "380 0.0005641088223893309\n",
      "381 0.0005459759428030897\n",
      "382 0.0005292862430673617\n",
      "383 0.0005126140088955733\n",
      "384 0.0004962523850418621\n",
      "385 0.00048214793262440006\n",
      "386 0.00046655349772713184\n",
      "387 0.0004524255556683267\n",
      "388 0.0004390380007446848\n",
      "389 0.0004262363687724813\n",
      "390 0.0004125485919784233\n",
      "391 0.00040061032575929023\n",
      "392 0.00038887029673713436\n",
      "393 0.0003770890526115789\n",
      "394 0.0003661457967400472\n",
      "395 0.0003565668336670269\n",
      "396 0.0003462843018496309\n",
      "397 0.000335817162704366\n",
      "398 0.00032690922981465365\n",
      "399 0.00031806446057797144\n",
      "400 0.00030885047450168734\n",
      "401 0.0003003591152119789\n",
      "402 0.00029208649365636274\n",
      "403 0.0002845203942488661\n",
      "404 0.0002767318854747236\n",
      "405 0.00026956049165460794\n",
      "406 0.00026204050060074646\n",
      "407 0.0002555440658580932\n",
      "408 0.0002487391934202221\n",
      "409 0.00024271969130790216\n",
      "410 0.0002369183340368286\n",
      "411 0.0002296284806702631\n",
      "412 0.00022429312600602547\n",
      "413 0.0002190643833120398\n",
      "414 0.00021364427868275637\n",
      "415 0.00020891907260817133\n",
      "416 0.00020398491322332069\n",
      "417 0.00019873433464574763\n",
      "418 0.0001941989908618713\n",
      "419 0.00018932649325087425\n",
      "420 0.00018469358894157573\n",
      "421 0.0001808537615027861\n",
      "422 0.00017602912735115162\n",
      "423 0.00017217760346449618\n",
      "424 0.0001678077500142372\n",
      "425 0.00016447356108761912\n",
      "426 0.00016039933831435427\n",
      "427 0.00015714091342494685\n",
      "428 0.00015318353134335938\n",
      "429 0.0001500528537672352\n",
      "430 0.00014668968337844257\n",
      "431 0.00014373861438266022\n",
      "432 0.00014027831510643463\n",
      "433 0.00013765381668845444\n",
      "434 0.00013428847597679594\n",
      "435 0.00013117929022621322\n",
      "436 0.0001281732403143332\n",
      "437 0.0001254865322997123\n",
      "438 0.0001230629612105072\n",
      "439 0.00012020727112543872\n",
      "440 0.0001181868704516198\n",
      "441 0.00011550349157168904\n",
      "442 0.00011334065802859339\n",
      "443 0.00011091754466441284\n",
      "444 0.00010868447604009401\n",
      "445 0.00010633371455365248\n",
      "446 0.00010456687001608733\n",
      "447 0.00010245239763967406\n",
      "448 0.00010040155940721496\n",
      "449 9.857380524025405e-05\n",
      "450 9.689116544137066e-05\n",
      "451 9.501081711188464e-05\n",
      "452 9.35791020670873e-05\n",
      "453 9.153156885682856e-05\n",
      "454 8.959495450229504e-05\n",
      "455 8.822872562058715e-05\n",
      "456 8.672985078038518e-05\n",
      "457 8.496006213837282e-05\n",
      "458 8.307195374102072e-05\n",
      "459 8.146778860058934e-05\n",
      "460 8.034233153510206e-05\n",
      "461 7.869811284295924e-05\n",
      "462 7.72248649845847e-05\n",
      "463 7.612542961532576e-05\n",
      "464 7.500293077364328e-05\n",
      "465 7.377147055800948e-05\n",
      "466 7.236155147406775e-05\n",
      "467 7.138718543855949e-05\n",
      "468 7.036608820439397e-05\n",
      "469 6.875431801117715e-05\n",
      "470 6.752156471324933e-05\n",
      "471 6.642543942753099e-05\n",
      "472 6.552301885749678e-05\n",
      "473 6.450859016389476e-05\n",
      "474 6.342098907374805e-05\n",
      "475 6.236376685492262e-05\n",
      "476 6.134206729679903e-05\n",
      "477 6.0357137385946835e-05\n",
      "478 5.946158751007902e-05\n",
      "479 5.8263026237181936e-05\n",
      "480 5.762879945492294e-05\n",
      "481 5.6560822910445285e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 5.5687679856378236e-05\n",
      "483 5.463943076523814e-05\n",
      "484 5.4071819940076926e-05\n",
      "485 5.3337978430892385e-05\n",
      "486 5.2641257290153565e-05\n",
      "487 5.1904853742956725e-05\n",
      "488 5.1125623296746636e-05\n",
      "489 5.029253701732683e-05\n",
      "490 4.9477430098934794e-05\n",
      "491 4.871886813402615e-05\n",
      "492 4.8090234028533296e-05\n",
      "493 4.755359102577572e-05\n",
      "494 4.6599577969430594e-05\n",
      "495 4.6187124971119875e-05\n",
      "496 4.5546439445709463e-05\n",
      "497 4.5053471565748016e-05\n",
      "498 4.426680337372979e-05\n",
      "499 4.3737294482398825e-05\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "# dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random input and output data\n",
    "x = torch.randn(N, D_in).type(dtype)\n",
    "y = torch.randn(N, D_out).type(dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H).type(dtype)\n",
    "w2 = torch.randn(H, D_out).type(dtype)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "    h_relu = h.clamp(min=0)\n",
    "    y_pred = h_relu.mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    grad_y_pred = 2.0 * (y_pred - y)\n",
    "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
    "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
    "    grad_h = grad_h_relu.clone()\n",
    "    grad_h[h < 0] = 0\n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 24727718.0\n",
      "1 17994948.0\n",
      "2 14547852.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "# Setting requires_grad=False indicates that we do not need to compute gradients\n",
    "# with respect to these Variables during the backward pass.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these Variables during the backward pass.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(3):\n",
    "    # Forward pass: compute predicted y using operations on Variables; these\n",
    "    # are exactly the same operations we used to compute the forward pass using\n",
    "    # Tensors, but we do not need to keep references to intermediate values since\n",
    "    # we are not implementing the backward pass by hand.\n",
    "    y_pred = x.mm(w1).clamp(min=0).mm(w2)\n",
    "\n",
    "    # Compute and print loss using operations on Variables.\n",
    "    # Now loss is a Variable of shape (1,) and loss.data is a Tensor of shape\n",
    "    # (1,); loss.data[0] is a scalar value holding the loss.\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass. This call will compute the\n",
    "    # gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call w1.grad and w2.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to w1 and w2 respectively.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent; w1.data and w2.data are Tensors,\n",
    "    # w1.grad and w2.grad are Variables and w1.grad.data and w2.grad.data are\n",
    "    # Tensors.\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 24086628.0\n",
      "1 20121036.0\n",
      "2 19003920.0\n",
      "3 18184696.0\n",
      "4 16461066.0\n",
      "5 13484244.0\n",
      "6 9995575.0\n",
      "7 6783247.0\n",
      "8 4389451.5\n",
      "9 2798093.75\n",
      "10 1822152.5\n",
      "11 1235690.875\n",
      "12 882750.375\n",
      "13 663415.6875\n",
      "14 521005.46875\n",
      "15 423498.1875\n",
      "16 353219.4375\n",
      "17 300080.8125\n",
      "18 258331.0625\n",
      "19 224521.984375\n",
      "20 196562.875\n",
      "21 173042.171875\n",
      "22 153017.46875\n",
      "23 135830.796875\n",
      "24 120971.4765625\n",
      "25 108059.890625\n",
      "26 96787.0859375\n",
      "27 86903.8984375\n",
      "28 78217.71875\n",
      "29 70563.859375\n",
      "30 63783.72265625\n",
      "31 57762.484375\n",
      "32 52396.12109375\n",
      "33 47603.97265625\n",
      "34 43320.20703125\n",
      "35 39481.62890625\n",
      "36 36033.48828125\n",
      "37 32928.65625\n",
      "38 30127.060546875\n",
      "39 27594.841796875\n",
      "40 25302.501953125\n",
      "41 23223.845703125\n",
      "42 21337.06640625\n",
      "43 19621.001953125\n",
      "44 18058.3359375\n",
      "45 16634.361328125\n",
      "46 15334.2138671875\n",
      "47 14146.0654296875\n",
      "48 13059.0537109375\n",
      "49 12063.9990234375\n",
      "50 11152.076171875\n",
      "51 10315.2431640625\n",
      "52 9546.7529296875\n",
      "53 8840.59765625\n",
      "54 8190.84033203125\n",
      "55 7592.71142578125\n",
      "56 7041.8154296875\n",
      "57 6533.86865234375\n",
      "58 6065.0126953125\n",
      "59 5632.2177734375\n",
      "60 5232.46337890625\n",
      "61 4863.107421875\n",
      "62 4521.3984375\n",
      "63 4205.16943359375\n",
      "64 3912.455322265625\n",
      "65 3641.419677734375\n",
      "66 3390.18603515625\n",
      "67 3157.274658203125\n",
      "68 2941.2509765625\n",
      "69 2740.82568359375\n",
      "70 2554.74609375\n",
      "71 2381.9365234375\n",
      "72 2221.40234375\n",
      "73 2072.2080078125\n",
      "74 1933.5361328125\n",
      "75 1804.5408935546875\n",
      "76 1684.549072265625\n",
      "77 1572.9737548828125\n",
      "78 1469.0145263671875\n",
      "79 1372.222900390625\n",
      "80 1282.081787109375\n",
      "81 1198.109375\n",
      "82 1119.82275390625\n",
      "83 1046.8734130859375\n",
      "84 978.8413696289062\n",
      "85 915.3224487304688\n",
      "86 856.0667114257812\n",
      "87 800.7860107421875\n",
      "88 749.1953125\n",
      "89 701.042236328125\n",
      "90 656.0909423828125\n",
      "91 614.1094360351562\n",
      "92 574.9046020507812\n",
      "93 538.2852172851562\n",
      "94 504.0662841796875\n",
      "95 472.0794677734375\n",
      "96 442.1878967285156\n",
      "97 414.257568359375\n",
      "98 388.1265563964844\n",
      "99 363.69842529296875\n",
      "100 340.84930419921875\n",
      "101 319.4804382324219\n",
      "102 299.48016357421875\n",
      "103 280.7684020996094\n",
      "104 263.2547607421875\n",
      "105 246.8706817626953\n",
      "106 231.52630615234375\n",
      "107 217.1630096435547\n",
      "108 203.71420288085938\n",
      "109 191.11932373046875\n",
      "110 179.31764221191406\n",
      "111 168.27113342285156\n",
      "112 157.91543579101562\n",
      "113 148.21420288085938\n",
      "114 139.1250457763672\n",
      "115 130.60372924804688\n",
      "116 122.61911010742188\n",
      "117 115.13190460205078\n",
      "118 108.11247253417969\n",
      "119 101.53164672851562\n",
      "120 95.36122131347656\n",
      "121 89.57251739501953\n",
      "122 84.14497375488281\n",
      "123 79.05220794677734\n",
      "124 74.27462768554688\n",
      "125 69.79169464111328\n",
      "126 65.5860595703125\n",
      "127 61.63916778564453\n",
      "128 57.93372344970703\n",
      "129 54.456912994384766\n",
      "130 51.19364929199219\n",
      "131 48.12862014770508\n",
      "132 45.25202560424805\n",
      "133 42.55055236816406\n",
      "134 40.014007568359375\n",
      "135 37.6314811706543\n",
      "136 35.39369201660156\n",
      "137 33.29155731201172\n",
      "138 31.316986083984375\n",
      "139 29.462158203125\n",
      "140 27.719451904296875\n",
      "141 26.08146095275879\n",
      "142 24.542577743530273\n",
      "143 23.095672607421875\n",
      "144 21.736066818237305\n",
      "145 20.45756721496582\n",
      "146 19.25696563720703\n",
      "147 18.127344131469727\n",
      "148 17.06537437438965\n",
      "149 16.066574096679688\n",
      "150 15.127962112426758\n",
      "151 14.24453067779541\n",
      "152 13.41413402557373\n",
      "153 12.632612228393555\n",
      "154 11.89818000793457\n",
      "155 11.207193374633789\n",
      "156 10.556600570678711\n",
      "157 9.94442081451416\n",
      "158 9.368817329406738\n",
      "159 8.826881408691406\n",
      "160 8.316987991333008\n",
      "161 7.837002754211426\n",
      "162 7.385588645935059\n",
      "163 6.96010684967041\n",
      "164 6.559843063354492\n",
      "165 6.182835578918457\n",
      "166 5.828336238861084\n",
      "167 5.49423360824585\n",
      "168 5.1796393394470215\n",
      "169 4.883303165435791\n",
      "170 4.604323863983154\n",
      "171 4.34160852432251\n",
      "172 4.093987941741943\n",
      "173 3.8608694076538086\n",
      "174 3.6413142681121826\n",
      "175 3.4344165325164795\n",
      "176 3.2394278049468994\n",
      "177 3.055659294128418\n",
      "178 2.8825531005859375\n",
      "179 2.719273805618286\n",
      "180 2.56563401222229\n",
      "181 2.420764684677124\n",
      "182 2.284353494644165\n",
      "183 2.1554996967315674\n",
      "184 2.034050226211548\n",
      "185 1.9196122884750366\n",
      "186 1.8118072748184204\n",
      "187 1.7101186513900757\n",
      "188 1.6142359972000122\n",
      "189 1.5238792896270752\n",
      "190 1.4385685920715332\n",
      "191 1.35819673538208\n",
      "192 1.2823117971420288\n",
      "193 1.2107131481170654\n",
      "194 1.1432543992996216\n",
      "195 1.0795756578445435\n",
      "196 1.0195403099060059\n",
      "197 0.9629159569740295\n",
      "198 0.9093824625015259\n",
      "199 0.8589727282524109\n",
      "200 0.8113871216773987\n",
      "201 0.766433835029602\n",
      "202 0.7239879965782166\n",
      "203 0.684006929397583\n",
      "204 0.6462079286575317\n",
      "205 0.6105923652648926\n",
      "206 0.5769298076629639\n",
      "207 0.5451726317405701\n",
      "208 0.5151804685592651\n",
      "209 0.4868951141834259\n",
      "210 0.46010953187942505\n",
      "211 0.43489164113998413\n",
      "212 0.411089688539505\n",
      "213 0.38853052258491516\n",
      "214 0.36725297570228577\n",
      "215 0.3471921384334564\n",
      "216 0.3282240033149719\n",
      "217 0.31029266119003296\n",
      "218 0.29341599345207214\n",
      "219 0.2773723900318146\n",
      "220 0.26232072710990906\n",
      "221 0.2480313777923584\n",
      "222 0.23454634845256805\n",
      "223 0.2217836230993271\n",
      "224 0.20975761115550995\n",
      "225 0.19838470220565796\n",
      "226 0.18764092028141022\n",
      "227 0.1774827092885971\n",
      "228 0.16786953806877136\n",
      "229 0.15880587697029114\n",
      "230 0.15024755895137787\n",
      "231 0.14215832948684692\n",
      "232 0.1344868689775467\n",
      "233 0.1272667497396469\n",
      "234 0.12041459232568741\n",
      "235 0.11393073201179504\n",
      "236 0.10777478665113449\n",
      "237 0.1019931435585022\n",
      "238 0.09653132408857346\n",
      "239 0.09135190397500992\n",
      "240 0.08647225052118301\n",
      "241 0.08184020221233368\n",
      "242 0.07745783030986786\n",
      "243 0.07331426441669464\n",
      "244 0.06940590590238571\n",
      "245 0.06570715457201004\n",
      "246 0.06219609081745148\n",
      "247 0.05888647958636284\n",
      "248 0.05575219914317131\n",
      "249 0.05279412120580673\n",
      "250 0.049981966614723206\n",
      "251 0.04731700196862221\n",
      "252 0.04481193423271179\n",
      "253 0.042434826493263245\n",
      "254 0.04018840566277504\n",
      "255 0.03806762397289276\n",
      "256 0.03604862093925476\n",
      "257 0.03413598611950874\n",
      "258 0.032340601086616516\n",
      "259 0.03061952069401741\n",
      "260 0.029012972488999367\n",
      "261 0.027482761070132256\n",
      "262 0.026038244366645813\n",
      "263 0.024671340361237526\n",
      "264 0.023377113044261932\n",
      "265 0.022154727950692177\n",
      "266 0.020993707701563835\n",
      "267 0.019889716058969498\n",
      "268 0.018852781504392624\n",
      "269 0.01787729561328888\n",
      "270 0.016946185380220413\n",
      "271 0.016061773523688316\n",
      "272 0.015233222395181656\n",
      "273 0.014439129270613194\n",
      "274 0.013694308698177338\n",
      "275 0.012976228259503841\n",
      "276 0.012308006174862385\n",
      "277 0.011678745970129967\n",
      "278 0.01106527540832758\n",
      "279 0.010501688346266747\n",
      "280 0.009957743808627129\n",
      "281 0.009453457780182362\n",
      "282 0.008974996395409107\n",
      "283 0.008513553999364376\n",
      "284 0.008078496903181076\n",
      "285 0.007677390240132809\n",
      "286 0.007282339036464691\n",
      "287 0.006915177684277296\n",
      "288 0.006567975040525198\n",
      "289 0.006244114600121975\n",
      "290 0.005933575797826052\n",
      "291 0.0056366524659097195\n",
      "292 0.005358489695936441\n",
      "293 0.005094689317047596\n",
      "294 0.004840988200157881\n",
      "295 0.0046102991327643394\n",
      "296 0.004383238963782787\n",
      "297 0.0041704196482896805\n",
      "298 0.003967368043959141\n",
      "299 0.0037782981526106596\n",
      "300 0.003596027148887515\n",
      "301 0.0034258116502314806\n",
      "302 0.0032647091429680586\n",
      "303 0.0031124106608331203\n",
      "304 0.002966455416753888\n",
      "305 0.0028271405026316643\n",
      "306 0.002696678275242448\n",
      "307 0.0025726715102791786\n",
      "308 0.002457602648064494\n",
      "309 0.002345533110201359\n",
      "310 0.0022406799253076315\n",
      "311 0.0021392167545855045\n",
      "312 0.002043583197519183\n",
      "313 0.0019527490949258208\n",
      "314 0.0018699538195505738\n",
      "315 0.0017895549535751343\n",
      "316 0.0017111608758568764\n",
      "317 0.0016389369266107678\n",
      "318 0.00156903057359159\n",
      "319 0.0015032782685011625\n",
      "320 0.0014392184093594551\n",
      "321 0.0013788773212581873\n",
      "322 0.0013224415015429258\n",
      "323 0.0012681439984589815\n",
      "324 0.0012172677088528872\n",
      "325 0.0011672999244183302\n",
      "326 0.001121946726925671\n",
      "327 0.0010764198377728462\n",
      "328 0.0010355296544730663\n",
      "329 0.0009949816158041358\n",
      "330 0.0009566113585606217\n",
      "331 0.0009201365173794329\n",
      "332 0.0008858726359903812\n",
      "333 0.0008523280266672373\n",
      "334 0.0008210374508053064\n",
      "335 0.0007898479816503823\n",
      "336 0.0007610335014760494\n",
      "337 0.0007324421312659979\n",
      "338 0.000705092737916857\n",
      "339 0.0006798059330321848\n",
      "340 0.0006556891603395343\n",
      "341 0.0006321140681393445\n",
      "342 0.0006102152401581407\n",
      "343 0.0005889316671527922\n",
      "344 0.000567426613997668\n",
      "345 0.0005482911365106702\n",
      "346 0.0005294748698361218\n",
      "347 0.0005119204288348556\n",
      "348 0.0004939547507092357\n",
      "349 0.00047779735177755356\n",
      "350 0.000462502270238474\n",
      "351 0.00044606553274206817\n",
      "352 0.00043141216156072915\n",
      "353 0.00041854928713291883\n",
      "354 0.0004043873050250113\n",
      "355 0.00039245164953172207\n",
      "356 0.00037974599399603903\n",
      "357 0.0003677841159515083\n",
      "358 0.00035667690099217\n",
      "359 0.0003456602862570435\n",
      "360 0.00033488444751128554\n",
      "361 0.0003245096595492214\n",
      "362 0.00031476913136430085\n",
      "363 0.00030543922912329435\n",
      "364 0.00029713098774664104\n",
      "365 0.0002876583021134138\n",
      "366 0.0002794982574414462\n",
      "367 0.00027099522412754595\n",
      "368 0.0002635630080476403\n",
      "369 0.00025674764765426517\n",
      "370 0.0002495502703823149\n",
      "371 0.00024278748605865985\n",
      "372 0.00023574971419293433\n",
      "373 0.00022956397151574492\n",
      "374 0.0002232015976915136\n",
      "375 0.0002166650810977444\n",
      "376 0.0002114861854352057\n",
      "377 0.00020602896984200925\n",
      "378 0.00019995335605926812\n",
      "379 0.00019512613653205335\n",
      "380 0.00018965653725899756\n",
      "381 0.00018435379024595022\n",
      "382 0.00017983138968702406\n",
      "383 0.00017476135690230876\n",
      "384 0.00017093915084842592\n",
      "385 0.00016671104822307825\n",
      "386 0.00016241884441114962\n",
      "387 0.00015828195319045335\n",
      "388 0.00015443797747138888\n",
      "389 0.00015103443001862615\n",
      "390 0.00014778817421756685\n",
      "391 0.00014450929302256554\n",
      "392 0.00014066224684938788\n",
      "393 0.00013755167310591787\n",
      "394 0.0001340547314612195\n",
      "395 0.0001312180102104321\n",
      "396 0.0001281718723475933\n",
      "397 0.0001254781091120094\n",
      "398 0.0001223210128955543\n",
      "399 0.00011982354044448584\n",
      "400 0.0001167871305369772\n",
      "401 0.00011437876673880965\n",
      "402 0.00011187951895408332\n",
      "403 0.00010966671106871217\n",
      "404 0.00010707572073442861\n",
      "405 0.00010508139530429617\n",
      "406 0.00010264428419759497\n",
      "407 0.00010004534851759672\n",
      "408 9.831152419792488e-05\n",
      "409 9.623760706745088e-05\n",
      "410 9.404172305949032e-05\n",
      "411 9.226043039234355e-05\n",
      "412 9.034651884576306e-05\n",
      "413 8.863383845891804e-05\n",
      "414 8.711096597835422e-05\n",
      "415 8.547019388061017e-05\n",
      "416 8.369852730538696e-05\n",
      "417 8.183236059267074e-05\n",
      "418 8.051112672546878e-05\n",
      "419 7.886529783718288e-05\n",
      "420 7.762121822452173e-05\n",
      "421 7.618638483108953e-05\n",
      "422 7.455130980815738e-05\n",
      "423 7.322418969124556e-05\n",
      "424 7.193988130893558e-05\n",
      "425 7.057018228806555e-05\n",
      "426 6.943165499251336e-05\n",
      "427 6.814264634158462e-05\n",
      "428 6.68610300635919e-05\n",
      "429 6.543411291204393e-05\n",
      "430 6.422658771043643e-05\n",
      "431 6.319516251096502e-05\n",
      "432 6.211672734934837e-05\n",
      "433 6.118278542999178e-05\n",
      "434 6.0298407333903015e-05\n",
      "435 5.927644815528765e-05\n",
      "436 5.8139550674241036e-05\n",
      "437 5.730306656914763e-05\n",
      "438 5.645947749144398e-05\n",
      "439 5.5482301831943914e-05\n",
      "440 5.448398951557465e-05\n",
      "441 5.368970596464351e-05\n",
      "442 5.2811967179877684e-05\n",
      "443 5.187236820347607e-05\n",
      "444 5.107176912133582e-05\n",
      "445 5.0236361857969314e-05\n",
      "446 4.952640301780775e-05\n",
      "447 4.898259794572368e-05\n",
      "448 4.815501597477123e-05\n",
      "449 4.758730938192457e-05\n",
      "450 4.695645839092322e-05\n",
      "451 4.610275209415704e-05\n",
      "452 4.5326160034164786e-05\n",
      "453 4.4616564991883934e-05\n",
      "454 4.3960939365206286e-05\n",
      "455 4.336153870099224e-05\n",
      "456 4.283425005269237e-05\n",
      "457 4.212950079818256e-05\n",
      "458 4.1580264223739505e-05\n",
      "459 4.1123934352071956e-05\n",
      "460 4.059301863890141e-05\n",
      "461 4.0174087189370766e-05\n",
      "462 3.9537742850370705e-05\n",
      "463 3.899409421137534e-05\n",
      "464 3.844589809887111e-05\n",
      "465 3.7835430703125894e-05\n",
      "466 3.717899016919546e-05\n",
      "467 3.684035982587375e-05\n",
      "468 3.632029620348476e-05\n",
      "469 3.582380304578692e-05\n",
      "470 3.5412471333984286e-05\n",
      "471 3.47148634318728e-05\n",
      "472 3.435579128563404e-05\n",
      "473 3.3853688364615664e-05\n",
      "474 3.351706254761666e-05\n",
      "475 3.3100957807619125e-05\n",
      "476 3.2610041671432555e-05\n",
      "477 3.219453719793819e-05\n",
      "478 3.1720188417239115e-05\n",
      "479 3.1213923648465425e-05\n",
      "480 3.089369056397118e-05\n",
      "481 3.057672074646689e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "482 3.036273665202316e-05\n",
      "483 2.9804959922330454e-05\n",
      "484 2.9563147109001875e-05\n",
      "485 2.9158076358726248e-05\n",
      "486 2.869852505682502e-05\n",
      "487 2.842980575223919e-05\n",
      "488 2.8036571166012436e-05\n",
      "489 2.7760195735027082e-05\n",
      "490 2.7446405511000194e-05\n",
      "491 2.729773405008018e-05\n",
      "492 2.6985622753272764e-05\n",
      "493 2.6684308977564797e-05\n",
      "494 2.6404573873151094e-05\n",
      "495 2.6144376533920877e-05\n",
      "496 2.6003841412602924e-05\n",
      "497 2.5721272322698496e-05\n",
      "498 2.5351750082336366e-05\n",
      "499 2.513606523280032e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class MyReLU(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    We can implement our own custom autograd Functions by subclassing\n",
    "    torch.autograd.Function and implementing the forward and backward passes\n",
    "    which operate on Tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        In the forward pass we receive a Tensor containing the input and return a\n",
    "        Tensor containing the output. You can cache arbitrary Tensors for use in the\n",
    "        backward pass using the save_for_backward method.\n",
    "        \"\"\"\n",
    "        self.save_for_backward(input)\n",
    "        return input.clamp(min=0)\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
    "        with respect to the output, and we need to compute the gradient of the loss\n",
    "        with respect to the input.\n",
    "        \"\"\"\n",
    "        input, = self.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input < 0] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create random Tensors to hold input and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype), requires_grad=False)\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Create random Tensors for weights, and wrap them in Variables.\n",
    "w1 = Variable(torch.randn(D_in, H).type(dtype), requires_grad=True)\n",
    "w2 = Variable(torch.randn(H, D_out).type(dtype), requires_grad=True)\n",
    "\n",
    "learning_rate = 1e-6\n",
    "for t in range(500):\n",
    "    # Construct an instance of our MyReLU class to use in our network\n",
    "    relu = MyReLU()\n",
    "\n",
    "    # Forward pass: compute predicted y using operations on Variables; we compute\n",
    "    # ReLU using our custom autograd operation.\n",
    "    y_pred = relu(x.mm(w1)).mm(w2)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Use autograd to compute the backward pass.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights using gradient descent\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "\n",
    "    # Manually zero the gradients after updating weights\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.25145e+07\n",
      "2.76097e+07\n",
      "2.77802e+07\n",
      "2.80369e+07\n",
      "2.54698e+07\n",
      "1.96257e+07\n",
      "1.28596e+07\n",
      "7.49538e+06\n",
      "4.21512e+06\n",
      "2.46301e+06\n",
      "1.56808e+06\n",
      "1.09849e+06\n",
      "833224.0\n",
      "667714.0\n",
      "554058.0\n",
      "469672.0\n",
      "403490.0\n",
      "349734.0\n",
      "305081.0\n",
      "267522.0\n",
      "235503.0\n",
      "208000.0\n",
      "184257.0\n",
      "163689.0\n",
      "145787.0\n",
      "130132.0\n",
      "116402.0\n",
      "104329.0\n",
      "93677.6\n",
      "84262.9\n",
      "75919.4\n",
      "68501.6\n",
      "61898.7\n",
      "56009.4\n",
      "50746.3\n",
      "46032.7\n",
      "41804.2\n",
      "38004.7\n",
      "34585.6\n",
      "31508.4\n",
      "28731.1\n",
      "26222.5\n",
      "23953.3\n",
      "21898.1\n",
      "20035.3\n",
      "18351.5\n",
      "16823.2\n",
      "15434.2\n",
      "14171.9\n",
      "13028.3\n",
      "11985.1\n",
      "11033.6\n",
      "10163.8\n",
      "9368.74\n",
      "8640.75\n",
      "7973.82\n",
      "7362.27\n",
      "6801.27\n",
      "6286.45\n",
      "5813.58\n",
      "5378.96\n",
      "4979.35\n",
      "4611.63\n",
      "4272.94\n",
      "3960.84\n",
      "3673.42\n",
      "3408.5\n",
      "3163.92\n",
      "2938.06\n",
      "2728.98\n",
      "2535.78\n",
      "2357.25\n",
      "2192.13\n",
      "2039.29\n",
      "1897.77\n",
      "1766.62\n",
      "1645.09\n",
      "1532.41\n",
      "1427.9\n",
      "1330.9\n",
      "1240.86\n",
      "1157.26\n",
      "1079.6\n",
      "1007.42\n",
      "940.327\n",
      "877.938\n",
      "819.913\n",
      "765.911\n",
      "715.635\n",
      "668.816\n",
      "625.235\n",
      "584.624\n",
      "546.782\n",
      "511.483\n",
      "478.586\n",
      "447.892\n",
      "419.256\n",
      "392.54\n",
      "367.588\n",
      "344.3\n",
      "322.577\n",
      "302.281\n",
      "283.321\n",
      "265.593\n",
      "249.022\n",
      "233.523\n",
      "219.024\n",
      "205.464\n",
      "192.777\n",
      "180.901\n",
      "169.786\n",
      "159.377\n",
      "149.631\n",
      "140.504\n",
      "131.954\n",
      "123.941\n",
      "116.429\n",
      "109.389\n",
      "102.788\n",
      "96.5993\n",
      "90.7936\n",
      "85.3484\n",
      "80.2406\n",
      "75.4497\n",
      "70.9524\n",
      "66.7312\n",
      "62.7692\n",
      "59.0476\n",
      "55.5546\n",
      "52.2721\n",
      "49.1915\n",
      "46.2978\n",
      "43.5774\n",
      "41.0222\n",
      "38.6215\n",
      "36.3648\n",
      "34.2403\n",
      "32.2461\n",
      "30.3711\n",
      "28.6061\n",
      "26.947\n",
      "25.3863\n",
      "23.9185\n",
      "22.5364\n",
      "21.2365\n",
      "20.015\n",
      "18.8641\n",
      "17.7808\n",
      "16.7609\n",
      "15.8008\n",
      "14.8988\n",
      "14.047\n",
      "13.2451\n",
      "12.4912\n",
      "11.7808\n",
      "11.1109\n",
      "10.4808\n",
      "9.8867\n",
      "9.32737\n",
      "8.79997\n",
      "8.30269\n",
      "7.83407\n",
      "7.39284\n",
      "6.97642\n",
      "6.58463\n",
      "6.21458\n",
      "5.86604\n",
      "5.53748\n",
      "5.22735\n",
      "4.93499\n",
      "4.65943\n",
      "4.39942\n",
      "4.15431\n",
      "3.9228\n",
      "3.70454\n",
      "3.49861\n",
      "3.30419\n",
      "3.12119\n",
      "2.94835\n",
      "2.7848\n",
      "2.6306\n",
      "2.48559\n",
      "2.3482\n",
      "2.21851\n",
      "2.0965\n",
      "1.98099\n",
      "1.87179\n",
      "1.7692\n",
      "1.67197\n",
      "1.58018\n",
      "1.49346\n",
      "1.41181\n",
      "1.33446\n",
      "1.26154\n",
      "1.19262\n",
      "1.12735\n",
      "1.06585\n",
      "1.00771\n",
      "0.952794\n",
      "0.901108\n",
      "0.852115\n",
      "0.805906\n",
      "0.762101\n",
      "0.720757\n",
      "0.681664\n",
      "0.644692\n",
      "0.60974\n",
      "0.576754\n",
      "0.545594\n",
      "0.516099\n",
      "0.488209\n",
      "0.461893\n",
      "0.43696\n",
      "0.413468\n",
      "0.391234\n",
      "0.370196\n",
      "0.350327\n",
      "0.331472\n",
      "0.313703\n",
      "0.296938\n",
      "0.280971\n",
      "0.265907\n",
      "0.251627\n",
      "0.238182\n",
      "0.225414\n",
      "0.213448\n",
      "0.202032\n",
      "0.191275\n",
      "0.181072\n",
      "0.171451\n",
      "0.162353\n",
      "0.153638\n",
      "0.145451\n",
      "0.137726\n",
      "0.130417\n",
      "0.123463\n",
      "0.116944\n",
      "0.110717\n",
      "0.104895\n",
      "0.0993391\n",
      "0.0940855\n",
      "0.0890843\n",
      "0.0843773\n",
      "0.0799091\n",
      "0.0756703\n",
      "0.0716902\n",
      "0.067897\n",
      "0.0643367\n",
      "0.0609867\n",
      "0.0577768\n",
      "0.0547308\n",
      "0.0518368\n",
      "0.0491114\n",
      "0.0465478\n",
      "0.0440929\n",
      "0.0417866\n",
      "0.0395934\n",
      "0.0375099\n",
      "0.0355544\n",
      "0.0337097\n",
      "0.031955\n",
      "0.0302817\n",
      "0.028702\n",
      "0.027215\n",
      "0.0257924\n",
      "0.0244606\n",
      "0.0231707\n",
      "0.0219767\n",
      "0.0208224\n",
      "0.0197537\n",
      "0.0187333\n",
      "0.0177735\n",
      "0.0168755\n",
      "0.0160056\n",
      "0.0151824\n",
      "0.0144024\n",
      "0.0136605\n",
      "0.0129593\n",
      "0.0122936\n",
      "0.0116669\n",
      "0.0110735\n",
      "0.0105211\n",
      "0.00998708\n",
      "0.00948966\n",
      "0.00900479\n",
      "0.00855539\n",
      "0.00812275\n",
      "0.00771356\n",
      "0.00732939\n",
      "0.00696217\n",
      "0.00661626\n",
      "0.00629408\n",
      "0.00598164\n",
      "0.0056877\n",
      "0.00541309\n",
      "0.00515031\n",
      "0.00489934\n",
      "0.0046614\n",
      "0.00442948\n",
      "0.00422137\n",
      "0.00401685\n",
      "0.00382146\n",
      "0.00364099\n",
      "0.00347143\n",
      "0.00330932\n",
      "0.00315232\n",
      "0.00300968\n",
      "0.00286831\n",
      "0.00273187\n",
      "0.00260962\n",
      "0.00248813\n",
      "0.00237697\n",
      "0.00226897\n",
      "0.00216778\n",
      "0.00207175\n",
      "0.00198195\n",
      "0.00189591\n",
      "0.00181199\n",
      "0.00173349\n",
      "0.00165958\n",
      "0.00158906\n",
      "0.00152149\n",
      "0.00145517\n",
      "0.00139518\n",
      "0.00133937\n",
      "0.00128238\n",
      "0.00123148\n",
      "0.00117999\n",
      "0.00113307\n",
      "0.00108904\n",
      "0.00104545\n",
      "0.00100716\n",
      "0.000968565\n",
      "0.000931827\n",
      "0.000897567\n",
      "0.000864355\n",
      "0.000830318\n",
      "0.000800655\n",
      "0.000769655\n",
      "0.000742509\n",
      "0.000714523\n",
      "0.000690081\n",
      "0.000665216\n",
      "0.000642831\n",
      "0.000619489\n",
      "0.000598375\n",
      "0.000577028\n",
      "0.000558029\n",
      "0.00053879\n",
      "0.000520886\n",
      "0.000503495\n",
      "0.000487283\n",
      "0.000472302\n",
      "0.000458118\n",
      "0.000442435\n",
      "0.000428605\n",
      "0.000414183\n",
      "0.000401687\n",
      "0.000390041\n",
      "0.000378037\n",
      "0.0003663\n",
      "0.000355108\n",
      "0.000345478\n",
      "0.000336127\n",
      "0.000326354\n",
      "0.000317154\n",
      "0.000308117\n",
      "0.00029938\n",
      "0.000291407\n",
      "0.000282279\n",
      "0.000274396\n",
      "0.000267452\n",
      "0.00025909\n",
      "0.000251738\n",
      "0.000245623\n",
      "0.000238887\n",
      "0.000233085\n",
      "0.000226897\n",
      "0.000221098\n",
      "0.000215435\n",
      "0.000209925\n",
      "0.000204189\n",
      "0.000199632\n",
      "0.000195021\n",
      "0.000190566\n",
      "0.000185227\n",
      "0.000180845\n",
      "0.000177067\n",
      "0.000173184\n",
      "0.000168328\n",
      "0.000164261\n",
      "0.000161548\n",
      "0.000157264\n",
      "0.000153602\n",
      "0.0001503\n",
      "0.000147295\n",
      "0.000143953\n",
      "0.000140564\n",
      "0.000137817\n",
      "0.000134873\n",
      "0.000132029\n",
      "0.000129493\n",
      "0.000126273\n",
      "0.000123517\n",
      "0.000121179\n",
      "0.000118501\n",
      "0.000116263\n",
      "0.00011393\n",
      "0.000111941\n",
      "0.000109711\n",
      "0.000107577\n",
      "0.000105153\n",
      "0.000103163\n",
      "0.000101521\n",
      "9.95374e-05\n",
      "9.75806e-05\n",
      "9.585e-05\n",
      "9.41584e-05\n",
      "9.27303e-05\n",
      "9.10607e-05\n",
      "8.90954e-05\n",
      "8.7738e-05\n",
      "8.5914e-05\n",
      "8.44785e-05\n",
      "8.29438e-05\n",
      "8.15367e-05\n",
      "7.98906e-05\n",
      "7.87556e-05\n",
      "7.73946e-05\n",
      "7.61706e-05\n",
      "7.50964e-05\n",
      "7.41484e-05\n",
      "7.27953e-05\n",
      "7.17504e-05\n",
      "7.05915e-05\n",
      "6.96174e-05\n",
      "6.86353e-05\n",
      "6.74439e-05\n",
      "6.65562e-05\n",
      "6.52432e-05\n",
      "6.42134e-05\n",
      "6.32382e-05\n",
      "6.22432e-05\n",
      "6.14017e-05\n",
      "6.06248e-05\n",
      "5.98975e-05\n",
      "5.89928e-05\n",
      "5.80031e-05\n",
      "5.71943e-05\n",
      "5.65718e-05\n",
      "5.56963e-05\n",
      "5.5081e-05\n",
      "5.4326e-05\n",
      "5.36611e-05\n",
      "5.29471e-05\n",
      "5.22147e-05\n",
      "5.13062e-05\n",
      "5.07597e-05\n",
      "5.00776e-05\n",
      "4.93185e-05\n",
      "4.88241e-05\n",
      "4.8201e-05\n",
      "4.76528e-05\n",
      "4.70626e-05\n",
      "4.62372e-05\n",
      "4.58866e-05\n",
      "4.52045e-05\n",
      "4.45263e-05\n",
      "4.40578e-05\n",
      "4.34048e-05\n",
      "4.27211e-05\n",
      "4.20779e-05\n",
      "4.16514e-05\n",
      "4.11006e-05\n",
      "4.0441e-05\n",
      "4.00894e-05\n",
      "3.96065e-05\n",
      "3.89673e-05\n",
      "3.87035e-05\n",
      "3.81167e-05\n",
      "3.76706e-05\n",
      "3.72927e-05\n",
      "3.68601e-05\n",
      "3.62543e-05\n",
      "3.59023e-05\n",
      "3.53379e-05\n",
      "3.50276e-05\n",
      "3.46992e-05\n",
      "3.43789e-05\n",
      "3.40146e-05\n",
      "3.34775e-05\n",
      "3.31923e-05\n",
      "3.29803e-05\n",
      "3.26863e-05\n",
      "3.22122e-05\n",
      "3.19086e-05\n",
      "3.16328e-05\n",
      "3.12307e-05\n",
      "3.07908e-05\n",
      "3.05192e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# First we set up the computational graph:\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "# Create placeholders for the input and target data; these will be filled\n",
    "# with real data when we execute the graph.\n",
    "x = tf.placeholder(tf.float32, shape=(None, D_in))\n",
    "y = tf.placeholder(tf.float32, shape=(None, D_out))\n",
    "\n",
    "# Create Variables for the weights and initialize them with random data.\n",
    "# A TensorFlow Variable persists its value across executions of the graph.\n",
    "w1 = tf.Variable(tf.random_normal((D_in, H)))\n",
    "w2 = tf.Variable(tf.random_normal((H, D_out)))\n",
    "\n",
    "# Forward pass: Compute the predicted y using operations on TensorFlow Tensors.\n",
    "# Note that this code does not actually perform any numeric operations; it\n",
    "# merely sets up the computational graph that we will later execute.\n",
    "h = tf.matmul(x, w1)\n",
    "h_relu = tf.maximum(h, tf.zeros(1))\n",
    "y_pred = tf.matmul(h_relu, w2)\n",
    "\n",
    "# Compute loss using operations on TensorFlow Tensors\n",
    "loss = tf.reduce_sum((y - y_pred) ** 2.0)\n",
    "\n",
    "# Compute gradient of the loss with respect to w1 and w2.\n",
    "grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n",
    "\n",
    "# Update the weights using gradient descent. To actually update the weights\n",
    "# we need to evaluate new_w1 and new_w2 when executing the graph. Note that\n",
    "# in TensorFlow the the act of updating the value of the weights is part of\n",
    "# the computational graph; in PyTorch this happens outside the computational\n",
    "# graph.\n",
    "learning_rate = 1e-6\n",
    "new_w1 = w1.assign(w1 - learning_rate * grad_w1)\n",
    "new_w2 = w2.assign(w2 - learning_rate * grad_w2)\n",
    "\n",
    "# Now we have built our computational graph, so we enter a TensorFlow session to\n",
    "# actually execute the graph.\n",
    "with tf.Session() as sess:\n",
    "    # Run the graph once to initialize the Variables w1 and w2.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create numpy arrays holding the actual data for the inputs x and targets\n",
    "    # y\n",
    "    x_value = np.random.randn(N, D_in)\n",
    "    y_value = np.random.randn(N, D_out)\n",
    "    for _ in range(500):\n",
    "        # Execute the graph many times. Each time it executes we want to bind\n",
    "        # x_value to x and y_value to y, specified with the feed_dict argument.\n",
    "        # Each time we execute the graph we want to compute the values for loss,\n",
    "        # new_w1, and new_w2; the values of these Tensors are returned as numpy\n",
    "        # arrays.\n",
    "        loss_value, _, _ = sess.run([loss, new_w1, new_w2],\n",
    "                                    feed_dict={x: x_value, y: y_value})\n",
    "        print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 688.768310546875\n",
      "1 634.3409423828125\n",
      "2 588.1471557617188\n",
      "3 547.951171875\n",
      "4 512.3643798828125\n",
      "5 480.7498474121094\n",
      "6 451.8994140625\n",
      "7 425.6877136230469\n",
      "8 401.72412109375\n",
      "9 379.54473876953125\n",
      "10 358.8777770996094\n",
      "11 339.56378173828125\n",
      "12 321.5136413574219\n",
      "13 304.54400634765625\n",
      "14 288.6012878417969\n",
      "15 273.59112548828125\n",
      "16 259.44317626953125\n",
      "17 246.0689697265625\n",
      "18 233.38198852539062\n",
      "19 221.22227478027344\n",
      "20 209.622802734375\n",
      "21 198.58499145507812\n",
      "22 188.07989501953125\n",
      "23 178.08340454101562\n",
      "24 168.60147094726562\n",
      "25 159.53439331054688\n",
      "26 150.9268798828125\n",
      "27 142.74002075195312\n",
      "28 134.9234161376953\n",
      "29 127.50122833251953\n",
      "30 120.46525573730469\n",
      "31 113.80619812011719\n",
      "32 107.51043701171875\n",
      "33 101.54353332519531\n",
      "34 95.87861633300781\n",
      "35 90.52456665039062\n",
      "36 85.46832275390625\n",
      "37 80.68843078613281\n",
      "38 76.17933654785156\n",
      "39 71.929443359375\n",
      "40 67.91213989257812\n",
      "41 64.12391662597656\n",
      "42 60.553321838378906\n",
      "43 57.185333251953125\n",
      "44 54.00910949707031\n",
      "45 51.0123291015625\n",
      "46 48.1849479675293\n",
      "47 45.519996643066406\n",
      "48 43.013824462890625\n",
      "49 40.64952087402344\n",
      "50 38.42151641845703\n",
      "51 36.31732940673828\n",
      "52 34.333675384521484\n",
      "53 32.46540832519531\n",
      "54 30.7032413482666\n",
      "55 29.04277801513672\n",
      "56 27.477127075195312\n",
      "57 26.003082275390625\n",
      "58 24.611557006835938\n",
      "59 23.297645568847656\n",
      "60 22.06039810180664\n",
      "61 20.89223861694336\n",
      "62 19.789913177490234\n",
      "63 18.749736785888672\n",
      "64 17.76923942565918\n",
      "65 16.844165802001953\n",
      "66 15.970271110534668\n",
      "67 15.145633697509766\n",
      "68 14.368001937866211\n",
      "69 13.63217544555664\n",
      "70 12.937139511108398\n",
      "71 12.279901504516602\n",
      "72 11.658639907836914\n",
      "73 11.07187271118164\n",
      "74 10.517745018005371\n",
      "75 9.994401931762695\n",
      "76 9.499300956726074\n",
      "77 9.030993461608887\n",
      "78 8.587099075317383\n",
      "79 8.167238235473633\n",
      "80 7.769686698913574\n",
      "81 7.394021511077881\n",
      "82 7.038824081420898\n",
      "83 6.702510833740234\n",
      "84 6.383878707885742\n",
      "85 6.081945419311523\n",
      "86 5.795651912689209\n",
      "87 5.5241780281066895\n",
      "88 5.267014026641846\n",
      "89 5.022539138793945\n",
      "90 4.790360450744629\n",
      "91 4.570357322692871\n",
      "92 4.362112522125244\n",
      "93 4.164496421813965\n",
      "94 3.9766147136688232\n",
      "95 3.7988104820251465\n",
      "96 3.6297945976257324\n",
      "97 3.4690988063812256\n",
      "98 3.316457986831665\n",
      "99 3.1712465286254883\n",
      "100 3.0329833030700684\n",
      "101 2.9011330604553223\n",
      "102 2.7756848335266113\n",
      "103 2.656339645385742\n",
      "104 2.5426247119903564\n",
      "105 2.4343204498291016\n",
      "106 2.3310203552246094\n",
      "107 2.232574701309204\n",
      "108 2.1387438774108887\n",
      "109 2.049372673034668\n",
      "110 1.9638445377349854\n",
      "111 1.882226824760437\n",
      "112 1.8042945861816406\n",
      "113 1.7299689054489136\n",
      "114 1.6591253280639648\n",
      "115 1.5912201404571533\n",
      "116 1.5263502597808838\n",
      "117 1.464289665222168\n",
      "118 1.4049482345581055\n",
      "119 1.3482362031936646\n",
      "120 1.2939696311950684\n",
      "121 1.242040991783142\n",
      "122 1.1923441886901855\n",
      "123 1.1447877883911133\n",
      "124 1.0992889404296875\n",
      "125 1.0557482242584229\n",
      "126 1.013999581336975\n",
      "127 0.9740887880325317\n",
      "128 0.9359352588653564\n",
      "129 0.8993499279022217\n",
      "130 0.8642939925193787\n",
      "131 0.8306999206542969\n",
      "132 0.7985177040100098\n",
      "133 0.7677076458930969\n",
      "134 0.7381502389907837\n",
      "135 0.7097913026809692\n",
      "136 0.6826049089431763\n",
      "137 0.6565297842025757\n",
      "138 0.6315218806266785\n",
      "139 0.607501208782196\n",
      "140 0.5845032930374146\n",
      "141 0.5624544620513916\n",
      "142 0.5413566827774048\n",
      "143 0.521109402179718\n",
      "144 0.5016565918922424\n",
      "145 0.482980340719223\n",
      "146 0.4650458097457886\n",
      "147 0.44781196117401123\n",
      "148 0.431262344121933\n",
      "149 0.41537123918533325\n",
      "150 0.40009814500808716\n",
      "151 0.3854246735572815\n",
      "152 0.371329128742218\n",
      "153 0.357780396938324\n",
      "154 0.34475407004356384\n",
      "155 0.3322373628616333\n",
      "156 0.3201967179775238\n",
      "157 0.3086113929748535\n",
      "158 0.2974697947502136\n",
      "159 0.28676509857177734\n",
      "160 0.2764628529548645\n",
      "161 0.2665656805038452\n",
      "162 0.2570212781429291\n",
      "163 0.24784322082996368\n",
      "164 0.23902583122253418\n",
      "165 0.23053888976573944\n",
      "166 0.22235848009586334\n",
      "167 0.21448299288749695\n",
      "168 0.20689722895622253\n",
      "169 0.19959720969200134\n",
      "170 0.19257092475891113\n",
      "171 0.18581481277942657\n",
      "172 0.17930367588996887\n",
      "173 0.17302943766117096\n",
      "174 0.16697514057159424\n",
      "175 0.1611492931842804\n",
      "176 0.1555350124835968\n",
      "177 0.1501237154006958\n",
      "178 0.14490815997123718\n",
      "179 0.13988097012043\n",
      "180 0.13503466546535492\n",
      "181 0.13037145137786865\n",
      "182 0.1258755326271057\n",
      "183 0.1215398758649826\n",
      "184 0.11735942959785461\n",
      "185 0.11332898586988449\n",
      "186 0.10944347083568573\n",
      "187 0.10569682717323303\n",
      "188 0.10208696126937866\n",
      "189 0.09860461950302124\n",
      "190 0.09524606168270111\n",
      "191 0.09200876951217651\n",
      "192 0.0888843983411789\n",
      "193 0.0858721137046814\n",
      "194 0.0829634815454483\n",
      "195 0.08015933632850647\n",
      "196 0.07745106518268585\n",
      "197 0.07483842968940735\n",
      "198 0.0723198801279068\n",
      "199 0.06989143043756485\n",
      "200 0.06754466891288757\n",
      "201 0.065279021859169\n",
      "202 0.06309346854686737\n",
      "203 0.06098351627588272\n",
      "204 0.058948829770088196\n",
      "205 0.05698316916823387\n",
      "206 0.055084340274333954\n",
      "207 0.053251370787620544\n",
      "208 0.05148138850927353\n",
      "209 0.04977326840162277\n",
      "210 0.048125702887773514\n",
      "211 0.046533964574337006\n",
      "212 0.044997163116931915\n",
      "213 0.043513379991054535\n",
      "214 0.04207983613014221\n",
      "215 0.04069589078426361\n",
      "216 0.03935915604233742\n",
      "217 0.03806755691766739\n",
      "218 0.03681990131735802\n",
      "219 0.035614676773548126\n",
      "220 0.034450285136699677\n",
      "221 0.03332554176449776\n",
      "222 0.03223808482289314\n",
      "223 0.03118840977549553\n",
      "224 0.03017478436231613\n",
      "225 0.029195033013820648\n",
      "226 0.028247656300663948\n",
      "227 0.027331333607435226\n",
      "228 0.02644588239490986\n",
      "229 0.02559029683470726\n",
      "230 0.02476346865296364\n",
      "231 0.0239639300853014\n",
      "232 0.023190943524241447\n",
      "233 0.022443613037467003\n",
      "234 0.02172086574137211\n",
      "235 0.02102266252040863\n",
      "236 0.02034721150994301\n",
      "237 0.019694674760103226\n",
      "238 0.019063176587224007\n",
      "239 0.01845233328640461\n",
      "240 0.017861953005194664\n",
      "241 0.017291072756052017\n",
      "242 0.016739370301365852\n",
      "243 0.01620539464056492\n",
      "244 0.015689002349972725\n",
      "245 0.01518961414694786\n",
      "246 0.014706311747431755\n",
      "247 0.01423892192542553\n",
      "248 0.013786903582513332\n",
      "249 0.013349419459700584\n",
      "250 0.012926971539855003\n",
      "251 0.012517653405666351\n",
      "252 0.012121678330004215\n",
      "253 0.01173875667154789\n",
      "254 0.011368071660399437\n",
      "255 0.011009277775883675\n",
      "256 0.010662142187356949\n",
      "257 0.010326171293854713\n",
      "258 0.01000107079744339\n",
      "259 0.009686829522252083\n",
      "260 0.009382476098835468\n",
      "261 0.009087735787034035\n",
      "262 0.008802641183137894\n",
      "263 0.008526738733053207\n",
      "264 0.00825961772352457\n",
      "265 0.008004824630916119\n",
      "266 0.007759891916066408\n",
      "267 0.007522800471633673\n",
      "268 0.00729319266974926\n",
      "269 0.007070785854011774\n",
      "270 0.006855513900518417\n",
      "271 0.006646857596933842\n",
      "272 0.006444862112402916\n",
      "273 0.006249303929507732\n",
      "274 0.006059797015041113\n",
      "275 0.005876266397535801\n",
      "276 0.005698373541235924\n",
      "277 0.005526270251721144\n",
      "278 0.00535944988951087\n",
      "279 0.005197822116315365\n",
      "280 0.0050412192940711975\n",
      "281 0.0048894574865698814\n",
      "282 0.004742387682199478\n",
      "283 0.004599900916218758\n",
      "284 0.004461843054741621\n",
      "285 0.004328103736042976\n",
      "286 0.0041984571143984795\n",
      "287 0.004072863608598709\n",
      "288 0.003951156511902809\n",
      "289 0.0038331295363605022\n",
      "290 0.0037187677808105946\n",
      "291 0.003607897087931633\n",
      "292 0.0035004708915948868\n",
      "293 0.00339645822532475\n",
      "294 0.0032955463975667953\n",
      "295 0.0031976718455553055\n",
      "296 0.0031028538942337036\n",
      "297 0.003010888583958149\n",
      "298 0.0029216937255114317\n",
      "299 0.0028352385852485895\n",
      "300 0.0027514593675732613\n",
      "301 0.002670199843123555\n",
      "302 0.002591505413874984\n",
      "303 0.002515144180506468\n",
      "304 0.0024411133490502834\n",
      "305 0.002369378926232457\n",
      "306 0.0022997320629656315\n",
      "307 0.002232165075838566\n",
      "308 0.0021666353568434715\n",
      "309 0.0021030642092227936\n",
      "310 0.002041494706645608\n",
      "311 0.0019817387219518423\n",
      "312 0.001923781936056912\n",
      "313 0.0018675189930945635\n",
      "314 0.00181295583024621\n",
      "315 0.0017600624123588204\n",
      "316 0.0017087211599573493\n",
      "317 0.0016589660663157701\n",
      "318 0.0016106875846162438\n",
      "319 0.0015638221520930529\n",
      "320 0.0015183878131210804\n",
      "321 0.0014742804924026132\n",
      "322 0.001431499607861042\n",
      "323 0.0013899871846660972\n",
      "324 0.0013497043401002884\n",
      "325 0.0013106373371556401\n",
      "326 0.0012727277353405952\n",
      "327 0.0012359335087239742\n",
      "328 0.001200237893499434\n",
      "329 0.0011655786074697971\n",
      "330 0.001131970202550292\n",
      "331 0.0010993338655680418\n",
      "332 0.001067677978426218\n",
      "333 0.0010369925294071436\n",
      "334 0.001007172977551818\n",
      "335 0.0009782088454812765\n",
      "336 0.0009501234744675457\n",
      "337 0.000922869541682303\n",
      "338 0.0008964041480794549\n",
      "339 0.0008707123924978077\n",
      "340 0.0008457666262984276\n",
      "341 0.0008215614361688495\n",
      "342 0.0007980735972523689\n",
      "343 0.0007752664969302714\n",
      "344 0.0007531262817792594\n",
      "345 0.0007316245464608073\n",
      "346 0.0007107511046342552\n",
      "347 0.0006905058398842812\n",
      "348 0.0006708338623866439\n",
      "349 0.0006517372676171362\n",
      "350 0.0006331972545012832\n",
      "351 0.0006152071291580796\n",
      "352 0.0005977379623800516\n",
      "353 0.0005807781126350164\n",
      "354 0.0005643080221489072\n",
      "355 0.0005483095301315188\n",
      "356 0.00053276342805475\n",
      "357 0.0005176756531000137\n",
      "358 0.0005030173342674971\n",
      "359 0.0004887924296781421\n",
      "360 0.000474978587590158\n",
      "361 0.0004615653306245804\n",
      "362 0.0004485334502533078\n",
      "363 0.0004358743317425251\n",
      "364 0.00042357706115581095\n",
      "365 0.00041163997957482934\n",
      "366 0.00040005147457122803\n",
      "367 0.00038880406646057963\n",
      "368 0.00037787010660395026\n",
      "369 0.0003672439488582313\n",
      "370 0.0003569243708625436\n",
      "371 0.00034689775202423334\n",
      "372 0.00033715798053890467\n",
      "373 0.0003277044743299484\n",
      "374 0.0003185098175890744\n",
      "375 0.00030959153082221746\n",
      "376 0.00030091922963038087\n",
      "377 0.00029249483486637473\n",
      "378 0.000284314010059461\n",
      "379 0.00027637151652015746\n",
      "380 0.0002686410443857312\n",
      "381 0.00026113807689398527\n",
      "382 0.0002538480912335217\n",
      "383 0.0002467682643327862\n",
      "384 0.00023988806060515344\n",
      "385 0.0002331991126993671\n",
      "386 0.00022670504404231906\n",
      "387 0.00022039408213458955\n",
      "388 0.0002142727025784552\n",
      "389 0.0002083260624203831\n",
      "390 0.00020255189156159759\n",
      "391 0.00019693630747497082\n",
      "392 0.00019147529383189976\n",
      "393 0.00018617260502651334\n",
      "394 0.00018101926252711564\n",
      "395 0.0001760133309289813\n",
      "396 0.00017114711226895452\n",
      "397 0.00016641768161207438\n",
      "398 0.00016182141553144902\n",
      "399 0.00015735384658910334\n",
      "400 0.00015301417442969978\n",
      "401 0.0001487937697675079\n",
      "402 0.00014469695452135056\n",
      "403 0.00014070747420191765\n",
      "404 0.00013683378347195685\n",
      "405 0.00013306450273375958\n",
      "406 0.00012940489978063852\n",
      "407 0.00012585011427290738\n",
      "408 0.0001223917060997337\n",
      "409 0.00011902769620064646\n",
      "410 0.00011576239194255322\n",
      "411 0.00011258438462391496\n",
      "412 0.00010949501302093267\n",
      "413 0.00010649488103808835\n",
      "414 0.0001035782479448244\n",
      "415 0.00010074178862851113\n",
      "416 9.798212704481557e-05\n",
      "417 9.53007911448367e-05\n",
      "418 9.269269503420219e-05\n",
      "419 9.015799878397956e-05\n",
      "420 8.769432315602899e-05\n",
      "421 8.529845217708498e-05\n",
      "422 8.296631131088361e-05\n",
      "423 8.070233889156953e-05\n",
      "424 7.850128167774528e-05\n",
      "425 7.635936344740912e-05\n",
      "426 7.427739910781384e-05\n",
      "427 7.225590525195003e-05\n",
      "428 7.02859615557827e-05\n",
      "429 6.837177352281287e-05\n",
      "430 6.65125553496182e-05\n",
      "431 6.470208609243855e-05\n",
      "432 6.294128979789093e-05\n",
      "433 6.123053026385605e-05\n",
      "434 5.9568443248281255e-05\n",
      "435 5.795068136649206e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436 5.6377244618488476e-05\n",
      "437 5.484482244355604e-05\n",
      "438 5.335819878382608e-05\n",
      "439 5.1910086767748e-05\n",
      "440 5.050359322922304e-05\n",
      "441 4.913658631267026e-05\n",
      "442 4.7803270717849955e-05\n",
      "443 4.650843038689345e-05\n",
      "444 4.525059921434149e-05\n",
      "445 4.402386548463255e-05\n",
      "446 4.283379530534148e-05\n",
      "447 4.167429869994521e-05\n",
      "448 4.0546670788899064e-05\n",
      "449 3.9453618228435516e-05\n",
      "450 3.838668635580689e-05\n",
      "451 3.734987330972217e-05\n",
      "452 3.6342080420581624e-05\n",
      "453 3.536090662237257e-05\n",
      "454 3.440622458583675e-05\n",
      "455 3.3478754630777985e-05\n",
      "456 3.257756179664284e-05\n",
      "457 3.16983278025873e-05\n",
      "458 3.0844581488054246e-05\n",
      "459 3.0013594368938357e-05\n",
      "460 2.9204755264800042e-05\n",
      "461 2.8419835871318355e-05\n",
      "462 2.7655592930386774e-05\n",
      "463 2.691131885512732e-05\n",
      "464 2.6187557523371652e-05\n",
      "465 2.548459087847732e-05\n",
      "466 2.4799081074888818e-05\n",
      "467 2.4132838007062674e-05\n",
      "468 2.3485761630581692e-05\n",
      "469 2.2855740098748356e-05\n",
      "470 2.224159106845036e-05\n",
      "471 2.164450052077882e-05\n",
      "472 2.1063957319711335e-05\n",
      "473 2.0500036043813452e-05\n",
      "474 1.9949446141254157e-05\n",
      "475 1.9415330825722776e-05\n",
      "476 1.8895769244409166e-05\n",
      "477 1.8390182958683e-05\n",
      "478 1.7897524230647832e-05\n",
      "479 1.7418398783775046e-05\n",
      "480 1.6953024896793067e-05\n",
      "481 1.649915793677792e-05\n",
      "482 1.605850411579013e-05\n",
      "483 1.5628689652658068e-05\n",
      "484 1.5210877791105304e-05\n",
      "485 1.4804668353463057e-05\n",
      "486 1.4409081813937519e-05\n",
      "487 1.4024469237483572e-05\n",
      "488 1.3650782420882024e-05\n",
      "489 1.328619327978231e-05\n",
      "490 1.2931272067362443e-05\n",
      "491 1.2587437595357187e-05\n",
      "492 1.2251111911609769e-05\n",
      "493 1.192510717373807e-05\n",
      "494 1.160634019470308e-05\n",
      "495 1.1296831871732138e-05\n",
      "496 1.0996661330864299e-05\n",
      "497 1.0703288353397511e-05\n",
      "498 1.0418045349069871e-05\n",
      "499 1.0140951417270117e-05\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype))\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. Each Linear Module computes output from input using a\n",
    "# linear function, and holds internal Variables for its weight and bias.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H).type(dtype),\n",
    "    torch.nn.ReLU().type(dtype),\n",
    "    torch.nn.Linear(H, D_out).type(dtype),\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Variable of input data to the Module and it produces\n",
    "    # a Variable of output data.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss. We pass Variables containing the predicted and true\n",
    "    # values of y, and the loss function returns a Variable containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Variables with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Variable, so\n",
    "    # we can access its data and gradients like we did before.\n",
    "    for param in model.parameters():\n",
    "        param.data -= learning_rate * param.grad.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 700.1295166015625\n",
      "1 1462.2896728515625\n",
      "2 430.818359375\n",
      "3 184.82394409179688\n",
      "4 417.3115539550781\n",
      "5 355.7149658203125\n",
      "6 166.05194091796875\n",
      "7 80.34666442871094\n",
      "8 111.40391540527344\n",
      "9 156.47450256347656\n",
      "10 149.40567016601562\n",
      "11 106.1256103515625\n",
      "12 69.86040496826172\n",
      "13 59.00864028930664\n",
      "14 63.316280364990234\n",
      "15 64.71348571777344\n",
      "16 56.688751220703125\n",
      "17 45.67634963989258\n",
      "18 38.86406326293945\n",
      "19 37.21964645385742\n",
      "20 36.668907165527344\n",
      "21 33.295650482177734\n",
      "22 27.216564178466797\n",
      "23 21.251148223876953\n",
      "24 18.17379379272461\n",
      "25 18.404067993164062\n",
      "26 19.738988876342773\n",
      "27 19.45221519470215\n",
      "28 16.45364761352539\n",
      "29 12.150310516357422\n",
      "30 9.208830833435059\n",
      "31 8.907902717590332\n",
      "32 9.873128890991211\n",
      "33 10.034008979797363\n",
      "34 8.746550559997559\n",
      "35 6.918580055236816\n",
      "36 5.794905185699463\n",
      "37 5.5052289962768555\n",
      "38 5.342265605926514\n",
      "39 4.899595260620117\n",
      "40 4.282815933227539\n",
      "41 3.7543773651123047\n",
      "42 3.447333812713623\n",
      "43 3.224381923675537\n",
      "44 2.940765857696533\n",
      "45 2.5973777770996094\n",
      "46 2.270620107650757\n",
      "47 2.039142370223999\n",
      "48 1.891257405281067\n",
      "49 1.7708712816238403\n",
      "50 1.6318325996398926\n",
      "51 1.4404823780059814\n",
      "52 1.2349917888641357\n",
      "53 1.0923529863357544\n",
      "54 1.0333706140518188\n",
      "55 0.987835168838501\n",
      "56 0.8774600028991699\n",
      "57 0.7649149894714355\n",
      "58 0.6986620426177979\n",
      "59 0.618542492389679\n",
      "60 0.543836772441864\n",
      "61 0.5211668014526367\n",
      "62 0.5031285285949707\n",
      "63 0.43969619274139404\n",
      "64 0.3514323830604553\n",
      "65 0.3092882037162781\n",
      "66 0.31465041637420654\n",
      "67 0.30728766322135925\n",
      "68 0.2702663242816925\n",
      "69 0.22889862954616547\n",
      "70 0.19771379232406616\n",
      "71 0.17226730287075043\n",
      "72 0.1584610491991043\n",
      "73 0.16026948392391205\n",
      "74 0.15855686366558075\n",
      "75 0.13354624807834625\n",
      "76 0.09910144656896591\n",
      "77 0.08752848207950592\n",
      "78 0.09448728710412979\n",
      "79 0.09211548417806625\n",
      "80 0.07652077078819275\n",
      "81 0.06551648676395416\n",
      "82 0.06176023930311203\n",
      "83 0.05584113672375679\n",
      "84 0.04749087244272232\n",
      "85 0.04210701584815979\n",
      "86 0.04236231744289398\n",
      "87 0.04153687134385109\n",
      "88 0.03441927954554558\n",
      "89 0.026404574513435364\n",
      "90 0.023717619478702545\n",
      "91 0.025040514767169952\n",
      "92 0.02542148530483246\n",
      "93 0.02199431136250496\n",
      "94 0.01608680561184883\n",
      "95 0.013272401876747608\n",
      "96 0.015017193742096424\n",
      "97 0.01569024845957756\n",
      "98 0.012543807737529278\n",
      "99 0.009520260617136955\n",
      "100 0.00891629233956337\n",
      "101 0.00906253233551979\n",
      "102 0.008515728637576103\n",
      "103 0.00725159514695406\n",
      "104 0.006276275962591171\n",
      "105 0.0059387097135186195\n",
      "106 0.0053722066804766655\n",
      "107 0.0043898532167077065\n",
      "108 0.004029326606541872\n",
      "109 0.004162459634244442\n",
      "110 0.003917197231203318\n",
      "111 0.003127493429929018\n",
      "112 0.0025205668061971664\n",
      "113 0.002420461969450116\n",
      "114 0.002449573250487447\n",
      "115 0.0022460944019258022\n",
      "116 0.0018848244799301028\n",
      "117 0.0015910223592072725\n",
      "118 0.0014927322044968605\n",
      "119 0.0015041532460600138\n",
      "120 0.0013337775599211454\n",
      "121 0.0010199457174167037\n",
      "122 0.000922356266528368\n",
      "123 0.0009537608129903674\n",
      "124 0.0009193678852170706\n",
      "125 0.0007774179102852941\n",
      "126 0.0006253579631447792\n",
      "127 0.0005751318531110883\n",
      "128 0.0005772761069238186\n",
      "129 0.0005032816552557051\n",
      "130 0.0004166131839156151\n",
      "131 0.00040600597276352346\n",
      "132 0.0004026287642773241\n",
      "133 0.0003385637537576258\n",
      "134 0.0002677260781638324\n",
      "135 0.00024549340014345944\n",
      "136 0.0002604843466542661\n",
      "137 0.00023639510618522763\n",
      "138 0.00017698618466965854\n",
      "139 0.000164089840836823\n",
      "140 0.00018446495232637972\n",
      "141 0.00015705842815805227\n",
      "142 0.00010739195568021387\n",
      "143 0.00010268004552926868\n",
      "144 0.00012041458103340119\n",
      "145 0.00010559923975961283\n",
      "146 8.058835373958573e-05\n",
      "147 7.161032408475876e-05\n",
      "148 7.106802513590083e-05\n",
      "149 6.946254143258557e-05\n",
      "150 5.7802721130428836e-05\n",
      "151 4.3130443373229355e-05\n",
      "152 4.303614696254954e-05\n",
      "153 4.9333746574120596e-05\n",
      "154 4.208479731460102e-05\n",
      "155 3.050724626518786e-05\n",
      "156 2.8544704036903568e-05\n",
      "157 2.6994257495971397e-05\n",
      "158 2.3900889573269524e-05\n",
      "159 2.400222911091987e-05\n",
      "160 2.2553951566806063e-05\n",
      "161 1.811264519346878e-05\n",
      "162 1.548662294226233e-05\n",
      "163 1.4296772860689089e-05\n",
      "164 1.2467027772800066e-05\n",
      "165 1.237103970197495e-05\n",
      "166 1.23797854030272e-05\n",
      "167 9.993317689804826e-06\n",
      "168 8.384113243664615e-06\n",
      "169 7.917913535493426e-06\n",
      "170 6.7572664192994125e-06\n",
      "171 6.18588137513143e-06\n",
      "172 6.464745638368186e-06\n",
      "173 5.804503416584339e-06\n",
      "174 4.4930202420800924e-06\n",
      "175 4.0054683267953806e-06\n",
      "176 3.902113348885905e-06\n",
      "177 3.510227315928205e-06\n",
      "178 3.215044671378564e-06\n",
      "179 2.9063207875879016e-06\n",
      "180 2.438125193293672e-06\n",
      "181 2.348100451854407e-06\n",
      "182 2.2899898795003537e-06\n",
      "183 1.7927043245435925e-06\n",
      "184 1.4890557622493361e-06\n",
      "185 1.5526286460953997e-06\n",
      "186 1.5330259657275747e-06\n",
      "187 1.2158761819591746e-06\n",
      "188 1.0570711310720071e-06\n",
      "189 1.1387202221158077e-06\n",
      "190 9.233234550265479e-07\n",
      "191 6.047429792488401e-07\n",
      "192 6.990475185375544e-07\n",
      "193 8.811958878141013e-07\n",
      "194 6.995385319896741e-07\n",
      "195 4.116595277992019e-07\n",
      "196 3.771905028315814e-07\n",
      "197 5.027235374654992e-07\n",
      "198 4.576808407819044e-07\n",
      "199 3.3585951086934074e-07\n",
      "200 3.2346304124075687e-07\n",
      "201 3.165488067224942e-07\n",
      "202 2.30073709417411e-07\n",
      "203 2.2258851117840095e-07\n",
      "204 2.474662323947996e-07\n",
      "205 2.030814982845186e-07\n",
      "206 1.7050335543444817e-07\n",
      "207 1.9020642127998144e-07\n",
      "208 1.9671008999466721e-07\n",
      "209 1.97442503235834e-07\n",
      "210 2.7099326871393714e-07\n",
      "211 4.7184724394355726e-07\n",
      "212 8.711234613656416e-07\n",
      "213 1.7483039300714154e-06\n",
      "214 3.815989657596219e-06\n",
      "215 8.696421900822315e-06\n",
      "216 2.0336323359515518e-05\n",
      "217 4.877710671280511e-05\n",
      "218 0.00011975191591773182\n",
      "219 0.000300355430226773\n",
      "220 0.0007690793136134744\n",
      "221 0.0020092828199267387\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 100000, 1000, 10\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype))\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Use the nn package to define our model and loss function.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ").type(dtype)\n",
    "loss_fn = torch.nn.MSELoss(size_average=False).type(dtype)\n",
    "\n",
    "# Use the optim package to define an Optimizer that will update the weights of\n",
    "# the model for us. Here we will use Adam; the optim package contains many other\n",
    "# optimization algoriths. The first argument to the Adam constructor tells the\n",
    "# optimizer which Variables it should update.\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables it will update (which are the learnable weights\n",
    "    # of the model)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to model\n",
    "    # parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 680.6207275390625\n",
      "1 797.928466796875\n",
      "2 633.4841918945312\n",
      "3 291.8186950683594\n",
      "4 235.925048828125\n",
      "5 184.9457550048828\n",
      "6 139.656005859375\n",
      "7 116.38621520996094\n",
      "8 98.16300964355469\n",
      "9 87.5408935546875\n",
      "10 80.47701263427734\n",
      "11 73.89134216308594\n",
      "12 65.64324951171875\n",
      "13 59.18330001831055\n",
      "14 55.32588195800781\n",
      "15 52.20457458496094\n",
      "16 48.065879821777344\n",
      "17 45.50067138671875\n",
      "18 42.52301025390625\n",
      "19 39.42010498046875\n",
      "20 36.38455581665039\n",
      "21 34.0142936706543\n",
      "22 32.061744689941406\n",
      "23 30.360309600830078\n",
      "24 27.207584381103516\n",
      "25 24.918292999267578\n",
      "26 23.187267303466797\n",
      "27 21.560400009155273\n",
      "28 20.271190643310547\n",
      "29 19.18348503112793\n",
      "30 18.25925064086914\n",
      "31 17.456737518310547\n",
      "32 16.75872039794922\n",
      "33 16.1453914642334\n",
      "34 15.608312606811523\n",
      "35 15.1362943649292\n",
      "36 14.725401878356934\n",
      "37 14.369331359863281\n",
      "38 14.066527366638184\n",
      "39 13.80737018585205\n",
      "40 13.546483993530273\n",
      "41 13.327537536621094\n",
      "42 13.144830703735352\n",
      "43 12.995343208312988\n",
      "44 12.882376670837402\n",
      "45 12.799389839172363\n",
      "46 12.756230354309082\n",
      "47 12.737066268920898\n",
      "48 12.760368347167969\n",
      "49 12.795568466186523\n",
      "50 12.875682830810547\n",
      "51 12.940025329589844\n",
      "52 13.043389320373535\n",
      "53 12.451369285583496\n",
      "54 12.073920249938965\n",
      "55 11.722270011901855\n",
      "56 11.44876480102539\n",
      "57 11.210304260253906\n",
      "58 11.016813278198242\n",
      "59 10.854186058044434\n",
      "60 10.713844299316406\n",
      "61 10.597404479980469\n",
      "62 10.489463806152344\n",
      "63 10.400025367736816\n",
      "64 10.311431884765625\n",
      "65 10.23776626586914\n",
      "66 10.160907745361328\n",
      "67 10.096689224243164\n",
      "68 10.027313232421875\n",
      "69 9.969078063964844\n",
      "70 9.904890060424805\n",
      "71 9.850749015808105\n",
      "72 9.790567398071289\n",
      "73 9.739622116088867\n",
      "74 9.682945251464844\n",
      "75 9.63477897644043\n",
      "76 9.581390380859375\n",
      "77 9.535825729370117\n",
      "78 9.485662460327148\n",
      "79 9.442658424377441\n",
      "80 9.395105361938477\n",
      "81 9.351312637329102\n",
      "82 9.305863380432129\n",
      "83 9.26676082611084\n",
      "84 9.225167274475098\n",
      "85 9.188996315002441\n",
      "86 9.15077018737793\n",
      "87 9.117347717285156\n",
      "88 9.082305908203125\n",
      "89 9.05151081085205\n",
      "90 9.019469261169434\n",
      "91 8.991162300109863\n",
      "92 8.961917877197266\n",
      "93 8.935948371887207\n",
      "94 8.90928840637207\n",
      "95 8.885486602783203\n",
      "96 8.861190795898438\n",
      "97 8.839374542236328\n",
      "98 8.817232131958008\n",
      "99 8.79725170135498\n",
      "100 8.777060508728027\n",
      "101 8.758745193481445\n",
      "102 8.740312576293945\n",
      "103 8.723503112792969\n",
      "104 8.706647872924805\n",
      "105 8.691198348999023\n",
      "106 8.675756454467773\n",
      "107 8.661529541015625\n",
      "108 8.647346496582031\n",
      "109 8.634217262268066\n",
      "110 8.621155738830566\n",
      "111 8.6090087890625\n",
      "112 8.596949577331543\n",
      "113 8.585683822631836\n",
      "114 8.574514389038086\n",
      "115 8.564033508300781\n",
      "116 8.553659439086914\n",
      "117 8.543891906738281\n",
      "118 8.534248352050781\n",
      "119 8.525137901306152\n",
      "120 8.516140937805176\n",
      "121 8.507608413696289\n",
      "122 8.499183654785156\n",
      "123 8.49116039276123\n",
      "124 8.483241081237793\n",
      "125 8.47567081451416\n",
      "126 8.4681978225708\n",
      "127 8.461030960083008\n",
      "128 8.453956604003906\n",
      "129 8.447149276733398\n",
      "130 8.440430641174316\n",
      "131 8.433943748474121\n",
      "132 8.427541732788086\n",
      "133 8.421343803405762\n",
      "134 8.415224075317383\n",
      "135 8.409286499023438\n",
      "136 8.403423309326172\n",
      "137 8.397722244262695\n",
      "138 8.392091751098633\n",
      "139 8.386605262756348\n",
      "140 8.381180763244629\n",
      "141 8.375884056091309\n",
      "142 8.370648384094238\n",
      "143 8.365525245666504\n",
      "144 8.360457420349121\n",
      "145 8.355489730834961\n",
      "146 8.350580215454102\n",
      "147 8.345756530761719\n",
      "148 8.340977668762207\n",
      "149 8.336280822753906\n",
      "150 8.331628799438477\n",
      "151 8.327049255371094\n",
      "152 8.322510719299316\n",
      "153 8.318036079406738\n",
      "154 8.313602447509766\n",
      "155 8.309225082397461\n",
      "156 8.304885864257812\n",
      "157 8.30059814453125\n",
      "158 8.296343803405762\n",
      "159 8.292139053344727\n",
      "160 8.2879638671875\n",
      "161 8.283831596374512\n",
      "162 8.279729843139648\n",
      "163 8.275667190551758\n",
      "164 8.271632194519043\n",
      "165 8.267631530761719\n",
      "166 8.263657569885254\n",
      "167 8.259716033935547\n",
      "168 8.25579833984375\n",
      "169 8.251909255981445\n",
      "170 8.24804401397705\n",
      "171 8.2442045211792\n",
      "172 8.240386962890625\n",
      "173 8.236595153808594\n",
      "174 8.232820510864258\n",
      "175 8.229069709777832\n",
      "176 8.225337982177734\n",
      "177 8.221626281738281\n",
      "178 8.217933654785156\n",
      "179 8.21425724029541\n",
      "180 8.210599899291992\n",
      "181 8.20695972442627\n",
      "182 8.203333854675293\n",
      "183 8.199725151062012\n",
      "184 8.196130752563477\n",
      "185 8.192551612854004\n",
      "186 8.188984870910645\n",
      "187 8.185431480407715\n",
      "188 8.181893348693848\n",
      "189 8.178367614746094\n",
      "190 8.17485237121582\n",
      "191 8.171350479125977\n",
      "192 8.16786003112793\n",
      "193 8.164380073547363\n",
      "194 8.160911560058594\n",
      "195 8.157454490661621\n",
      "196 8.15400505065918\n",
      "197 8.150567054748535\n",
      "198 8.147138595581055\n",
      "199 8.143718719482422\n",
      "200 8.140308380126953\n",
      "201 8.136907577514648\n",
      "202 8.133512496948242\n",
      "203 8.130128860473633\n",
      "204 8.126751899719238\n",
      "205 8.123382568359375\n",
      "206 8.120020866394043\n",
      "207 8.116665840148926\n",
      "208 8.113317489624023\n",
      "209 8.109977722167969\n",
      "210 8.106643676757812\n",
      "211 8.103318214416504\n",
      "212 8.099995613098145\n",
      "213 8.096681594848633\n",
      "214 8.09337329864502\n",
      "215 8.090071678161621\n",
      "216 8.086773872375488\n",
      "217 8.083484649658203\n",
      "218 8.08019733428955\n",
      "219 8.076918601989746\n",
      "220 8.07364273071289\n",
      "221 8.07037353515625\n",
      "222 8.067107200622559\n",
      "223 8.063848495483398\n",
      "224 8.060592651367188\n",
      "225 8.057342529296875\n",
      "226 8.054095268249512\n",
      "227 8.050853729248047\n",
      "228 8.047616004943848\n",
      "229 8.044384002685547\n",
      "230 8.041153907775879\n",
      "231 8.03792953491211\n",
      "232 8.034708023071289\n",
      "233 8.031492233276367\n",
      "234 8.028278350830078\n",
      "235 8.025070190429688\n",
      "236 8.021862030029297\n",
      "237 8.018660545349121\n",
      "238 8.015462875366211\n",
      "239 8.012267112731934\n",
      "240 8.009075164794922\n",
      "241 8.005887031555176\n",
      "242 8.002701759338379\n",
      "243 7.999519348144531\n",
      "244 7.996340274810791\n",
      "245 7.993165016174316\n",
      "246 7.989992141723633\n",
      "247 7.986822128295898\n",
      "248 7.98365592956543\n",
      "249 7.980491638183594\n",
      "250 7.977330207824707\n",
      "251 7.974172592163086\n",
      "252 7.971016883850098\n",
      "253 7.967864036560059\n",
      "254 7.9647135734558105\n",
      "255 7.961566925048828\n",
      "256 7.958420753479004\n",
      "257 7.955278396606445\n",
      "258 7.952138900756836\n",
      "259 7.949000835418701\n",
      "260 7.945866584777832\n",
      "261 7.9427337646484375\n",
      "262 7.939602851867676\n",
      "263 7.93647575378418\n",
      "264 7.933349609375\n",
      "265 7.9302263259887695\n",
      "266 7.927105903625488\n",
      "267 7.92398738861084\n",
      "268 7.920870304107666\n",
      "269 7.917755126953125\n",
      "270 7.914642810821533\n",
      "271 7.911532402038574\n",
      "272 7.908425331115723\n",
      "273 7.905318737030029\n",
      "274 7.902214050292969\n",
      "275 7.899113655090332\n",
      "276 7.896012306213379\n",
      "277 7.892914772033691\n",
      "278 7.88981819152832\n",
      "279 7.886724472045898\n",
      "280 7.883632183074951\n",
      "281 7.88054084777832\n",
      "282 7.877452850341797\n",
      "283 7.874366283416748\n",
      "284 7.871281623840332\n",
      "285 7.868197917938232\n",
      "286 7.865117073059082\n",
      "287 7.862037658691406\n",
      "288 7.858959197998047\n",
      "289 7.855883598327637\n",
      "290 7.852808952331543\n",
      "291 7.849737644195557\n",
      "292 7.84666633605957\n",
      "293 7.843597412109375\n",
      "294 7.8405303955078125\n",
      "295 7.837464809417725\n",
      "296 7.8344011306762695\n",
      "297 7.831337928771973\n",
      "298 7.828276634216309\n",
      "299 7.825218200683594\n",
      "300 7.822160720825195\n",
      "301 7.819104194641113\n",
      "302 7.816050052642822\n",
      "303 7.812997817993164\n",
      "304 7.809946060180664\n",
      "305 7.806897163391113\n",
      "306 7.803849220275879\n",
      "307 7.800801753997803\n",
      "308 7.797756195068359\n",
      "309 7.794713020324707\n",
      "310 7.791670799255371\n",
      "311 7.788631439208984\n",
      "312 7.7855916023254395\n",
      "313 7.782553672790527\n",
      "314 7.779518127441406\n",
      "315 7.776482582092285\n",
      "316 7.773449897766113\n",
      "317 7.770418167114258\n",
      "318 7.767387866973877\n",
      "319 7.764359474182129\n",
      "320 7.761331558227539\n",
      "321 7.758305549621582\n",
      "322 7.755281448364258\n",
      "323 7.75225830078125\n",
      "324 7.749236106872559\n",
      "325 7.7462158203125\n",
      "326 7.743196487426758\n",
      "327 7.740179538726807\n",
      "328 7.7371625900268555\n",
      "329 7.734148025512695\n",
      "330 7.731133937835693\n",
      "331 7.728122234344482\n",
      "332 7.725110054016113\n",
      "333 7.722101211547852\n",
      "334 7.719093322753906\n",
      "335 7.716086387634277\n",
      "336 7.7130818367004395\n",
      "337 7.710076808929443\n",
      "338 7.707075119018555\n",
      "339 7.704072952270508\n",
      "340 7.701072692871094\n",
      "341 7.698073387145996\n",
      "342 7.695076942443848\n",
      "343 7.692080497741699\n",
      "344 7.689084529876709\n",
      "345 7.686091899871826\n",
      "346 7.683099746704102\n",
      "347 7.680108070373535\n",
      "348 7.67711877822876\n",
      "349 7.674129962921143\n",
      "350 7.671143054962158\n",
      "351 7.668156623840332\n",
      "352 7.665172576904297\n",
      "353 7.662188529968262\n",
      "354 7.659206867218018\n",
      "355 7.65622615814209\n",
      "356 7.653246879577637\n",
      "357 7.650267601013184\n",
      "358 7.64729118347168\n",
      "359 7.644313812255859\n",
      "360 7.641340255737305\n",
      "361 7.638367176055908\n",
      "362 7.635395050048828\n",
      "363 7.6324238777160645\n",
      "364 7.629455089569092\n",
      "365 7.626485824584961\n",
      "366 7.623519420623779\n",
      "367 7.620553016662598\n",
      "368 7.617588996887207\n",
      "369 7.6146240234375\n",
      "370 7.611662864685059\n",
      "371 7.608701705932617\n",
      "372 7.60574197769165\n",
      "373 7.602783203125\n",
      "374 7.599825859069824\n",
      "375 7.596869468688965\n",
      "376 7.593914985656738\n",
      "377 7.590961456298828\n",
      "378 7.588008880615234\n",
      "379 7.585057258605957\n",
      "380 7.5821075439453125\n",
      "381 7.579157829284668\n",
      "382 7.576210021972656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383 7.573263168334961\n",
      "384 7.570318698883057\n",
      "385 7.567375183105469\n",
      "386 7.564432144165039\n",
      "387 7.561490058898926\n",
      "388 7.558548927307129\n",
      "389 7.555610656738281\n",
      "390 7.552671909332275\n",
      "391 7.549734592437744\n",
      "392 7.5467987060546875\n",
      "393 7.543864727020264\n",
      "394 7.54093074798584\n",
      "395 7.537998199462891\n",
      "396 7.535067081451416\n",
      "397 7.532136917114258\n",
      "398 7.529209136962891\n",
      "399 7.526281356811523\n",
      "400 7.523355007171631\n",
      "401 7.520429611206055\n",
      "402 7.517505645751953\n",
      "403 7.514582633972168\n",
      "404 7.511661529541016\n",
      "405 7.508740425109863\n",
      "406 7.505821228027344\n",
      "407 7.502902984619141\n",
      "408 7.499986171722412\n",
      "409 7.497070789337158\n",
      "410 7.494155406951904\n",
      "411 7.491241455078125\n",
      "412 7.48832893371582\n",
      "413 7.48541784286499\n",
      "414 7.482508182525635\n",
      "415 7.479598522186279\n",
      "416 7.476691246032715\n",
      "417 7.47378396987915\n",
      "418 7.470878601074219\n",
      "419 7.4679741859436035\n",
      "420 7.465070724487305\n",
      "421 7.4621686935424805\n",
      "422 7.459268093109131\n",
      "423 7.456368446350098\n",
      "424 7.453469276428223\n",
      "425 7.450571537017822\n",
      "426 7.447675704956055\n",
      "427 7.444780349731445\n",
      "428 7.4418864250183105\n",
      "429 7.438993453979492\n",
      "430 7.436101913452148\n",
      "431 7.433211326599121\n",
      "432 7.43032169342041\n",
      "433 7.427433013916016\n",
      "434 7.424546241760254\n",
      "435 7.421659469604492\n",
      "436 7.4187750816345215\n",
      "437 7.415890693664551\n",
      "438 7.413007736206055\n",
      "439 7.410126686096191\n",
      "440 7.407246112823486\n",
      "441 7.404366493225098\n",
      "442 7.401488304138184\n",
      "443 7.398612022399902\n",
      "444 7.395735740661621\n",
      "445 7.392861366271973\n",
      "446 7.389987468719482\n",
      "447 7.387115478515625\n",
      "448 7.384243488311768\n",
      "449 7.381373405456543\n",
      "450 7.378505706787109\n",
      "451 7.375637054443359\n",
      "452 7.3727707862854\n",
      "453 7.369904518127441\n",
      "454 7.367040634155273\n",
      "455 7.3641767501831055\n",
      "456 7.36131477355957\n",
      "457 7.358452796936035\n",
      "458 7.355593204498291\n",
      "459 7.352734565734863\n",
      "460 7.34987735748291\n",
      "461 7.347021102905273\n",
      "462 7.344164848327637\n",
      "463 7.341311454772949\n",
      "464 7.338458061218262\n",
      "465 7.335605621337891\n",
      "466 7.332754611968994\n",
      "467 7.329905033111572\n",
      "468 7.327055931091309\n",
      "469 7.324208736419678\n",
      "470 7.321362495422363\n",
      "471 7.318517208099365\n",
      "472 7.315671443939209\n",
      "473 7.312829494476318\n",
      "474 7.3099870681762695\n",
      "475 7.307146072387695\n",
      "476 7.3043060302734375\n",
      "477 7.301467418670654\n",
      "478 7.2986297607421875\n",
      "479 7.295793533325195\n",
      "480 7.292957305908203\n",
      "481 7.290122985839844\n",
      "482 7.287290573120117\n",
      "483 7.284458160400391\n",
      "484 7.2816267013549805\n",
      "485 7.278797149658203\n",
      "486 7.275968074798584\n",
      "487 7.2731404304504395\n",
      "488 7.270313739776611\n",
      "489 7.267488479614258\n",
      "490 7.2646636962890625\n",
      "491 7.261839866638184\n",
      "492 7.259018898010254\n",
      "493 7.256196975708008\n",
      "494 7.253377437591553\n",
      "495 7.250558853149414\n",
      "496 7.247740745544434\n",
      "497 7.2449235916137695\n",
      "498 7.242108345031738\n",
      "499 7.239293575286865\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class TwoLayerNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Variable of input data and we must return\n",
    "        a Variable of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Variables.\n",
    "        \"\"\"\n",
    "        h_relu = self.linear1(x).clamp(min=0)\n",
    "        y_pred = self.linear2(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 100000, 100, 10\n",
    "\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype))\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = TwoLayerNet(D_in, H, D_out).type(dtype)\n",
    "\n",
    "# Construct our loss function and an Optimizer. The call to model.parameters()\n",
    "# in the SGD constructor will contain the learnable parameters of the two\n",
    "# nn.Linear modules which are members of the model.\n",
    "criterion = torch.nn.MSELoss(size_average=False).type(dtype)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 645.0169677734375\n",
      "1 641.960693359375\n",
      "2 644.8233032226562\n",
      "3 571.0902709960938\n",
      "4 85.2299575805664\n",
      "5 601.1029663085938\n",
      "6 297.89727783203125\n",
      "7 159.08444213867188\n",
      "8 424.093505859375\n",
      "9 297.1700439453125\n",
      "10 152.26446533203125\n",
      "11 279.21478271484375\n",
      "12 6575.2646484375\n",
      "13 4024.62255859375\n",
      "14 752.6444091796875\n",
      "15 59723.7421875\n",
      "16 1210406.75\n",
      "17 43081984.0\n",
      "18 6.267762120388956e+35\n",
      "19 nan\n",
      "20 nan\n",
      "21 nan\n",
      "22 nan\n",
      "23 nan\n",
      "24 nan\n",
      "25 nan\n",
      "26 nan\n",
      "27 nan\n",
      "28 nan\n",
      "29 nan\n",
      "30 nan\n",
      "31 nan\n",
      "32 nan\n",
      "33 nan\n",
      "34 nan\n",
      "35 nan\n",
      "36 nan\n",
      "37 nan\n",
      "38 nan\n",
      "39 nan\n",
      "40 nan\n",
      "41 nan\n",
      "42 nan\n",
      "43 nan\n",
      "44 nan\n",
      "45 nan\n",
      "46 nan\n",
      "47 nan\n",
      "48 nan\n",
      "49 nan\n",
      "50 nan\n",
      "51 nan\n",
      "52 nan\n",
      "53 nan\n",
      "54 nan\n",
      "55 nan\n",
      "56 nan\n",
      "57 nan\n",
      "58 nan\n",
      "59 nan\n",
      "60 nan\n",
      "61 nan\n",
      "62 nan\n",
      "63 nan\n",
      "64 nan\n",
      "65 nan\n",
      "66 nan\n",
      "67 nan\n",
      "68 nan\n",
      "69 nan\n",
      "70 nan\n",
      "71 nan\n",
      "72 nan\n",
      "73 nan\n",
      "74 nan\n",
      "75 nan\n",
      "76 nan\n",
      "77 nan\n",
      "78 nan\n",
      "79 nan\n",
      "80 nan\n",
      "81 nan\n",
      "82 nan\n",
      "83 nan\n",
      "84 nan\n",
      "85 nan\n",
      "86 nan\n",
      "87 nan\n",
      "88 nan\n",
      "89 nan\n",
      "90 nan\n",
      "91 nan\n",
      "92 nan\n",
      "93 nan\n",
      "94 nan\n",
      "95 nan\n",
      "96 nan\n",
      "97 nan\n",
      "98 nan\n",
      "99 nan\n",
      "100 nan\n",
      "101 nan\n",
      "102 nan\n",
      "103 nan\n",
      "104 nan\n",
      "105 nan\n",
      "106 nan\n",
      "107 nan\n",
      "108 nan\n",
      "109 nan\n",
      "110 nan\n",
      "111 nan\n",
      "112 nan\n",
      "113 nan\n",
      "114 nan\n",
      "115 nan\n",
      "116 nan\n",
      "117 nan\n",
      "118 nan\n",
      "119 nan\n",
      "120 nan\n",
      "121 nan\n",
      "122 nan\n",
      "123 nan\n",
      "124 nan\n",
      "125 nan\n",
      "126 nan\n",
      "127 nan\n",
      "128 nan\n",
      "129 nan\n",
      "130 nan\n",
      "131 nan\n",
      "132 nan\n",
      "133 nan\n",
      "134 nan\n",
      "135 nan\n",
      "136 nan\n",
      "137 nan\n",
      "138 nan\n",
      "139 nan\n",
      "140 nan\n",
      "141 nan\n",
      "142 nan\n",
      "143 nan\n",
      "144 nan\n",
      "145 nan\n",
      "146 nan\n",
      "147 nan\n",
      "148 nan\n",
      "149 nan\n",
      "150 nan\n",
      "151 nan\n",
      "152 nan\n",
      "153 nan\n",
      "154 nan\n",
      "155 nan\n",
      "156 nan\n",
      "157 nan\n",
      "158 nan\n",
      "159 nan\n",
      "160 nan\n",
      "161 nan\n",
      "162 nan\n",
      "163 nan\n",
      "164 nan\n",
      "165 nan\n",
      "166 nan\n",
      "167 nan\n",
      "168 nan\n",
      "169 nan\n",
      "170 nan\n",
      "171 nan\n",
      "172 nan\n",
      "173 nan\n",
      "174 nan\n",
      "175 nan\n",
      "176 nan\n",
      "177 nan\n",
      "178 nan\n",
      "179 nan\n",
      "180 nan\n",
      "181 nan\n",
      "182 nan\n",
      "183 nan\n",
      "184 nan\n",
      "185 nan\n",
      "186 nan\n",
      "187 nan\n",
      "188 nan\n",
      "189 nan\n",
      "190 nan\n",
      "191 nan\n",
      "192 nan\n",
      "193 nan\n",
      "194 nan\n",
      "195 nan\n",
      "196 nan\n",
      "197 nan\n",
      "198 nan\n",
      "199 nan\n",
      "200 nan\n",
      "201 nan\n",
      "202 nan\n",
      "203 nan\n",
      "204 nan\n",
      "205 nan\n",
      "206 nan\n",
      "207 nan\n",
      "208 nan\n",
      "209 nan\n",
      "210 nan\n",
      "211 nan\n",
      "212 nan\n",
      "213 nan\n",
      "214 nan\n",
      "215 nan\n",
      "216 nan\n",
      "217 nan\n",
      "218 nan\n",
      "219 nan\n",
      "220 nan\n",
      "221 nan\n",
      "222 nan\n",
      "223 nan\n",
      "224 nan\n",
      "225 nan\n",
      "226 nan\n",
      "227 nan\n",
      "228 nan\n",
      "229 nan\n",
      "230 nan\n",
      "231 nan\n",
      "232 nan\n",
      "233 nan\n",
      "234 nan\n",
      "235 nan\n",
      "236 nan\n",
      "237 nan\n",
      "238 nan\n",
      "239 nan\n",
      "240 nan\n",
      "241 nan\n",
      "242 nan\n",
      "243 nan\n",
      "244 nan\n",
      "245 nan\n",
      "246 nan\n",
      "247 nan\n",
      "248 nan\n",
      "249 nan\n",
      "250 nan\n",
      "251 nan\n",
      "252 nan\n",
      "253 nan\n",
      "254 nan\n",
      "255 nan\n",
      "256 nan\n",
      "257 nan\n",
      "258 nan\n",
      "259 nan\n",
      "260 nan\n",
      "261 nan\n",
      "262 nan\n",
      "263 nan\n",
      "264 nan\n",
      "265 nan\n",
      "266 nan\n",
      "267 nan\n",
      "268 nan\n",
      "269 nan\n",
      "270 nan\n",
      "271 nan\n",
      "272 nan\n",
      "273 nan\n",
      "274 nan\n",
      "275 nan\n",
      "276 nan\n",
      "277 nan\n",
      "278 nan\n",
      "279 nan\n",
      "280 nan\n",
      "281 nan\n",
      "282 nan\n",
      "283 nan\n",
      "284 nan\n",
      "285 nan\n",
      "286 nan\n",
      "287 nan\n",
      "288 nan\n",
      "289 nan\n",
      "290 nan\n",
      "291 nan\n",
      "292 nan\n",
      "293 nan\n",
      "294 nan\n",
      "295 nan\n",
      "296 nan\n",
      "297 nan\n",
      "298 nan\n",
      "299 nan\n",
      "300 nan\n",
      "301 nan\n",
      "302 nan\n",
      "303 nan\n",
      "304 nan\n",
      "305 nan\n",
      "306 nan\n",
      "307 nan\n",
      "308 nan\n",
      "309 nan\n",
      "310 nan\n",
      "311 nan\n",
      "312 nan\n",
      "313 nan\n",
      "314 nan\n",
      "315 nan\n",
      "316 nan\n",
      "317 nan\n",
      "318 nan\n",
      "319 nan\n",
      "320 nan\n",
      "321 nan\n",
      "322 nan\n",
      "323 nan\n",
      "324 nan\n",
      "325 nan\n",
      "326 nan\n",
      "327 nan\n",
      "328 nan\n",
      "329 nan\n",
      "330 nan\n",
      "331 nan\n",
      "332 nan\n",
      "333 nan\n",
      "334 nan\n",
      "335 nan\n",
      "336 nan\n",
      "337 nan\n",
      "338 nan\n",
      "339 nan\n",
      "340 nan\n",
      "341 nan\n",
      "342 nan\n",
      "343 nan\n",
      "344 nan\n",
      "345 nan\n",
      "346 nan\n",
      "347 nan\n",
      "348 nan\n",
      "349 nan\n",
      "350 nan\n",
      "351 nan\n",
      "352 nan\n",
      "353 nan\n",
      "354 nan\n",
      "355 nan\n",
      "356 nan\n",
      "357 nan\n",
      "358 nan\n",
      "359 nan\n",
      "360 nan\n",
      "361 nan\n",
      "362 nan\n",
      "363 nan\n",
      "364 nan\n",
      "365 nan\n",
      "366 nan\n",
      "367 nan\n",
      "368 nan\n",
      "369 nan\n",
      "370 nan\n",
      "371 nan\n",
      "372 nan\n",
      "373 nan\n",
      "374 nan\n",
      "375 nan\n",
      "376 nan\n",
      "377 nan\n",
      "378 nan\n",
      "379 nan\n",
      "380 nan\n",
      "381 nan\n",
      "382 nan\n",
      "383 nan\n",
      "384 nan\n",
      "385 nan\n",
      "386 nan\n",
      "387 nan\n",
      "388 nan\n",
      "389 nan\n",
      "390 nan\n",
      "391 nan\n",
      "392 nan\n",
      "393 nan\n",
      "394 nan\n",
      "395 nan\n",
      "396 nan\n",
      "397 nan\n",
      "398 nan\n",
      "399 nan\n",
      "400 nan\n",
      "401 nan\n",
      "402 nan\n",
      "403 nan\n",
      "404 nan\n",
      "405 nan\n",
      "406 nan\n",
      "407 nan\n",
      "408 nan\n",
      "409 nan\n",
      "410 nan\n",
      "411 nan\n",
      "412 nan\n",
      "413 nan\n",
      "414 nan\n",
      "415 nan\n",
      "416 nan\n",
      "417 nan\n",
      "418 nan\n",
      "419 nan\n",
      "420 nan\n",
      "421 nan\n",
      "422 nan\n",
      "423 nan\n",
      "424 nan\n",
      "425 nan\n",
      "426 nan\n",
      "427 nan\n",
      "428 nan\n",
      "429 nan\n",
      "430 nan\n",
      "431 nan\n",
      "432 nan\n",
      "433 nan\n",
      "434 nan\n",
      "435 nan\n",
      "436 nan\n",
      "437 nan\n",
      "438 nan\n",
      "439 nan\n",
      "440 nan\n",
      "441 nan\n",
      "442 nan\n",
      "443 nan\n",
      "444 nan\n",
      "445 nan\n",
      "446 nan\n",
      "447 nan\n",
      "448 nan\n",
      "449 nan\n",
      "450 nan\n",
      "451 nan\n",
      "452 nan\n",
      "453 nan\n",
      "454 nan\n",
      "455 nan\n",
      "456 nan\n",
      "457 nan\n",
      "458 nan\n",
      "459 nan\n",
      "460 nan\n",
      "461 nan\n",
      "462 nan\n",
      "463 nan\n",
      "464 nan\n",
      "465 nan\n",
      "466 nan\n",
      "467 nan\n",
      "468 nan\n",
      "469 nan\n",
      "470 nan\n",
      "471 nan\n",
      "472 nan\n",
      "473 nan\n",
      "474 nan\n",
      "475 nan\n",
      "476 nan\n",
      "477 nan\n",
      "478 nan\n",
      "479 nan\n",
      "480 nan\n",
      "481 nan\n",
      "482 nan\n",
      "483 nan\n",
      "484 nan\n",
      "485 nan\n",
      "486 nan\n",
      "487 nan\n",
      "488 nan\n",
      "489 nan\n",
      "490 nan\n",
      "491 nan\n",
      "492 nan\n",
      "493 nan\n",
      "494 nan\n",
      "495 nan\n",
      "496 nan\n",
      "497 nan\n",
      "498 nan\n",
      "499 nan\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "\n",
    "dtype = torch.cuda.FloatTensor # Uncomment this to run on GPU\n",
    "# Create random Tensors to hold inputs and outputs, and wrap them in Variables.\n",
    "x = Variable(torch.randn(N, D_in).type(dtype))\n",
    "y = Variable(torch.randn(N, D_out).type(dtype), requires_grad=False)\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out).type(dtype)\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(size_average=False).type(dtype)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "for t in range(500):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    print(t, loss.data[0])\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

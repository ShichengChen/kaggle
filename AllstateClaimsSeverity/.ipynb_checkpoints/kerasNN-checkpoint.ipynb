{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3, Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "'''gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))'''\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1153)\n",
      "(188318,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((188318, 1153), (188318,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "cat_names = [c for c in train.columns if 'cat' in c]\n",
    "\n",
    "train = pd.get_dummies(data=train, columns=cat_names)\n",
    "\n",
    "features = [x for x in train.columns if x not in ['id','loss']]\n",
    "\n",
    "train_x = np.array(train[features])\n",
    "\n",
    "ntrain = train_x.shape[0]\n",
    "\n",
    "train_y = np.log(train['loss'] + 200)\n",
    "\n",
    "print (train_x.shape)\n",
    "print (train_y.shape)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=3):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nfolds,))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        mlp = mlp_func()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        fit = mlp.fit(xtr, ytr, validation_split=0.2, batch_size=128, \n",
    "                      nb_epoch=30, verbose=1, callbacks=[early_stopping])\n",
    "        pred = mlp.predict(xte, batch_size=256)\n",
    "        score = mean_absolute_error(yte, pred)\n",
    "        val_scores[k] += score\n",
    "        print ('Fold {}, MAE: {}'.format(k, score))\n",
    "    avg_score = np.sum(val_scores) / float(nfolds)\n",
    "    print ('{}-fold CV score: {}'.format(nfolds, avg_score))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(train_x, train_y, test_size=0.25, random_state=31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cdn.rawgit.com/dnkirill/allstate_capstone/master/images/mlp3.svg\"></td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat))\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true) - K.exp(y_pred)))\n",
    "\n",
    "def mean_pred_metrics(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true) - K.exp(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyper_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(351, input_dim=train_x.shape[1], init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.578947))\n",
    "    \n",
    "    model.add(Dense(293, init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.26666))\n",
    "    \n",
    "    model.add(Dense(46, init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.188888))\n",
    "    \n",
    "    model.add(Dense(1, init='he_normal'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=mean_pred,metrics=['mae', mean_pred_metrics])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100436 samples, validate on 25109 samples\n",
      "Epoch 1/30\n",
      "100436/100436 [==============================] - 8s - loss: 3085.2742 - mean_absolute_error: 6.2451 - mean_pred_metrics: 3085.2742 - val_loss: 2815.7498 - val_mean_absolute_error: 6.7370 - val_mean_pred_metrics: 2815.7498\n",
      "Epoch 2/30\n",
      "100436/100436 [==============================] - 7s - loss: 2380.7105 - mean_absolute_error: 3.0840 - mean_pred_metrics: 2380.7105 - val_loss: 1812.2373 - val_mean_absolute_error: 2.1164 - val_mean_pred_metrics: 1812.2373\n",
      "Epoch 3/30\n",
      "100436/100436 [==============================] - 7s - loss: 2132.2872 - mean_absolute_error: 1.3786 - mean_pred_metrics: 2132.2872 - val_loss: 1730.8004 - val_mean_absolute_error: 0.9254 - val_mean_pred_metrics: 1730.8004\n",
      "Epoch 4/30\n",
      "100436/100436 [==============================] - 7s - loss: 1976.1216 - mean_absolute_error: 0.9467 - mean_pred_metrics: 1976.1216 - val_loss: 1625.5351 - val_mean_absolute_error: 0.6602 - val_mean_pred_metrics: 1625.5351\n",
      "Epoch 5/30\n",
      "100436/100436 [==============================] - 7s - loss: 1876.9349 - mean_absolute_error: 0.8302 - mean_pred_metrics: 1876.9349 - val_loss: 1603.9250 - val_mean_absolute_error: 0.6269 - val_mean_pred_metrics: 1603.9250\n",
      "Epoch 6/30\n",
      "100436/100436 [==============================] - 7s - loss: 1831.6222 - mean_absolute_error: 0.7903 - mean_pred_metrics: 1831.6222 - val_loss: 1507.0171 - val_mean_absolute_error: 0.5824 - val_mean_pred_metrics: 1507.0171\n",
      "Epoch 7/30\n",
      "100436/100436 [==============================] - 7s - loss: 1782.4977 - mean_absolute_error: 0.7597 - mean_pred_metrics: 1782.4977 - val_loss: 1427.6333 - val_mean_absolute_error: 0.5242 - val_mean_pred_metrics: 1427.6333\n",
      "Epoch 8/30\n",
      "100436/100436 [==============================] - 7s - loss: 1743.0605 - mean_absolute_error: 0.7399 - mean_pred_metrics: 1743.0605 - val_loss: 1551.5359 - val_mean_absolute_error: 0.5598 - val_mean_pred_metrics: 1551.5359\n",
      "Epoch 9/30\n",
      "100436/100436 [==============================] - 7s - loss: 1714.7379 - mean_absolute_error: 0.7172 - mean_pred_metrics: 1714.7379 - val_loss: 1569.6625 - val_mean_absolute_error: 0.5707 - val_mean_pred_metrics: 1569.6625\n",
      "Epoch 10/30\n",
      "100436/100436 [==============================] - 7s - loss: 1683.8860 - mean_absolute_error: 0.7036 - mean_pred_metrics: 1683.8860 - val_loss: 1436.2514 - val_mean_absolute_error: 0.5463 - val_mean_pred_metrics: 1436.2514\n",
      "Epoch 11/30\n",
      "100436/100436 [==============================] - 7s - loss: 1658.1534 - mean_absolute_error: 0.6874 - mean_pred_metrics: 1658.1534 - val_loss: 1419.0661 - val_mean_absolute_error: 0.5265 - val_mean_pred_metrics: 1419.0661\n",
      "Epoch 12/30\n",
      "100436/100436 [==============================] - 7s - loss: 1637.8328 - mean_absolute_error: 0.6657 - mean_pred_metrics: 1637.8328 - val_loss: 1367.4644 - val_mean_absolute_error: 0.5037 - val_mean_pred_metrics: 1367.4644\n",
      "Epoch 13/30\n",
      "100436/100436 [==============================] - 7s - loss: 1621.8129 - mean_absolute_error: 0.6580 - mean_pred_metrics: 1621.8129 - val_loss: 1366.2594 - val_mean_absolute_error: 0.5046 - val_mean_pred_metrics: 1366.2594\n",
      "Epoch 14/30\n",
      "100436/100436 [==============================] - 7s - loss: 1596.3304 - mean_absolute_error: 0.6395 - mean_pred_metrics: 1596.3304 - val_loss: 1356.4713 - val_mean_absolute_error: 0.4790 - val_mean_pred_metrics: 1356.4713\n",
      "Epoch 15/30\n",
      "100436/100436 [==============================] - 7s - loss: 1573.4829 - mean_absolute_error: 0.6267 - mean_pred_metrics: 1573.4829 - val_loss: 1308.8398 - val_mean_absolute_error: 0.4630 - val_mean_pred_metrics: 1308.8398\n",
      "Epoch 16/30\n",
      "100436/100436 [==============================] - 7s - loss: 1558.8034 - mean_absolute_error: 0.6069 - mean_pred_metrics: 1558.8034 - val_loss: 1275.7067 - val_mean_absolute_error: 0.4512 - val_mean_pred_metrics: 1275.7067\n",
      "Epoch 17/30\n",
      "100436/100436 [==============================] - 7s - loss: 1521.5459 - mean_absolute_error: 0.5858 - mean_pred_metrics: 1521.5459 - val_loss: 1271.2924 - val_mean_absolute_error: 0.4500 - val_mean_pred_metrics: 1271.2924\n",
      "Epoch 18/30\n",
      "100436/100436 [==============================] - 7s - loss: 1511.2223 - mean_absolute_error: 0.5731 - mean_pred_metrics: 1511.2223 - val_loss: 1226.5043 - val_mean_absolute_error: 0.4158 - val_mean_pred_metrics: 1226.5043\n",
      "Epoch 19/30\n",
      "100436/100436 [==============================] - 7s - loss: 1490.4322 - mean_absolute_error: 0.5583 - mean_pred_metrics: 1490.4322 - val_loss: 1269.3685 - val_mean_absolute_error: 0.4265 - val_mean_pred_metrics: 1269.3685\n",
      "Epoch 20/30\n",
      "100436/100436 [==============================] - 7s - loss: 1471.0148 - mean_absolute_error: 0.5428 - mean_pred_metrics: 1471.0148 - val_loss: 1277.2898 - val_mean_absolute_error: 0.4229 - val_mean_pred_metrics: 1277.2898\n",
      "Epoch 21/30\n",
      "100436/100436 [==============================] - 7s - loss: 1448.8624 - mean_absolute_error: 0.5272 - mean_pred_metrics: 1448.8624 - val_loss: 1218.7310 - val_mean_absolute_error: 0.4141 - val_mean_pred_metrics: 1218.7310\n",
      "Epoch 22/30\n",
      "100436/100436 [==============================] - 7s - loss: 1437.0388 - mean_absolute_error: 0.5158 - mean_pred_metrics: 1437.0388 - val_loss: 1256.1567 - val_mean_absolute_error: 0.4199 - val_mean_pred_metrics: 1256.1567\n",
      "Epoch 23/30\n",
      "100436/100436 [==============================] - 7s - loss: 1410.7764 - mean_absolute_error: 0.5006 - mean_pred_metrics: 1410.7764 - val_loss: 1193.8826 - val_mean_absolute_error: 0.4001 - val_mean_pred_metrics: 1193.8826\n",
      "Epoch 24/30\n",
      "100436/100436 [==============================] - 7s - loss: 1397.8519 - mean_absolute_error: 0.4885 - mean_pred_metrics: 1397.8519 - val_loss: 1236.9314 - val_mean_absolute_error: 0.4119 - val_mean_pred_metrics: 1236.9314\n",
      "Epoch 25/30\n",
      "100436/100436 [==============================] - 7s - loss: 1381.2457 - mean_absolute_error: 0.4767 - mean_pred_metrics: 1381.2457 - val_loss: 1159.3308 - val_mean_absolute_error: 0.3847 - val_mean_pred_metrics: 1159.3308\n",
      "Epoch 26/30\n",
      "100436/100436 [==============================] - 7s - loss: 1357.0561 - mean_absolute_error: 0.4656 - mean_pred_metrics: 1357.0561 - val_loss: 1197.8472 - val_mean_absolute_error: 0.3936 - val_mean_pred_metrics: 1197.8472\n",
      "Epoch 27/30\n",
      "100436/100436 [==============================] - 7s - loss: 1342.8926 - mean_absolute_error: 0.4553 - mean_pred_metrics: 1342.8926 - val_loss: 1167.6963 - val_mean_absolute_error: 0.3821 - val_mean_pred_metrics: 1167.6963\n",
      "Epoch 28/30\n",
      "100436/100436 [==============================] - 7s - loss: 1327.7205 - mean_absolute_error: 0.4435 - mean_pred_metrics: 1327.7205 - val_loss: 1194.9883 - val_mean_absolute_error: 0.3867 - val_mean_pred_metrics: 1194.9883\n",
      "Epoch 29/30\n",
      "100096/100436 [============================>.] - ETA: 0s - loss: 1310.3458 - mean_absolute_error: 0.4339 - mean_pred_metrics: 1310.3458"
     ]
    }
   ],
   "source": [
    "cv_score = cross_validate_mlp(hyper_model)\n",
    "(\"CV score for the final model:\", cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this model is not adapted for mere 30 epochs of training, nor for 3-fold CV (I used 5-fold on Kaggle), even though this is a single unbagged model which has been cross-validated on three folds only, we see a very good score:\n",
    "`CV = 1150` (your score may vary a little).\n",
    "\n",
    "By the way, this single model, bagged, 5-fold CVed, scored 1116.28 on Kaggle LB.\n",
    "\n",
    "As we see, this model is considerably better than any other models we had so far. We now take it as the second part of our final ensemble."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

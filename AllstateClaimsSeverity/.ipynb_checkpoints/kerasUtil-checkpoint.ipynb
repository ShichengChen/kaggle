{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "#sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a callback function to be used with training of Keras models.\n",
    "# It create an exponential moving average of a model (trainable) weights.\n",
    "# This functionlity is already available in TensorFlow:\n",
    "# https://www.tensorflow.org/versions/r0.10/api_docs/python/train.html#ExponentialMovingAverage\n",
    "# and can often be used to get better validation/test performance. For an\n",
    "# intuitive explantion on why to use this, see 'Model Ensembles\" section here:\n",
    "# http://cs231n.github.io/neural-networks-3/\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "\n",
    "class ExponentialMovingAverage(Callback):\n",
    "    \"\"\"create a copy of trainable weights which gets updated at every\n",
    "       batch using exponential weight decay. The moving average weights along\n",
    "       with the other states of original model(except original model trainable\n",
    "       weights) will be saved at every epoch if save_mv_ave_model is True.\n",
    "       If both save_mv_ave_model and save_best_only are True, the latest\n",
    "       best moving average model according to the quantity monitored\n",
    "       will not be overwritten. Of course, save_best_only can be True\n",
    "       only if there is a validation set.\n",
    "       This is equivalent to save_best_only mode of ModelCheckpoint\n",
    "       callback with similar code. custom_objects is a dictionary\n",
    "       holding name and Class implementation for custom layers.\n",
    "       At end of every batch, the update is as follows:\n",
    "       mv_weight -= (1 - decay) * (mv_weight - weight)\n",
    "       where weight and mv_weight is the ordinal model weight and the moving\n",
    "       averaged weight respectively. At the end of the training, the moving\n",
    "       averaged weights are transferred to the original model.\n",
    "       \"\"\"\n",
    "    def __init__(self, decay=0.999, filepath='temp_weight.hdf5',\n",
    "                 save_mv_ave_model=True, verbose=0,\n",
    "                 save_best_only=False, monitor='val_loss', mode='auto',\n",
    "                 save_weights_only=False, custom_objects={}):\n",
    "        self.decay = decay\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_mv_ave_model = save_mv_ave_model\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.save_best_only = save_best_only\n",
    "        self.monitor = monitor\n",
    "        self.custom_objects = custom_objects  # dictionary of custom layers\n",
    "        self.sym_trainable_weights = None  # trainable weights of model\n",
    "        self.mv_trainable_weights_vals = None  # moving averaged values\n",
    "        super(ExponentialMovingAverage, self).__init__()\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor:\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.sym_trainable_weights = self.model.trainable_weights\n",
    "        # Initialize moving averaged weights using original model values\n",
    "        self.mv_trainable_weights_vals = {x.name: K.get_value(x) for x in\n",
    "                                          self.sym_trainable_weights}\n",
    "        if self.verbose:\n",
    "            print('Created a copy of model weights to initialize moving'\n",
    "                  ' averaged weights.')\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        for weight in self.sym_trainable_weights:\n",
    "            old_val = self.mv_trainable_weights_vals[weight.name]\n",
    "            self.mv_trainable_weights_vals[weight.name] -= \\\n",
    "                (1.0 - self.decay) * (old_val - K.get_value(weight))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \"\"\"After each epoch, we can optionally save the moving averaged model,\n",
    "        but the weights will NOT be transferred to the original model. This\n",
    "        happens only at the end of training. We also need to transfer state of\n",
    "        original model to model2 as model2 only gets updated trainable weight\n",
    "        at end of each batch and non-trainable weights are not transferred\n",
    "        (for example mean and var for batch normalization layers).\"\"\"\n",
    "        if self.save_mv_ave_model:\n",
    "            filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = logs.get(self.monitor)\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best moving averaged model only '\n",
    "                                  'with %s available, skipping.'\n",
    "                                  % (self.monitor), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('saving moving average model to %s'\n",
    "                                  % (filepath))\n",
    "                        self.best = current\n",
    "                        model2 = self._make_mv_model(filepath)\n",
    "                        if self.save_weights_only:\n",
    "                            model2.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            model2.save(filepath, overwrite=True)\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving moving average model to %s' % (epoch, filepath))\n",
    "                model2 = self._make_mv_model(filepath)\n",
    "                if self.save_weights_only:\n",
    "                    model2.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    model2.save(filepath, overwrite=True)\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        for weight in self.sym_trainable_weights:\n",
    "            K.set_value(weight, self.mv_trainable_weights_vals[weight.name])\n",
    "\n",
    "    def _make_mv_model(self, filepath):\n",
    "        \"\"\" Create a model with moving averaged weights. Other variables are\n",
    "        the same as original mode. We first save original model to save its\n",
    "        state. Then copy moving averaged weights over.\"\"\"\n",
    "        self.model.save(filepath, overwrite=True)\n",
    "        model2 = load_model(filepath, custom_objects=self.custom_objects)\n",
    "\n",
    "        for w2, w in zip(model2.trainable_weights, self.model.trainable_weights):\n",
    "            K.set_value(w2, self.mv_trainable_weights_vals[w.name])\n",
    "\n",
    "        return model2\n",
    "\n",
    "\n",
    "def batch_generator(X, y=None, batch_size=128, shuffle=False):\n",
    "    index = np.arange(X.shape[0])\n",
    "\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(index)\n",
    "\n",
    "        batch_start = 0\n",
    "        while batch_start < X.shape[0]:\n",
    "            batch_index = index[batch_start:batch_start + batch_size]\n",
    "            batch_start += batch_size\n",
    "\n",
    "            X_batch = X[batch_index, :]\n",
    "\n",
    "            if sp.issparse(X_batch):\n",
    "                X_batch = X_batch.toarray()\n",
    "\n",
    "            if y is None:\n",
    "                yield X_batch\n",
    "            else:\n",
    "                yield X_batch, y[batch_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1153)\n",
      "(188318,)\n",
      "(125546, 131)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "cat_names = [c for c in train.columns if 'cat' in c]\n",
    "\n",
    "train = pd.get_dummies(data=train, columns=cat_names)\n",
    "\n",
    "features = [x for x in train.columns if x not in ['id','loss']]\n",
    "\n",
    "train_x = np.array(train[features])\n",
    "\n",
    "ntrain = train_x.shape[0]\n",
    "\n",
    "# np.log(train['loss'] + 200) provides\n",
    "# a better score, but let's keep it simple now\n",
    "train_y = np.array(train['loss'])\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print (train_x.shape)\n",
    "print (train_y.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cdn.rawgit.com/dnkirill/allstate_capstone/master/images/mlp3.svg\"></td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnmodel = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnmodel['nn%d'%1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nn1': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "def hyper_model(seed = None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(437, input_dim=train_x.shape[1], init=he_normal(seed = seed)\n",
    "                    ,W_regularizer=l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.536))\n",
    "    \n",
    "    model.add(Dense(182, init=he_normal(seed = seed),W_regularizer=l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(73, init=he_normal(seed = seed),W_regularizer=l2(0.002)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.233))\n",
    "    \n",
    "    model.add(Dense(1, init=he_normal(seed = seed),W_regularizer=l2(0.002)))\n",
    "    model.compile(loss='mae', optimizer='adadelta')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((2,2))\n",
    "a[0,[True,False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=2,nbags=2):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nbags,))\n",
    "    stack_train = np.zeros((nbags,len(train_y)))\n",
    "    stack_test = np.zeros((nbags,len(test)))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        for bag in range(nbags):\n",
    "            nnmodel['nn%d',k*10+bag*1] = mlp_func(seed = k*10+bag*1)\n",
    "            #early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            fit = nnmodel['nn%d',k*10+bag*1].fit(xtr, ytr, validation_split=0.2, batch_size=128,\n",
    "                          nb_epoch=1, verbose=1, callbacks=[ExponentialMovingAverage(save_mv_ave_model=False)])\n",
    "            pred = nnmodel['nn%d',k*10+bag*1].predict(xte, batch_size=256)\n",
    "            score = mean_absolute_error(yte, pred)\n",
    "            val_scores[bag] += score\n",
    "            stack_train[bag][test_index] = pred[:,0]\n",
    "    for bag in range(nbags):\n",
    "        avg_score = val_scores[bag] / float(nfolds)\n",
    "    print (avg_score)\n",
    "    return val_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(437, input_dim=1153, kernel_initializer=<keras.ini..., kernel_regularizer=<keras.reg...)`\n",
      "  import sys\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(182, kernel_initializer=<keras.ini..., kernel_regularizer=<keras.reg...)`\n",
      "  if sys.path[0] == '':\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(73, kernel_initializer=<keras.ini..., kernel_regularizer=<keras.reg...)`\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=<keras.ini..., kernel_regularizer=<keras.reg...)`\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 75327 samples, validate on 18832 samples\n",
      "Epoch 1/1\n",
      "75327/75327 [==============================] - 14s 191us/step - loss: 2691.5814 - val_loss: 1664.4522\n",
      "Train on 75327 samples, validate on 18832 samples\n",
      "Epoch 1/1\n",
      "75327/75327 [==============================] - 15s 198us/step - loss: 2565.6207 - val_loss: 1513.4816\n",
      "Train on 75327 samples, validate on 18832 samples\n",
      "Epoch 1/1\n",
      "75327/75327 [==============================] - 15s 198us/step - loss: 2632.8140 - val_loss: 1919.4477\n",
      "Train on 75327 samples, validate on 18832 samples\n",
      "Epoch 1/1\n",
      "75327/75327 [==============================] - 15s 202us/step - loss: 2771.6588 - val_loss: 1945.3880\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_bags' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-9eda43c7bf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyper_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"CV score for the final model:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-a37bf31a4394>\u001b[0m in \u001b[0;36mcross_validate_mlp\u001b[0;34m(mlp_func, nfolds, nbags)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mval_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mstack_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbag\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mavg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mavg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_bags' is not defined"
     ]
    }
   ],
   "source": [
    "cv_score = cross_validate_mlp(hyper_model)\n",
    "print (\"CV score for the final model:\", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, \n",
    " 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 73, 'optimizer': 'adadelta',\n",
    " 'wdecay': 0.0020300000000000001}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this model is not adapted for mere 30 epochs of training, nor for 3-fold CV (I used 5-fold on Kaggle), even though this is a single unbagged model which has been cross-validated on three folds only, we see a very good score:\n",
    "`CV = 1150` (your score may vary a little).\n",
    "\n",
    "By the way, this single model, bagged, 5-fold CVed, scored 1116.28 on Kaggle LB.\n",
    "\n",
    "As we see, this model is considerably better than any other models we had so far. We now take it as the second part of our final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'l3-nn': {\n",
    "        'predictions': l2_predictions,\n",
    "        'n_bags': 4,\n",
    "        'model': Keras(nn_lr, lambda: {'l1': 1e-5, 'l2': 1e-5, 'n_epoch': 30, 'batch_size': 128, 'optimizer': SGD(3e-2, momentum=0.8, nesterov=True, decay=3e-5), 'callbacks': [ExponentialMovingAverage(save_mv_ave_model=False)]}),\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=3):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nfolds,))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        mlp = mlp_func()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        fit = mlp.fit(xtr, ytr, validation_split=0.2, batch_size=128, \n",
    "                      nb_epoch=30, verbose=0, callbacks=[early_stopping])\n",
    "        pred = mlp.predict(xte, batch_size=256)\n",
    "        score = mean_absolute_error(yte, pred)\n",
    "        val_scores[k] += score\n",
    "        print ('Fold {}, MAE: {}'.format(k, score))\n",
    "    avg_score = np.sum(val_scores) / float(nfolds)\n",
    "    print ('{}-fold CV score: {}'.format(nfolds, avg_score))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing: {'hidden1_dropout': 0.4210526315789474, 'hidden1_units': 455, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 272, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 69, 'optimizer': 'adadelta', 'wdecay': 0.032330000000000005}\n",
      "Fold 0, MAE: 1163.148839039124\n",
      "Fold 1, MAE: 1159.9899238609737\n",
      "Fold 2, MAE: 1140.9771315408389\n",
      "3-fold CV score: 1154.7052981469787\n",
      "Model Testing: {'hidden1_dropout': 0.57894736842105265, 'hidden1_units': 541, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 134, 'hidden3_dropout': 0.10000000000000001, 'hidden3_units': 30, 'optimizer': 'adadelta', 'wdecay': 0.082830000000000001}\n",
      "Fold 0, MAE: 1181.2090776051534\n",
      "Fold 1, MAE: 1175.7242010975745\n",
      "Fold 2, MAE: 1149.1617817128606\n",
      "3-fold CV score: 1168.698353471863\n",
      "Model Testing: {'hidden1_dropout': 0.57894736842105265, 'hidden1_units': 541, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 113, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 22, 'optimizer': 'adam', 'wdecay': 0.010110000000000001}\n",
      "Fold 0, MAE: 1161.0922305512295\n",
      "Fold 1, MAE: 1171.8751691438747\n",
      "Fold 2, MAE: 1142.5130553590734\n",
      "3-fold CV score: 1158.4934850180591\n",
      "Model Testing: {'hidden1_dropout': 0.56842105263157894, 'hidden1_units': 351, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 168, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 44, 'optimizer': 'adam', 'wdecay': 0.066669999999999993}\n",
      "Fold 0, MAE: 1175.3901692187044\n",
      "Fold 1, MAE: 1176.3282762184622\n",
      "Fold 2, MAE: 1171.493253623609\n",
      "3-fold CV score: 1174.4038996869251\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 351, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 237, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 28, 'optimizer': 'adam', 'wdecay': 0.0040499999999999998}\n",
      "Fold 0, MAE: 1167.663476455973\n",
      "Fold 1, MAE: 1158.721241361386\n",
      "Fold 2, MAE: 1148.2196995976833\n",
      "3-fold CV score: 1158.2014724716807\n",
      "Model Testing: {'hidden1_dropout': 0.45263157894736844, 'hidden1_units': 437, 'hidden2_dropout': 0.5, 'hidden2_units': 120, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 30, 'optimizer': 'adam', 'wdecay': 0.055560000000000005}\n",
      "Fold 0, MAE: 1192.865180594892\n",
      "Fold 1, MAE: 1170.481112811505\n",
      "Fold 2, MAE: 1171.0399158641085\n",
      "3-fold CV score: 1178.128736423502\n",
      "Model Testing: {'hidden1_dropout': 0.41052631578947368, 'hidden1_units': 368, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 237, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 34, 'optimizer': 'adadelta', 'wdecay': 0.082830000000000001}\n",
      "Fold 0, MAE: 1163.6607907634843\n",
      "Fold 1, MAE: 1170.6899247157944\n",
      "Fold 2, MAE: 1149.6886504229296\n",
      "3-fold CV score: 1161.3464553007361\n",
      "Model Testing: {'hidden1_dropout': 0.57894736842105265, 'hidden1_units': 394, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 217, 'hidden3_dropout': 0.5, 'hidden3_units': 26, 'optimizer': 'adadelta', 'wdecay': 0.086870000000000003}\n",
      "Fold 0, MAE: 1186.010471694171\n",
      "Fold 1, MAE: 1194.6887222751257\n",
      "Fold 2, MAE: 1178.986956053622\n",
      "3-fold CV score: 1186.5620500076395\n",
      "Model Testing: {'hidden1_dropout': 0.4210526315789474, 'hidden1_units': 550, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 175, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 30, 'optimizer': 'adadelta', 'wdecay': 0.054550000000000008}\n",
      "Fold 0, MAE: 1173.4874602173836\n",
      "Fold 1, MAE: 1168.5583186899196\n",
      "Fold 2, MAE: 1157.0938108456683\n",
      "3-fold CV score: 1166.3798632509906\n",
      "Model Testing: {'hidden1_dropout': 0.41052631578947368, 'hidden1_units': 420, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 272, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 20, 'optimizer': 'adam', 'wdecay': 0.051520000000000003}\n",
      "Fold 0, MAE: 1187.3547460026052\n",
      "Fold 1, MAE: 1165.0640505257604\n",
      "Fold 2, MAE: 1152.0578003723883\n",
      "3-fold CV score: 1168.1588656335846\n",
      "Model Testing: {'hidden1_dropout': 0.49473684210526314, 'hidden1_units': 506, 'hidden2_dropout': 0.5, 'hidden2_units': 155, 'hidden3_dropout': 0.5, 'hidden3_units': 38, 'optimizer': 'adam', 'wdecay': 0.0030400000000000002}\n",
      "Fold 0, MAE: 1165.5917111922117\n",
      "Fold 1, MAE: 1157.0224820727203\n",
      "Fold 2, MAE: 1145.9990145378135\n",
      "3-fold CV score: 1156.2044026009153\n",
      "Model Testing: {'hidden1_dropout': 0.52631578947368418, 'hidden1_units': 550, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 217, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 46, 'optimizer': 'adadelta', 'wdecay': 0.053540000000000004}\n",
      "Fold 0, MAE: 1178.285182548254\n",
      "Fold 1, MAE: 1161.227306544953\n",
      "Fold 2, MAE: 1146.3369486137735\n",
      "3-fold CV score: 1161.9498125689936\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 308, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 100, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 48, 'optimizer': 'adadelta', 'wdecay': 0.083839999999999998}\n",
      "Fold 0, MAE: 1175.8002146167726\n",
      "Fold 1, MAE: 1172.0227174765078\n",
      "Fold 2, MAE: 1154.2503788092345\n",
      "3-fold CV score: 1167.3577703008384\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 446, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 217, 'hidden3_dropout': 0.5, 'hidden3_units': 22, 'optimizer': 'adadelta', 'wdecay': 0.089899999999999994}\n",
      "Fold 0, MAE: 1198.0498968117809\n",
      "Fold 1, MAE: 1192.423294968826\n",
      "Fold 2, MAE: 1191.1537727940815\n",
      "3-fold CV score: 1193.8756548582294\n",
      "Model Testing: {'hidden1_dropout': 0.40000000000000002, 'hidden1_units': 541, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 258, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 75, 'optimizer': 'adadelta', 'wdecay': 0.02324}\n",
      "Fold 0, MAE: 1162.2846737751456\n",
      "Fold 1, MAE: 1157.0434973514984\n",
      "Fold 2, MAE: 1149.8406610896955\n",
      "3-fold CV score: 1156.3896107387798\n",
      "Model Testing: {'hidden1_dropout': 0.4210526315789474, 'hidden1_units': 412, 'hidden2_dropout': 0.5, 'hidden2_units': 203, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 24, 'optimizer': 'adadelta', 'wdecay': 0.065659999999999996}\n",
      "Fold 0, MAE: 1162.6868081304262\n",
      "Fold 1, MAE: 1207.019499323167\n",
      "Fold 2, MAE: 1164.6480082339472\n",
      "3-fold CV score: 1178.1181052291802\n",
      "Model Testing: {'hidden1_dropout': 0.49473684210526314, 'hidden1_units': 386, 'hidden2_dropout': 0.26666666666666666, 'hidden2_units': 113, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 44, 'optimizer': 'adam', 'wdecay': 0.01213}\n",
      "Fold 0, MAE: 1162.20426789193\n",
      "Fold 1, MAE: 1165.871551874401\n",
      "Fold 2, MAE: 1144.635762708466\n",
      "3-fold CV score: 1157.570527491599\n",
      "Model Testing: {'hidden1_dropout': 0.52631578947368418, 'hidden1_units': 489, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 272, 'hidden3_dropout': 0.32222222222222224, 'hidden3_units': 42, 'optimizer': 'adadelta', 'wdecay': 0.047480000000000008}\n",
      "Fold 0, MAE: 1159.1230678129568\n",
      "Fold 1, MAE: 1170.1456261211185\n",
      "Fold 2, MAE: 1141.1387421620404\n",
      "3-fold CV score: 1156.8024786987053\n",
      "Model Testing: {'hidden1_dropout': 0.47368421052631582, 'hidden1_units': 368, 'hidden2_dropout': 0.5, 'hidden2_units': 196, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 61, 'optimizer': 'adam', 'wdecay': 0.076770000000000005}\n",
      "Fold 0, MAE: 1167.3144952524326\n",
      "Fold 1, MAE: 1158.442539164428\n",
      "Fold 2, MAE: 1170.1439974149687\n",
      "3-fold CV score: 1165.3003439439433\n",
      "Model Testing: {'hidden1_dropout': 0.57894736842105265, 'hidden1_units': 325, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 258, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 59, 'optimizer': 'adadelta', 'wdecay': 0.070709999999999995}\n",
      "Fold 0, MAE: 1161.177618771013\n",
      "Fold 1, MAE: 1157.4865109404855\n",
      "Fold 2, MAE: 1143.5037899814306\n",
      "3-fold CV score: 1154.0559732309764\n",
      "Model Testing: {'hidden1_dropout': 0.58947368421052637, 'hidden1_units': 325, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 148, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 69, 'optimizer': 'adadelta', 'wdecay': 0.070709999999999995}\n",
      "Fold 0, MAE: 1169.0057906375498\n",
      "Fold 1, MAE: 1163.4061472146307\n",
      "Fold 2, MAE: 1150.80821222944\n",
      "3-fold CV score: 1161.0733833605402\n",
      "Model Testing: {'hidden1_dropout': 0.44210526315789478, 'hidden1_units': 455, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 258, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 63, 'optimizer': 'adadelta', 'wdecay': 0.032330000000000005}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, MAE: 1160.1148852933434\n",
      "Fold 1, MAE: 1153.5388360438872\n",
      "Fold 2, MAE: 1146.284142179796\n",
      "3-fold CV score: 1153.312621172342\n",
      "Model Testing: {'hidden1_dropout': 0.44210526315789478, 'hidden1_units': 325, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 258, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 59, 'optimizer': 'adadelta', 'wdecay': 0.058590000000000003}\n",
      "Fold 0, MAE: 1159.533359263806\n",
      "Fold 1, MAE: 1154.5401700530679\n",
      "Fold 2, MAE: 1152.34695090863\n",
      "3-fold CV score: 1155.473493408501\n",
      "Model Testing: {'hidden1_dropout': 0.43157894736842106, 'hidden1_units': 377, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 189, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 63, 'optimizer': 'adadelta', 'wdecay': 0.081820000000000004}\n",
      "Fold 0, MAE: 1162.9307342647628\n",
      "Fold 1, MAE: 1177.8290937843656\n",
      "Fold 2, MAE: 1148.0584482485735\n",
      "3-fold CV score: 1162.9394254325673\n",
      "Model Testing: {'hidden1_dropout': 0.55789473684210522, 'hidden1_units': 455, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 162, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 63, 'optimizer': 'adadelta', 'wdecay': 0.091920000000000002}\n",
      "Fold 0, MAE: 1161.4301880915023\n",
      "Fold 1, MAE: 1169.6419220691284\n",
      "Fold 2, MAE: 1144.48012878803\n",
      "3-fold CV score: 1158.5174129828868\n",
      "Model Testing: {'hidden1_dropout': 0.50526315789473686, 'hidden1_units': 472, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 279, 'hidden3_dropout': 0.27777777777777779, 'hidden3_units': 77, 'optimizer': 'adadelta', 'wdecay': 0.069699999999999998}\n",
      "Fold 0, MAE: 1158.2613808574185\n",
      "Fold 1, MAE: 1156.7999195958928\n",
      "Fold 2, MAE: 1153.1107720208292\n",
      "3-fold CV score: 1156.0573574913803\n",
      "Model Testing: {'hidden1_dropout': 0.4631578947368421, 'hidden1_units': 524, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 265, 'hidden3_dropout': 0.10000000000000001, 'hidden3_units': 40, 'optimizer': 'adadelta', 'wdecay': 0.094950000000000007}\n",
      "Fold 0, MAE: 1195.4596557820985\n",
      "Fold 1, MAE: 1166.5828679966726\n",
      "Fold 2, MAE: 1151.5350493940605\n",
      "3-fold CV score: 1171.1925243909438\n",
      "Model Testing: {'hidden1_dropout': 0.51578947368421058, 'hidden1_units': 498, 'hidden2_dropout': 0.26666666666666666, 'hidden2_units': 231, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 59, 'optimizer': 'adadelta', 'wdecay': 0.08788}\n",
      "Fold 0, MAE: 1166.894567545835\n",
      "Fold 1, MAE: 1158.6302274524644\n",
      "Fold 2, MAE: 1146.4025209941412\n",
      "3-fold CV score: 1157.3091053308135\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 334, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 106, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 53, 'optimizer': 'adadelta', 'wdecay': 0.035360000000000003}\n",
      "Fold 0, MAE: 1156.7171541562705\n",
      "Fold 1, MAE: 1158.617184146834\n",
      "Fold 2, MAE: 1140.9087310499317\n",
      "3-fold CV score: 1152.0810231176786\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 515, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 286, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 71, 'optimizer': 'adadelta', 'wdecay': 0.035360000000000003}\n",
      "Fold 0, MAE: 1166.3465921313127\n",
      "Fold 1, MAE: 1155.4647161447238\n",
      "Fold 2, MAE: 1145.8189915304222\n",
      "3-fold CV score: 1155.8767666021529\n",
      "Model Testing: {'hidden1_dropout': 0.44210526315789478, 'hidden1_units': 334, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 106, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 65, 'optimizer': 'adadelta', 'wdecay': 0.052530000000000007}\n",
      "Fold 0, MAE: 1165.2972734181083\n",
      "Fold 1, MAE: 1162.3415273140827\n",
      "Fold 2, MAE: 1143.2022154553692\n",
      "3-fold CV score: 1156.9470053958535\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 481, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 106, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 53, 'optimizer': 'adadelta', 'wdecay': 0.00809}\n",
      "Fold 0, MAE: 1159.2449543552357\n",
      "Fold 1, MAE: 1154.8565114282767\n",
      "Fold 2, MAE: 1140.933696843291\n",
      "3-fold CV score: 1151.6783875422677\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 334, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 106, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 53, 'optimizer': 'adadelta', 'wdecay': 0.014149999999999999}\n",
      "Fold 0, MAE: 1165.0503812670863\n",
      "Fold 1, MAE: 1157.1801844593206\n",
      "Fold 2, MAE: 1141.5077789837922\n",
      "3-fold CV score: 1154.579448236733\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 481, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 106, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 53, 'optimizer': 'adadelta', 'wdecay': 0.00809}\n",
      "Fold 0, MAE: 1162.7622893053533\n",
      "Fold 1, MAE: 1156.484460623302\n",
      "Fold 2, MAE: 1141.2796353609326\n",
      "3-fold CV score: 1153.5087950965292\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 481, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 141, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 53, 'optimizer': 'adam', 'wdecay': 0.025260000000000001}\n",
      "Fold 0, MAE: 1173.398777121047\n",
      "Fold 1, MAE: 1163.4376312509926\n",
      "Fold 2, MAE: 1149.4355696684008\n",
      "3-fold CV score: 1162.0906593468135\n",
      "Model Testing: {'hidden1_dropout': 0.56842105263157894, 'hidden1_units': 343, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 224, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 57, 'optimizer': 'adadelta', 'wdecay': 0.01617}\n",
      "Fold 0, MAE: 1157.8129235479112\n",
      "Fold 1, MAE: 1162.9604955281113\n",
      "Fold 2, MAE: 1137.8848549871118\n",
      "3-fold CV score: 1152.886091354378\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 463, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 210, 'hidden3_dropout': 0.32222222222222224, 'hidden3_units': 67, 'optimizer': 'adam', 'wdecay': 0.028289999999999999}\n",
      "Fold 0, MAE: 1167.1458696599193\n",
      "Fold 1, MAE: 1160.2728405505222\n",
      "Fold 2, MAE: 1154.656251596023\n",
      "3-fold CV score: 1160.6916539354881\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 360, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 300, 'hidden3_dropout': 0.10000000000000001, 'hidden3_units': 32, 'optimizer': 'adadelta', 'wdecay': 0.071720000000000006}\n",
      "Fold 0, MAE: 1157.0820389802964\n",
      "Fold 1, MAE: 1173.8628986425185\n",
      "Fold 2, MAE: 1147.7328339035314\n",
      "3-fold CV score: 1159.5592571754487\n",
      "Model Testing: {'hidden1_dropout': 0.45263157894736844, 'hidden1_units': 317, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 293, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 36, 'optimizer': 'adadelta', 'wdecay': 0.027280000000000002}\n",
      "Fold 0, MAE: 1162.285383334579\n",
      "Fold 1, MAE: 1160.938020819047\n",
      "Fold 2, MAE: 1145.0485755819968\n",
      "3-fold CV score: 1156.0906599118741\n",
      "Model Testing: {'hidden1_dropout': 0.51578947368421058, 'hidden1_units': 429, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 244, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 80, 'optimizer': 'adam', 'wdecay': 0.097979999999999998}\n",
      "Fold 0, MAE: 1187.3501504499832\n",
      "Fold 1, MAE: 1177.8064867953847\n",
      "Fold 2, MAE: 1153.1573311127709\n",
      "3-fold CV score: 1172.7713227860463\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 300, 'hidden2_dropout': 0.30000000000000004, 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 55, 'optimizer': 'adadelta', 'wdecay': 0.0020300000000000001}\n",
      "Fold 0, MAE: 1157.9619118652226\n",
      "Fold 1, MAE: 1155.7216872165664\n",
      "Fold 2, MAE: 1136.927755550967\n",
      "3-fold CV score: 1150.2037848775853\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 300, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 51, 'optimizer': 'adadelta', 'wdecay': 0.0020300000000000001}\n",
      "Fold 0, MAE: 1156.0632860191683\n",
      "Fold 1, MAE: 1151.4671627447715\n",
      "Fold 2, MAE: 1140.1617350157348\n",
      "3-fold CV score: 1149.230727926558\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 300, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 51, 'optimizer': 'adam', 'wdecay': 0.059600000000000007}\n",
      "Fold 0, MAE: 1168.5160545404665\n",
      "Fold 1, MAE: 1175.4194884359572\n",
      "Fold 2, MAE: 1152.5397784139907\n",
      "3-fold CV score: 1165.4917737968046\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 300, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 51, 'optimizer': 'adadelta', 'wdecay': 0.062630000000000005}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0, MAE: 1163.881212321844\n",
      "Fold 1, MAE: 1164.1301011722203\n",
      "Fold 2, MAE: 1150.2623383121809\n",
      "3-fold CV score: 1159.4245506020818\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 532, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 251, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 55, 'optimizer': 'adadelta', 'wdecay': 0.074749999999999997}\n",
      "Fold 0, MAE: 1161.926003949864\n",
      "Fold 1, MAE: 1171.028653969578\n",
      "Fold 2, MAE: 1147.243582406554\n",
      "3-fold CV score: 1160.0660801086653\n",
      "Model Testing: {'hidden1_dropout': 0.5473684210526315, 'hidden1_units': 300, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 127, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 55, 'optimizer': 'adam', 'wdecay': 0.0020300000000000001}\n",
      "Fold 0, MAE: 1157.4905136832626\n",
      "Fold 1, MAE: 1157.7959576055189\n",
      "Fold 2, MAE: 1145.165175664648\n",
      "3-fold CV score: 1153.4838823178097\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 73, 'optimizer': 'adadelta', 'wdecay': 0.0020300000000000001}\n",
      "Fold 0, MAE: 1154.1358029742491\n",
      "Fold 1, MAE: 1150.8801407907292\n",
      "Fold 2, MAE: 1136.143128436801\n",
      "3-fold CV score: 1147.0530240672597\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 134, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 73, 'optimizer': 'adadelta', 'wdecay': 0.088889999999999997}\n",
      "Fold 0, MAE: 1174.4271644173484\n",
      "Fold 1, MAE: 1160.2759364815581\n",
      "Fold 2, MAE: 1143.464337864193\n",
      "3-fold CV score: 1159.3891462543666\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 403, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 120, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 26, 'optimizer': 'adadelta', 'wdecay': 0.079799999999999996}\n",
      "Fold 0, MAE: 1177.3892872402876\n",
      "Fold 1, MAE: 1162.1597504698693\n",
      "Fold 2, MAE: 1156.8215401050213\n",
      "3-fold CV score: 1165.456859271726\n",
      "Model Testing: {'hidden1_dropout': 0.40000000000000002, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 168, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 73, 'optimizer': 'adam', 'wdecay': 0.072730000000000003}\n",
      "Fold 0, MAE: 1210.498220541357\n",
      "Fold 1, MAE: 1184.6350615099377\n",
      "Fold 2, MAE: 1151.241476172358\n",
      "3-fold CV score: 1182.1249194078841\n",
      "Model Testing: {'hidden1_dropout': 0.41052631578947368, 'hidden1_units': 351, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 182, 'hidden3_dropout': 0.5, 'hidden3_units': 20, 'optimizer': 'adadelta', 'wdecay': 0.0293}\n",
      "Fold 0, MAE: 1171.7247792783894\n",
      "Fold 1, MAE: 1176.3316548287394\n",
      "Fold 2, MAE: 1154.8692943033595\n",
      "3-fold CV score: 1167.6419094701625\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 394, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 155, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 34, 'optimizer': 'adadelta', 'wdecay': 0.01516}\n",
      "Fold 0, MAE: 1168.154443232974\n",
      "Fold 1, MAE: 1157.7412081981763\n",
      "Fold 2, MAE: 1141.040754590281\n",
      "3-fold CV score: 1155.6454686738105\n",
      "Model Testing: {'hidden1_dropout': 0.47368421052631582, 'hidden1_units': 420, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 237, 'hidden3_dropout': 0.32222222222222224, 'hidden3_units': 28, 'optimizer': 'adam', 'wdecay': 0.046470000000000004}\n",
      "Fold 0, MAE: 1164.3777441806067\n",
      "Fold 1, MAE: 1177.209987984398\n",
      "Fold 2, MAE: 1155.6756505514757\n",
      "3-fold CV score: 1165.7544609054933\n",
      "Model Testing: {'hidden1_dropout': 0.58947368421052637, 'hidden1_units': 437, 'hidden2_dropout': 0.26666666666666666, 'hidden2_units': 175, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 38, 'optimizer': 'adadelta', 'wdecay': 0.0020300000000000001}\n",
      "Fold 0, MAE: 1156.644832466085\n",
      "Fold 1, MAE: 1157.6123849948424\n",
      "Fold 2, MAE: 1137.0233535830582\n",
      "3-fold CV score: 1150.4268570146621\n",
      "Model Testing: {'hidden1_dropout': 0.43157894736842106, 'hidden1_units': 506, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 100, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 46, 'optimizer': 'adadelta', 'wdecay': 0.018190000000000001}\n",
      "Fold 0, MAE: 1156.7325890863394\n",
      "Fold 1, MAE: 1163.3614326980687\n",
      "Fold 2, MAE: 1140.6892231279783\n",
      "3-fold CV score: 1153.5944149707955\n",
      "Model Testing: {'hidden1_dropout': 0.55789473684210522, 'hidden1_units': 308, 'hidden2_dropout': 0.5, 'hidden2_units': 203, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 48, 'optimizer': 'adadelta', 'wdecay': 0.067680000000000004}\n",
      "Fold 0, MAE: 1187.777674460418\n",
      "Fold 1, MAE: 1164.7113053835535\n",
      "Fold 2, MAE: 1148.0043875643821\n",
      "3-fold CV score: 1166.8311224694514\n",
      "Model Testing: {'hidden1_dropout': 0.4631578947368421, 'hidden1_units': 386, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 182, 'hidden3_dropout': 0.10000000000000001, 'hidden3_units': 51, 'optimizer': 'adadelta', 'wdecay': 0.080810000000000007}\n",
      "Fold 0, MAE: 1165.0194917910676\n",
      "Fold 1, MAE: 1158.2729473606164\n",
      "Fold 2, MAE: 1152.9800377245338\n",
      "3-fold CV score: 1158.7574922920726\n",
      "Model Testing: {'hidden1_dropout': 0.49473684210526314, 'hidden1_units': 412, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 196, 'hidden3_dropout': 0.5, 'hidden3_units': 75, 'optimizer': 'adam', 'wdecay': 0.038390000000000007}\n",
      "Fold 0, MAE: 1161.5217347156527\n",
      "Fold 1, MAE: 1162.386833252451\n",
      "Fold 2, MAE: 1145.6365952047393\n",
      "3-fold CV score: 1156.5150543909476\n",
      "Model Testing: {'hidden1_dropout': 0.52631578947368418, 'hidden1_units': 446, 'hidden2_dropout': 0.40000000000000002, 'hidden2_units': 148, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 73, 'optimizer': 'adadelta', 'wdecay': 0.096970000000000001}\n",
      "Fold 0, MAE: 1160.2965376990726\n",
      "Fold 1, MAE: 1168.4996048508942\n",
      "Fold 2, MAE: 1149.110823150734\n",
      "3-fold CV score: 1159.3023219002337\n",
      "Model Testing: {'hidden1_dropout': 0.4210526315789474, 'hidden1_units': 489, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 113, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 42, 'optimizer': 'adadelta', 'wdecay': 0.060610000000000004}\n",
      "Fold 0, MAE: 1183.286138317614\n",
      "Fold 1, MAE: 1177.9553902909124\n",
      "Fold 2, MAE: 1155.3975773011248\n",
      "3-fold CV score: 1172.2130353032169\n",
      "Model Testing: {'hidden1_dropout': 0.50526315789473686, 'hidden1_units': 550, 'hidden2_dropout': 0.26666666666666666, 'hidden2_units': 162, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 24, 'optimizer': 'adadelta', 'wdecay': 0.056570000000000002}\n",
      "Fold 0, MAE: 1161.7203151536628\n",
      "Fold 1, MAE: 1179.3700442916124\n"
     ]
    }
   ],
   "source": [
    "# VERSION 4. Insights:\n",
    "#  why not to test 4-layer architectures?\n",
    "# we need to introduce new optimizers\n",
    "#  adding batch normalization (https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "# Describing the search space\n",
    "space = {'hidden1_dropout': hp.choice('hidden1_dropout', np.linspace(0.4,0.6,20)),\n",
    "        'hidden2_dropout': hp.choice('hidden2_dropout', np.linspace(0.2,0.5,10)),\n",
    "        'hidden3_dropout': hp.choice('hidden3_dropout', np.linspace(0.1,0.5,10)),\n",
    "         'hidden1_units': hp.choice('hidden1_units', np.linspace(300,550,30,dtype='int32')),\n",
    "         'hidden2_units': hp.choice('hidden2_units', np.linspace(100,300,30,dtype='int32')),\n",
    "         'hidden3_units': hp.choice('hidden3_units', np.linspace(20,80,30,dtype='int32')),\n",
    "         'optimizer': hp.choice('optimizer', ['adam','adadelta']),\n",
    "         'wdecay':hp.choice('wdecay', np.linspace(0.00001,0.1,1000)),\n",
    "        }\n",
    "\n",
    "# Implementing a function to minimize\n",
    "def hyperopt_search(params):\n",
    "    print ('Model Testing:', params)\n",
    "    def mlp_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(params['hidden1_units'], input_dim=train_x.shape[1], init='he_normal',\n",
    "                        W_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden1_dropout']))\n",
    "        \n",
    "        model.add(Dense(params['hidden2_units'], init='he_normal',W_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden2_dropout']))\n",
    "\n",
    "        model.add(Dense(params['hidden3_units'], init='he_normal',W_regularizer=l2(params['wdecay']))) \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden3_dropout']))\n",
    "        \n",
    "        model.add(Dense(1, init='he_normal',W_regularizer=l2(params['wdecay'])))\n",
    "        model.compile(loss='mae', optimizer=params['optimizer'])\n",
    "        return model\n",
    "    \n",
    "    cv_score = cross_validate_mlp(mlp_model)\n",
    "    return {'loss': cv_score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# UNCOMMENT THE NEXT LINE TO LAUNCH HYPEROPT:\n",
    "best = fmin(hyperopt_search, space, algo=tpe.suggest, max_evals = 100, trials=trials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

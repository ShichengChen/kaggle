{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: 116\n",
      "Numerical features: 14\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "cat_features = [x for x in train.select_dtypes(\n",
    "        include=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "num_features = [x for x in train.select_dtypes(\n",
    "        exclude=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "print \"Categorical features:\", len(cat_features)\n",
    "print \"Numerical features:\", len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels)),False\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat)),False\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: 'np.nan' if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True,na_sentinel=-1)[0]\n",
    "    joined[column] = joined[column] + 1\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "lgtrain = lgb.Dataset(X, label=y,categorical_feature=cat_features,)\n",
    "lgtest = lgb.Dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0= time.time()\n",
    "space4lgb = {\n",
    "    'max_depth': hp.choice('max_depth', range(3,29)),\n",
    "    'min_child_weight':hp.choice('min_child_weight',range(2,100)),\n",
    "    'num_leaves':hp.choice('num_leaves',range(50,400)),\n",
    "    \n",
    "    'min_split_gain':hp.choice('min_split_gain',[ 0.01 * i for i in range(0,100)]),\n",
    "    'colsample_bytree':hp.choice('colsample_bytree',[ 0.01 * i for i in range(50,100)]),\n",
    "    'subsample':hp.choice('subsample',[ 0.01 * i for i in range(50,100)]),\n",
    "    \n",
    "    'subsample_freq':hp.choice('subsample_freq',range(0,10)),\n",
    "    \n",
    "    'reg_alpha':hp.uniform('reg_alpha',0,1000),\n",
    "    'reg_lambda':hp.uniform('reg_lambda',0,1000),\n",
    "    \n",
    "    'nthread': hp.choice('nthread', [10]),\n",
    "}\n",
    "minacc = 1512.60244356\n",
    "def optf(params): \n",
    "    cv_result_lgb = lgb.cv(params, lgtrain, num_boost_round=100, nfold=3, \n",
    "                           stratified=False,categorical_feature=cat_features,\n",
    "                    feval=evalerror, early_stopping_rounds=5) \n",
    "    acc = cv_result_lgb['mae-mean'][-1]\n",
    "    print acc\n",
    "    global minacc\n",
    "    if acc < minacc:\n",
    "        minacc = acc\n",
    "        print 'new best:', minacc, params\n",
    "        \n",
    "        with open(\"lgbparams.txt\", \"a\") as text_file:\n",
    "            text_file.write('socre:{}, params:{}\\n'.format(minacc,params))\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:1004: UserWarning: categorical_feature in Dataset is overrided. New categorical_feature is ['cat1', 'cat10', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104', 'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat11', 'cat110', 'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cat12', 'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19', 'cat2', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25', 'cat26', 'cat27', 'cat28', 'cat29', 'cat3', 'cat30', 'cat31', 'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38', 'cat39', 'cat4', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44', 'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat5', 'cat50', 'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57', 'cat58', 'cat59', 'cat6', 'cat60', 'cat61', 'cat62', 'cat63', 'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat7', 'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76', 'cat77', 'cat78', 'cat79', 'cat8', 'cat80', 'cat81', 'cat82', 'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89', 'cat9', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95', 'cat96', 'cat97', 'cat98', 'cat99']\n",
      "  warnings.warn('categorical_feature in Dataset is overrided. New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1270.19421331\n",
      "new best: 1270.19421331 {'num_leaves': 344, 'reg_alpha': 854.9946380195793, 'subsample_freq': 7, 'colsample_bytree': 0.6900000000000001, 'verbose': 1, 'nthread': 10, 'min_child_weight': 39, 'min_split_gain': 0.22, 'subsample': 0.79, 'reg_lambda': 380.092886126646, 'max_bin': 255, 'categorical_column': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115], 'max_depth': 6}\n",
      "Rerunning from 1 trials to 2 (+1) trials\n",
      "1282.11649259\n",
      "Rerunning from 2 trials to 3 (+1) trials\n",
      "1198.12102817\n",
      "new best: 1198.12102817 {'num_leaves': 367, 'reg_alpha': 102.31314041450234, 'subsample_freq': 7, 'colsample_bytree': 0.8200000000000001, 'verbose': 1, 'nthread': 10, 'min_child_weight': 52, 'min_split_gain': 0.27, 'subsample': 0.53, 'reg_lambda': 197.13936826784752, 'max_depth': 6}\n",
      "Rerunning from 3 trials to 4 (+1) trials\n",
      "1236.85368127\n",
      "Rerunning from 4 trials to 5 (+1) trials\n",
      "1234.57294029\n",
      "Rerunning from 5 trials to 6 (+1) trials\n",
      "1273.66439596\n",
      "Rerunning from 6 trials to 7 (+1) trials\n",
      "1238.21391713\n",
      "Rerunning from 7 trials to 8 (+1) trials\n",
      "1278.45190866\n",
      "Rerunning from 8 trials to 9 (+1) trials\n",
      "1256.54891886\n",
      "Rerunning from 9 trials to 10 (+1) trials\n",
      "1179.64525762\n",
      "new best: 1179.64525762 {'num_leaves': 185, 'reg_alpha': 55.11521572530809, 'subsample_freq': 4, 'colsample_bytree': 0.75, 'verbose': 1, 'nthread': 10, 'min_child_weight': 75, 'min_split_gain': 0.53, 'subsample': 0.96, 'reg_lambda': 664.0986882572819, 'max_depth': 14}\n",
      "Rerunning from 10 trials to 11 (+1) trials\n",
      "1233.93934813\n",
      "Rerunning from 11 trials to 12 (+1) trials\n",
      "1224.56897495\n",
      "Rerunning from 12 trials to 13 (+1) trials\n",
      "1221.37963062\n",
      "Rerunning from 13 trials to 14 (+1) trials\n",
      "1202.0188261\n",
      "Rerunning from 14 trials to 15 (+1) trials\n",
      "1251.2435393\n",
      "Rerunning from 15 trials to 16 (+1) trials\n",
      "1262.59115721\n",
      "Rerunning from 16 trials to 17 (+1) trials\n",
      "1175.22468487\n",
      "new best: 1175.22468487 {'num_leaves': 338, 'reg_alpha': 18.081400516631984, 'subsample_freq': 5, 'colsample_bytree': 0.8300000000000001, 'verbose': 1, 'nthread': 10, 'min_child_weight': 23, 'min_split_gain': 0.16, 'subsample': 0.78, 'reg_lambda': 214.66622979514415, 'max_depth': 25}\n",
      "Rerunning from 17 trials to 18 (+1) trials\n",
      "1232.9439693\n",
      "Rerunning from 18 trials to 19 (+1) trials\n",
      "1312.1977878\n",
      "Rerunning from 19 trials to 20 (+1) trials\n",
      "1262.07296242\n",
      "Rerunning from 20 trials to 21 (+1) trials\n",
      "1306.59983794\n",
      "Rerunning from 21 trials to 22 (+1) trials\n",
      "1275.44486673\n",
      "Rerunning from 22 trials to 23 (+1) trials\n",
      "1274.87003448\n",
      "Rerunning from 23 trials to 24 (+1) trials\n",
      "1297.32084248\n",
      "Rerunning from 24 trials to 25 (+1) trials\n",
      "1237.84324545\n",
      "Rerunning from 25 trials to 26 (+1) trials\n",
      "1268.47540701\n",
      "Rerunning from 26 trials to 27 (+1) trials\n",
      "1278.10958186\n",
      "Rerunning from 27 trials to 28 (+1) trials\n",
      "1305.09175579\n",
      "Rerunning from 28 trials to 29 (+1) trials\n",
      "1277.36610907\n",
      "Rerunning from 29 trials to 30 (+1) trials\n",
      "1269.24023623\n",
      "Rerunning from 30 trials to 31 (+1) trials\n",
      "1267.90232227\n",
      "Rerunning from 31 trials to 32 (+1) trials\n",
      "1269.9570118\n",
      "Rerunning from 32 trials to 33 (+1) trials\n",
      "1194.63913548\n",
      "Rerunning from 33 trials to 34 (+1) trials\n",
      "1270.97761628\n",
      "Rerunning from 34 trials to 35 (+1) trials\n",
      "1276.99427072\n",
      "Rerunning from 35 trials to 36 (+1) trials\n",
      "1261.77304045\n",
      "Rerunning from 36 trials to 37 (+1) trials\n",
      "1257.80947672\n",
      "Rerunning from 37 trials to 38 (+1) trials\n",
      "1274.39669533\n",
      "Rerunning from 38 trials to 39 (+1) trials\n",
      "1287.57758994\n",
      "Rerunning from 39 trials to 40 (+1) trials\n",
      "1269.06405851\n",
      "Rerunning from 40 trials to 41 (+1) trials\n",
      "1283.64609086\n",
      "Rerunning from 41 trials to 42 (+1) trials\n",
      "1260.76262583\n",
      "Rerunning from 42 trials to 43 (+1) trials\n",
      "1205.47797861\n",
      "Rerunning from 43 trials to 44 (+1) trials\n",
      "1272.03024331\n",
      "Rerunning from 44 trials to 45 (+1) trials\n",
      "1214.78743343\n",
      "Rerunning from 45 trials to 46 (+1) trials\n",
      "1265.94767325\n",
      "Rerunning from 46 trials to 47 (+1) trials\n",
      "1267.22367959\n",
      "Rerunning from 47 trials to 48 (+1) trials\n",
      "1238.31935031\n",
      "Rerunning from 48 trials to 49 (+1) trials\n",
      "1268.0207702\n",
      "Rerunning from 49 trials to 50 (+1) trials\n"
     ]
    }
   ],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"/home/phe002/shicheng/dataset/lgbhyperopt\", \"rb\"))\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn=optf, space=space4lgb, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "    # save the trials object\n",
    "    with open(\"/home/phe002/shicheng/dataset/lgbhyperopt\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "\n",
    "# loop indefinitely and stop whenever you like\n",
    "while True:\n",
    "    run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

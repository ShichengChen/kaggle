{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:50:50.824152Z",
     "start_time": "2017-11-13T13:50:48.778117Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "'''import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from keras.layers import Dense, Activation, concatenate, Reshape,Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import regularizers\n",
    "from keras.initializers import he_normal\n",
    "from keras.regularizers import l2\n",
    "from keras.activations import selu\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:37.969687Z",
     "start_time": "2017-11-13T13:51:27.815222Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "ntrain = len(train)\n",
    "ids = test['id']\n",
    "test['loss'] = np.nan\n",
    "dataset = pd.DataFrame()\n",
    "joined = pd.concat([train, test])\n",
    "f_num = [f for f in train.columns if 'cont' in f]\n",
    "f_cat = [f for f in train.columns if 'cat' in f]\n",
    "for column in f_cat:\n",
    "    if (train[column].nunique() != test[column].nunique()\n",
    "        or (train[column].unique() != test[column].unique()).any()):\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        \n",
    "        remove = ((set_train - set_test)|(set_test - set_train))\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "        myfilter = lambda x: np.nan if x in remove else x\n",
    "        joined[column] = joined[column].apply(filter_cat, 1)\n",
    "\n",
    "    dataset[column] = pd.factorize(joined[column].values, sort=True)[0] + 1\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "#train_y = np.log(train['loss'] + shift)\n",
    "train_y=train['loss']\n",
    "train_x = train.drop(['loss', 'id'], 1)\n",
    "test = test.drop(['loss', 'id'], 1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "contx = scaler.fit_transform(train_x[f_num])\n",
    "catx = pd.get_dummies(data=train_x[f_cat],columns=f_cat,dummy_na=False)\n",
    "test = pd.get_dummies(data=test,columns=f_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:37.994859Z",
     "start_time": "2017-11-13T13:51:37.971909Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat116_MU</th>\n",
       "      <th>cat116_MV</th>\n",
       "      <th>cat116_MW</th>\n",
       "      <th>cat116_O</th>\n",
       "      <th>cat116_Q</th>\n",
       "      <th>cat116_R</th>\n",
       "      <th>cat116_S</th>\n",
       "      <th>cat116_T</th>\n",
       "      <th>cat116_U</th>\n",
       "      <th>cat116_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321594</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.246911</td>\n",
       "      <td>0.402922</td>\n",
       "      <td>0.281143</td>\n",
       "      <td>0.466591</td>\n",
       "      <td>0.317681</td>\n",
       "      <td>0.61229</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.38016</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.634734</td>\n",
       "      <td>0.620805</td>\n",
       "      <td>0.654310</td>\n",
       "      <td>0.946616</td>\n",
       "      <td>0.836443</td>\n",
       "      <td>0.482425</td>\n",
       "      <td>0.443760</td>\n",
       "      <td>0.71330</td>\n",
       "      <td>0.51890</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.290813</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.711159</td>\n",
       "      <td>0.412789</td>\n",
       "      <td>0.718531</td>\n",
       "      <td>0.212308</td>\n",
       "      <td>0.325779</td>\n",
       "      <td>0.29758</td>\n",
       "      <td>0.34365</td>\n",
       "      <td>0.30529</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.268622</td>\n",
       "      <td>0.681761</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.354893</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.369930</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.40028</td>\n",
       "      <td>0.33237</td>\n",
       "      <td>0.31480</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.299102</td>\n",
       "      <td>0.263570</td>\n",
       "      <td>0.696873</td>\n",
       "      <td>0.302678</td>\n",
       "      <td>0.398862</td>\n",
       "      <td>0.391833</td>\n",
       "      <td>0.23688</td>\n",
       "      <td>0.43731</td>\n",
       "      <td>0.50556</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1079 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0  0.321594  0.299102  0.246911  0.402922  0.281143  0.466591  0.317681   \n",
       "1  0.634734  0.620805  0.654310  0.946616  0.836443  0.482425  0.443760   \n",
       "2  0.290813  0.737068  0.711159  0.412789  0.718531  0.212308  0.325779   \n",
       "3  0.268622  0.681761  0.592681  0.354893  0.397069  0.369930  0.342355   \n",
       "4  0.553846  0.299102  0.263570  0.696873  0.302678  0.398862  0.391833   \n",
       "\n",
       "     cont8    cont9   cont10    ...     cat116_MU  cat116_MV  cat116_MW  \\\n",
       "0  0.61229  0.34365  0.38016    ...             0          0          0   \n",
       "1  0.71330  0.51890  0.60401    ...             0          0          0   \n",
       "2  0.29758  0.34365  0.30529    ...             0          0          0   \n",
       "3  0.40028  0.33237  0.31480    ...             0          0          0   \n",
       "4  0.23688  0.43731  0.50556    ...             0          0          0   \n",
       "\n",
       "   cat116_O  cat116_Q  cat116_R  cat116_S  cat116_T  cat116_U  cat116_Y  \n",
       "0         0         0         0         0         0         0         0  \n",
       "1         0         0         0         0         0         0         0  \n",
       "2         0         0         0         0         0         0         0  \n",
       "3         0         0         0         0         0         0         0  \n",
       "4         0         0         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 1079 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:41.073169Z",
     "start_time": "2017-11-13T13:51:37.996290Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in catx.columns:\n",
    "    a = catx[i].sum()\n",
    "    b = test[i].sum()\n",
    "    if(a < 100 | b < 100):\n",
    "        del catx[i]\n",
    "        del test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.028416Z",
     "start_time": "2017-11-13T13:51:41.074939Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1065) (188318, 14)\n",
      "(188318, 1079)\n",
      "(125546, 1079)\n",
      "(188318,)\n"
     ]
    }
   ],
   "source": [
    "print (catx.shape,contx.shape)\n",
    "test = test.values\n",
    "train_x = np.concatenate((contx,catx.values),axis=1)\n",
    "\n",
    "print (train_x.shape)\n",
    "print (test.shape)\n",
    "print (train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.035640Z",
     "start_time": "2017-11-13T13:51:42.030057Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true)-K.exp(y_pred)), axis=-1)\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint('weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', \n",
    "                             verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.178504Z",
     "start_time": "2017-11-13T13:51:42.037427Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://cs231n.github.io/neural-networks-3/\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "class ExponentialMovingAverage(Callback):\n",
    "    \"\"\"create a copy of trainable weights which gets updated at every\n",
    "       batch using exponential weight decay. The moving average weights along\n",
    "       with the other states of original model(except original model trainable\n",
    "       weights) will be saved at every epoch if save_mv_ave_model is True.\n",
    "       If both save_mv_ave_model and save_best_only are True, the latest\n",
    "       best moving average model according to the quantity monitored\n",
    "       will not be overwritten. Of course, save_best_only can be True\n",
    "       only if there is a validation set.\n",
    "       This is equivalent to save_best_only mode of ModelCheckpoint\n",
    "       callback with similar code. custom_objects is a dictionary\n",
    "       holding name and Class implementation for custom layers.\n",
    "       At end of every batch, the update is as follows:\n",
    "       mv_weight -= (1 - decay) * (mv_weight - weight)\n",
    "       where weight and mv_weight is the ordinal model weight and the moving\n",
    "       averaged weight respectively. At the end of the training, the moving\n",
    "       averaged weights are transferred to the original model.\n",
    "       \"\"\"\n",
    "    def __init__(self, decay=0.999, filepath='model2/model{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                 save_mv_ave_model=False, verbose=0,\n",
    "                 save_best_only=False, monitor='val_loss', mode='auto',\n",
    "                 save_weights_only=False, custom_objects={}):\n",
    "        self.decay = decay\n",
    "        self.filepath = filepath\n",
    "        self.verbose = verbose\n",
    "        self.save_mv_ave_model = save_mv_ave_model\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.save_best_only = save_best_only\n",
    "        self.monitor = monitor\n",
    "        self.custom_objects = custom_objects  # dictionary of custom layers\n",
    "        self.sym_trainable_weights = None  # trainable weights of model\n",
    "        self.mv_trainable_weights_vals = None  # moving averaged values\n",
    "        self.epochs = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('ModelCheckpoint mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor:\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.sym_trainable_weights = self.model.trainable_weights\n",
    "        # Initialize moving averaged weights using original model values\n",
    "        self.mv_trainable_weights_vals = {x.name: K.get_value(x).copy() for x in\n",
    "                                          self.sym_trainable_weights}\n",
    "        if self.verbose:\n",
    "            print('Created a copy of model weights to initialize moving averaged weights.')\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''old = K.get_value(self.model.trainable_weights[0])\n",
    "        name = self.model.trainable_weights[0].name\n",
    "        assert((old != self.mv_trainable_weights_vals[name]).any())'''\n",
    "        \n",
    "        for weight in self.sym_trainable_weights:\n",
    "            K.set_value(weight, self.mv_trainable_weights_vals[weight.name])\n",
    "\n",
    "        '''old = K.get_value(self.model.trainable_weights[0])\n",
    "        name = self.model.trainable_weights[0].name\n",
    "        assert((old == self.mv_trainable_weights_vals[name]).all())'''\n",
    "            \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        if(self.epochs + 5 > self.params['epochs']):\n",
    "            for weight in self.sym_trainable_weights:\n",
    "                old_val = self.mv_trainable_weights_vals[weight.name].copy()\n",
    "                self.mv_trainable_weights_vals[weight.name] = \\\n",
    "                    old_val * self.decay + (1.0 - self.decay) * K.get_value(weight).copy()\n",
    "            #assert((old_val == self.mv_trainable_weights_vals[weight.name]).all())\n",
    "            #assert((old_val == K.get_value(weight)).all())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.epochs += 1\n",
    "        if(self.epochs + 5 > self.params['epochs']):\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            self.model.save(filepath, overwrite=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.200130Z",
     "start_time": "2017-11-13T13:51:42.180293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cat107</th>\n",
       "      <th>cat108</th>\n",
       "      <th>cat109</th>\n",
       "      <th>cat110</th>\n",
       "      <th>cat111</th>\n",
       "      <th>cat112</th>\n",
       "      <th>cat113</th>\n",
       "      <th>cat114</th>\n",
       "      <th>cat115</th>\n",
       "      <th>cat116</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10   ...    \\\n",
       "0     1     2     1     2     1     1     1     1     2      1   ...     \n",
       "1     1     2     1     1     1     1     1     1     2      2   ...     \n",
       "2     1     2     1     1     2     1     1     1     2      2   ...     \n",
       "3     2     2     1     2     1     1     1     1     2      1   ...     \n",
       "4     1     2     1     2     1     1     1     1     2      2   ...     \n",
       "\n",
       "   cat107  cat108  cat109  cat110  cat111  cat112  cat113  cat114  cat115  \\\n",
       "0      10       7      39      27       3      20      54       1      15   \n",
       "1      11      11      30      59       1      23      37       1      15   \n",
       "2       6       1       3      79       1      29       5       1       9   \n",
       "3      11      11      30      61       3      40       4       1      15   \n",
       "4       7       2      57      45       3      51      37       1      11   \n",
       "\n",
       "   cat116  \n",
       "0     239  \n",
       "1      74  \n",
       "2     135  \n",
       "3      68  \n",
       "4      44  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.342422Z",
     "start_time": "2017-11-13T13:51:42.202611Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasetX = dataset.iloc[:ntrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.348137Z",
     "start_time": "2017-11-13T13:51:42.344398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 116)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.353175Z",
     "start_time": "2017-11-13T13:51:42.349735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188318, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.363785Z",
     "start_time": "2017-11-13T13:51:42.354780Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_list = []\n",
    "\n",
    "X_list.append(contx)\n",
    "for i in f_cat:\n",
    "    X_list.append(datasetX[i].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-13T13:51:42.368405Z",
     "start_time": "2017-11-13T13:51:42.365473Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, Merge\n",
    "from keras.layers import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T10:02:22.147667Z",
     "start_time": "2017-11-15T10:02:22.063883Z"
    }
   },
   "outputs": [],
   "source": [
    "def hyper_model(seed = None):\n",
    "    models = []\n",
    "\n",
    "    cur = Sequential()\n",
    "    cur.add(Dense(13, input_dim=14,kernel_initializer='uniform',kernel_regularizer=l2(0.001)))\n",
    "    cur.add(BatchNormalization())\n",
    "    models.append(cur)\n",
    "    input_shape = 7\n",
    "    for i in f_cat:\n",
    "        cur = Sequential()\n",
    "        num = dataset[i].nunique()\n",
    "        cur.add(Embedding(num, (num + 1) // 2, input_length=1))\n",
    "        input_shape += (num + 1) // 2\n",
    "        cur.add(Reshape(target_shape=((num + 1) // 2,)))\n",
    "        models.append(cur)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Merge(models, mode='concat'))\n",
    "    model.add(Dense(437, kernel_initializer='uniform'\n",
    "                    ,kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.536))\n",
    "    \n",
    "    model.add(Dense(300, kernel_initializer='uniform',kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.4))\n",
    "    \n",
    "    model.add(Dense(73, kernel_initializer='uniform',kernel_regularizer=l2(0.001)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.233))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, kernel_initializer='uniform',kernel_regularizer=l2(0.001)))\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.000)\n",
    "    #model.compile(optimizer='adadelta',loss = 'mae',metrics = [mae_score])\n",
    "    model.compile(optimizer='adam',loss = 'mae')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-15T10:16:58.562238Z",
     "start_time": "2017-11-15T10:02:31.000606Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150654 samples, validate on 37664 samples\n",
      "Epoch 1/90\n",
      "150654/150654 [==============================] - 33s 219us/step - loss: 3037.9546 - val_loss: 3025.2347\n",
      "Epoch 2/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 3031.2872 - val_loss: 3021.1974\n",
      "Epoch 3/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 3021.2453 - val_loss: 3012.9597\n",
      "Epoch 4/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 3007.9542 - val_loss: 2965.5726\n",
      "Epoch 5/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 2991.1463 - val_loss: 2961.5521\n",
      "Epoch 6/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2970.8715 - val_loss: 2944.7107\n",
      "Epoch 7/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2947.2092 - val_loss: 2923.3849\n",
      "Epoch 8/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2920.2509 - val_loss: 2897.2112\n",
      "Epoch 9/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2890.0740 - val_loss: 2868.8303\n",
      "Epoch 10/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2856.8009 - val_loss: 2859.6233\n",
      "Epoch 11/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2820.5691 - val_loss: 2828.7198\n",
      "Epoch 12/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2781.5076 - val_loss: 2760.2747\n",
      "Epoch 13/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2739.8317 - val_loss: 2725.2721\n",
      "Epoch 14/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2695.7567 - val_loss: 2664.2789\n",
      "Epoch 15/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2649.5637 - val_loss: 2487.6788\n",
      "Epoch 16/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2601.5361 - val_loss: 2501.9466\n",
      "Epoch 17/90\n",
      "150654/150654 [==============================] - 9s 58us/step - loss: 2551.8577 - val_loss: 2498.9356\n",
      "Epoch 18/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 2501.1911 - val_loss: 2411.9967\n",
      "Epoch 19/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2449.3484 - val_loss: 6986.6285\n",
      "Epoch 20/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2369.9036 - val_loss: 2395.2779\n",
      "Epoch 21/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 2311.0356 - val_loss: 2374.1121\n",
      "Epoch 22/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 2255.2270 - val_loss: 2232.3943\n",
      "Epoch 23/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 2197.7846 - val_loss: 2209.7531\n",
      "Epoch 24/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 2139.9023 - val_loss: 2139.0145\n",
      "Epoch 25/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2083.1380 - val_loss: 2061.0649\n",
      "Epoch 26/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 2025.2719 - val_loss: 2370.7782\n",
      "Epoch 27/90\n",
      "150654/150654 [==============================] - 9s 58us/step - loss: 1909.6714 - val_loss: 2568.7710\n",
      "Epoch 28/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1833.4064 - val_loss: 1807.8401\n",
      "Epoch 29/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1774.7211 - val_loss: 1707.2492\n",
      "Epoch 30/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1719.6573 - val_loss: 1644.0077\n",
      "Epoch 31/90\n",
      "150654/150654 [==============================] - 9s 58us/step - loss: 1667.0811 - val_loss: 1688.0629\n",
      "Epoch 32/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 1619.2276 - val_loss: 1612.4247\n",
      "Epoch 33/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1572.4587 - val_loss: 1525.1261\n",
      "Epoch 34/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1545.4504 - val_loss: 2832.5884\n",
      "Epoch 35/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1695.1954 - val_loss: 1995.9941\n",
      "Epoch 36/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1563.6758 - val_loss: 8993.9630\n",
      "Epoch 37/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1461.8010 - val_loss: 4307.2013\n",
      "Epoch 38/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1408.8779 - val_loss: 2112.6782\n",
      "Epoch 39/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1372.7302 - val_loss: 1841.2643\n",
      "Epoch 40/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1341.4570 - val_loss: 1538.3831\n",
      "Epoch 41/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1363.0868 - val_loss: 15643.0918\n",
      "Epoch 42/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1315.5150 - val_loss: 7163.9100\n",
      "Epoch 43/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1294.4572 - val_loss: 3925.3743\n",
      "Epoch 44/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1272.4362 - val_loss: 2867.4809\n",
      "Epoch 45/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1251.0509 - val_loss: 2962.0186\n",
      "Epoch 46/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1243.4255 - val_loss: 1362.7680\n",
      "Epoch 47/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1322.6545 - val_loss: 4527.1302\n",
      "Epoch 48/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1443.7060 - val_loss: 8876.4220\n",
      "Epoch 49/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1245.6988 - val_loss: 2878.7573\n",
      "Epoch 50/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1226.3715 - val_loss: 1506.3094\n",
      "Epoch 51/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1218.6383 - val_loss: 1477.9346\n",
      "Epoch 52/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1208.1072 - val_loss: 1520.1071\n",
      "Epoch 53/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1203.7475 - val_loss: 1341.2014\n",
      "Epoch 54/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1200.3585 - val_loss: 1755.8804\n",
      "Epoch 55/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1196.7040 - val_loss: 1249.2028\n",
      "Epoch 56/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1190.3222 - val_loss: 1497.0507\n",
      "Epoch 57/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1195.7341 - val_loss: 1244.6785\n",
      "Epoch 58/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1189.3660 - val_loss: 1574.1656\n",
      "Epoch 59/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1189.2118 - val_loss: 1310.7113\n",
      "Epoch 60/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1185.6675 - val_loss: 1221.5873\n",
      "Epoch 61/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1182.5852 - val_loss: 1295.8877\n",
      "Epoch 62/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1182.1281 - val_loss: 3650.3219\n",
      "Epoch 63/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1424.9175 - val_loss: 2214.7624\n",
      "Epoch 64/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1329.4625 - val_loss: 7507.4833\n",
      "Epoch 65/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1251.6008 - val_loss: 9537.4587\n",
      "Epoch 66/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1231.1580 - val_loss: 6399.6242\n",
      "Epoch 67/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 1221.3067 - val_loss: 3664.9485\n",
      "Epoch 68/90\n",
      "150654/150654 [==============================] - 9s 59us/step - loss: 1215.0874 - val_loss: 2246.9960\n",
      "Epoch 69/90\n",
      "150654/150654 [==============================] - 9s 58us/step - loss: 1207.9988 - val_loss: 2638.4176\n",
      "Epoch 70/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1205.8605 - val_loss: 2075.9310\n",
      "Epoch 71/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1203.9669 - val_loss: 1858.4481\n",
      "Epoch 72/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150654/150654 [==============================] - 9s 61us/step - loss: 1199.0623 - val_loss: 1255.3435\n",
      "Epoch 73/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1196.3549 - val_loss: 2198.3148\n",
      "Epoch 74/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1203.2189 - val_loss: 1695.7604\n",
      "Epoch 75/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1199.4316 - val_loss: 5189.3577\n",
      "Epoch 76/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1195.0975 - val_loss: 2146.7241\n",
      "Epoch 77/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 1192.5070 - val_loss: 1629.0413\n",
      "Epoch 78/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 1190.8038 - val_loss: 1325.0376\n",
      "Epoch 79/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1191.2545 - val_loss: 1393.8638\n",
      "Epoch 80/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1188.2610 - val_loss: 1589.9015\n",
      "Epoch 81/90\n",
      "150654/150654 [==============================] - 10s 64us/step - loss: 1184.8775 - val_loss: 3843.2379\n",
      "Epoch 82/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1183.6942 - val_loss: 1333.2911\n",
      "Epoch 83/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1319.0256 - val_loss: 5462.0357\n",
      "Epoch 84/90\n",
      "150654/150654 [==============================] - 9s 62us/step - loss: 1239.1511 - val_loss: 2695.3042\n",
      "Epoch 85/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1225.3748 - val_loss: 1353.9306\n",
      "Epoch 86/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1216.9338 - val_loss: 2023.5821\n",
      "Epoch 87/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1212.1035 - val_loss: 1677.0568\n",
      "Epoch 88/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1211.6662 - val_loss: 1738.8659\n",
      "Epoch 89/90\n",
      "150654/150654 [==============================] - 9s 61us/step - loss: 1210.6587 - val_loss: 2949.4834\n",
      "Epoch 90/90\n",
      "150654/150654 [==============================] - 9s 60us/step - loss: 1203.2042 - val_loss: 1639.7672\n"
     ]
    }
   ],
   "source": [
    "f = hyper_model(seed = 0)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "fit = f.fit(X_list, train_y, validation_split=0.2, batch_size=1500,\n",
    "              epochs=90, verbose=1)#, callbacks=[ExponentialMovingAverage()])\n",
    "pred =f.predict(X_list, batch_size=1024)\n",
    "#score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "score = mean_absolute_error(train_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1, kernel_initializer='he_normal',kernel_regularizer=l2(0.1))) val_loss: 2363.5925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1, kernel_initializer='glorot_uniform',kernel_regularizer=l2(0.1)))  2067.2395"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_regularizer=l2(0.1)))  uniform 1768.2859"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(1, kernel_initializer='uniform',kernel_regularizer=l2(0.1))) 1404.0575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.001) 3100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "1332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnmodel={}\n",
    "nnmodel.clear()\n",
    "def cross_validate_mlp(mlp_func, nfolds=10,nbags=5):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nbags,))\n",
    "    stack_train = np.zeros((nbags,len(train_y)))\n",
    "    stack_test = np.zeros((nbags,len(test)))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        for bag in range(nbags):\n",
    "            nnmodel['nn%d',k*10+bag*1] = mlp_func(seed = k*10+bag*1)\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            fit = nnmodel['nn%d',k*10+bag*1].fit(xtr, ytr, validation_split=0.2, batch_size=128,\n",
    "                          epochs=30, verbose=1, callbacks=[ExponentialMovingAverage()])\n",
    "            pred = nnmodel['nn%d',k*10+bag*1].predict(xte, batch_size=1024)\n",
    "            #score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "            score = mean_absolute_error(yte, pred)\n",
    "            val_scores[bag] += score\n",
    "            #stack_train[bag][test_index] = pred[:,0]\n",
    "            print (\"nfold:{},bag:{}\".format(k,bag),score)\n",
    "    for bag in range(nbags):\n",
    "        val_scores[bag] = val_scores[bag] / float(nfolds)\n",
    "    \n",
    "    \n",
    "    return val_scores\n",
    "\n",
    "cv_score = cross_validate_mlp(hyper_model)\n",
    "print (\"CV score for the final model:\", cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this model is not adapted for mere 30 epochs of training, nor for 3-fold CV (I used 5-fold on Kaggle), even though this is a single unbagged model which has been cross-validated on three folds only, we see a very good score:\n",
    "`CV = 1150` (your score may vary a little).\n",
    "\n",
    "By the way, this single model, bagged, 5-fold CVed, scored 1116.28 on Kaggle LB.\n",
    "\n",
    "As we see, this model is considerably better than any other models we had so far. We now take it as the second part of our final ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'l3-nn': {\n",
    "        'predictions': l2_predictions,\n",
    "        'n_bags': 4,\n",
    "        'model': Keras(nn_lr, lambda: {'l1': 1e-5, 'l2': 1e-5, 'n_epoch': 30, 'batch_size': 128, 'optimizer': SGD(3e-2, momentum=0.8, nesterov=True, decay=3e-5), 'callbacks': [ExponentialMovingAverage(save_mv_ave_model=False)]}),\n",
    "    },\n",
    "     'optimizer': SGD(1e-4, momentum=0.9, nesterov=True, decay=5e-5)\n",
    "            'optimizer': SGD(1e-5, momentum=0.9, nesterov=True, decay=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 437, 'hidden2_dropout': 0.40000000000000002, \n",
    " 'hidden2_units': 182, 'hidden3_dropout': 0.23333333333333334, 'hidden3_units': 73, 'optimizer': 'adadelta',\n",
    " 'wdecay': 0.0020300000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=3):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nfolds,))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        mlp = mlp_func()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "        fit = mlp.fit(xtr, ytr, validation_split=0.1, batch_size=128, \n",
    "                      epochs=10, verbose=0, callbacks=[early_stopping])\n",
    "        pred = mlp.predict(xte, batch_size=512)\n",
    "        score = mean_absolute_error(np.exp(yte), np.exp(pred))\n",
    "        val_scores[k] += score\n",
    "        print ('Fold {}, MAE: {}'.format(k, score))\n",
    "    avg_score = np.sum(val_scores) / float(nfolds)\n",
    "    print ('{}-fold CV score: {}'.format(nfolds, avg_score))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 463, 'hidden2_dropout': 0.46666666666666667, 'hidden2_units': 155, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 20, 'optimizer': 'adam', 'wdecay': 0.0012891891891891893}\n",
      "Fold 0, MAE: 1664.3154518123333\n",
      "Fold 1, MAE: 1789.6478768193072\n",
      "Fold 2, MAE: 2230.6679431902985\n",
      "3-fold CV score: 1894.877090607313\n",
      "Model Testing: {'hidden1_dropout': 0.50526315789473686, 'hidden1_units': 308, 'hidden2_dropout': 0.20000000000000001, 'hidden2_units': 244, 'hidden3_dropout': 0.41111111111111109, 'hidden3_units': 28, 'optimizer': 'adadelta', 'wdecay': 0.0075522522522522527}\n",
      "Fold 0, MAE: 2663.589775993532\n",
      "Fold 1, MAE: 2550.3793884253055\n",
      "Fold 2, MAE: 2698.309167392798\n",
      "3-fold CV score: 2637.426110603878\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 394, 'hidden2_dropout': 0.23333333333333334, 'hidden2_units': 120, 'hidden3_dropout': 0.18888888888888888, 'hidden3_units': 65, 'optimizer': 'adam', 'wdecay': 0.0076711711711711711}\n",
      "Fold 0, MAE: 1349.8792955749364\n",
      "Fold 1, MAE: 1348.0942437736849\n",
      "Fold 2, MAE: 1365.2535296867036\n",
      "3-fold CV score: 1354.409023011775\n",
      "Model Testing: {'hidden1_dropout': 0.59999999999999998, 'hidden1_units': 541, 'hidden2_dropout': 0.43333333333333335, 'hidden2_units': 258, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 51, 'optimizer': 'adadelta', 'wdecay': 0.0024189189189189188}\n",
      "Fold 0, MAE: 2598.4352573980386\n",
      "Fold 1, MAE: 2447.588075147961\n",
      "Fold 2, MAE: 2721.9736304441863\n",
      "3-fold CV score: 2589.332320996729\n",
      "Model Testing: {'hidden1_dropout': 0.5368421052631579, 'hidden1_units': 472, 'hidden2_dropout': 0.33333333333333337, 'hidden2_units': 217, 'hidden3_dropout': 0.14444444444444446, 'hidden3_units': 71, 'optimizer': 'adadelta', 'wdecay': 0.0055603603603603608}\n",
      "Fold 0, MAE: 1613.5498840747402\n",
      "Fold 1, MAE: 1411.0097020300386\n",
      "Fold 2, MAE: 1711.7215931226579\n",
      "3-fold CV score: 1578.7603930758123\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 429, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 224, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 36, 'optimizer': 'adam', 'wdecay': 0.0053720720720720726}\n",
      "Fold 0, MAE: 1803.0232709901081\n",
      "Fold 1, MAE: 2716.749151946116\n",
      "Fold 2, MAE: 2137.6247824488005\n",
      "3-fold CV score: 2219.1324017950083\n",
      "Model Testing: {'hidden1_dropout': 0.55789473684210522, 'hidden1_units': 308, 'hidden2_dropout': 0.5, 'hidden2_units': 148, 'hidden3_dropout': 0.4555555555555556, 'hidden3_units': 69, 'optimizer': 'adam', 'wdecay': 0.0020225225225225223}\n",
      "Fold 0, MAE: 2290.4482287011933\n",
      "Fold 1, MAE: 1908.4728142537497\n",
      "Fold 2, MAE: 1895.8826351188964\n",
      "3-fold CV score: 2031.6012260246132\n",
      "Model Testing: {'hidden1_dropout': 0.48421052631578948, 'hidden1_units': 481, 'hidden2_dropout': 0.3666666666666667, 'hidden2_units': 127, 'hidden3_dropout': 0.3666666666666667, 'hidden3_units': 28, 'optimizer': 'adam', 'wdecay': 0.0085432432432432422}\n",
      "Fold 0, MAE: 1813.761108549234\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-f3e899cfd5b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# UNCOMMENT THE NEXT LINE TO LAUNCH HYPEROPT:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperopt_search\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         )\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             return_argmin=return_argmin)\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     verbose=verbose)\n\u001b[1;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'job exception: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-252-f3e899cfd5b2>\u001b[0m in \u001b[0;36mhyperopt_search\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mcv_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcv_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'status'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-251-50776d6fa3b5>\u001b[0m in \u001b[0;36mcross_validate_mlp\u001b[0;34m(mlp_func, nfolds)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         fit = mlp.fit(xtr, ytr, validation_split=0.1, batch_size=128, \n\u001b[0;32m---> 12\u001b[0;31m                       epochs=10, verbose=0, callbacks=[early_stopping])\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_coo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2329\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                 \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# VERSION 4. Insights:\n",
    "# â€“ why not to test 4-layer architectures?\n",
    "# â€”Â we need to introduce new optimizers\n",
    "# â€” adding batch normalization (https://arxiv.org/abs/1502.03167)\n",
    "\n",
    "# Describing the search space\n",
    "space = {'hidden1_dropout': hp.choice('hidden1_dropout', np.linspace(0.4,0.6,20)),\n",
    "        'hidden2_dropout': hp.choice('hidden2_dropout', np.linspace(0.2,0.5,10)),\n",
    "        'hidden3_dropout': hp.choice('hidden3_dropout', np.linspace(0.1,0.5,10)),\n",
    "         'hidden1_units': hp.choice('hidden1_units', np.linspace(300,550,30,dtype='int32')),\n",
    "         'hidden2_units': hp.choice('hidden2_units', np.linspace(100,300,30,dtype='int32')),\n",
    "         'hidden3_units': hp.choice('hidden3_units', np.linspace(20,80,30,dtype='int32')),\n",
    "         'optimizer': hp.choice('optimizer', ['adadelta','adam']),\n",
    "         'wdecay':hp.choice('wdecay', np.linspace(0.0001,0.01,1000)),\n",
    "        }\n",
    "\n",
    "# Implementing a function to minimize\n",
    "def hyperopt_search(params):\n",
    "    print ('Model Testing:', params)\n",
    "    def mlp_model():\n",
    "        model = Sequential()\n",
    "        model.add(Dense(params['hidden1_units'], input_dim=train_x.shape[1], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden1_dropout']))\n",
    "        \n",
    "        model.add(Dense(params['hidden2_units'], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden2_dropout']))\n",
    "\n",
    "        model.add(Dense(params['hidden3_units'], kernel_initializer='he_normal',\n",
    "                        kernel_regularizer=l2(params['wdecay']))) \n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(params['hidden3_dropout']))\n",
    "        \n",
    "        model.add(Dense(1, kernel_initializer='he_normal',kernel_regularizer=l2(params['wdecay'])))\n",
    "        model.compile(loss=mae_score,metrics=[mae_score], optimizer=params['optimizer'])\n",
    "        return model\n",
    "    \n",
    "    cv_score = cross_validate_mlp(mlp_model)\n",
    "    return {'loss': cv_score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# UNCOMMENT THE NEXT LINE TO LAUNCH HYPEROPT:\n",
    "best = fmin(hyperopt_search, space, algo=tpe.suggest, max_evals = 100, trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features: 116\n",
      "Numerical features: 14\n"
     ]
    }
   ],
   "source": [
    "features = [x for x in train.columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "cat_features = [x for x in train.select_dtypes(\n",
    "        include=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "num_features = [x for x in train.select_dtypes(\n",
    "        exclude=['object']).columns if x not in ['id','loss', 'log_loss']]\n",
    "\n",
    "print \"Categorical features:\", len(cat_features)\n",
    "print \"Numerical features:\", len(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 188318 entries, 0 to 188317\n",
      "Columns: 132 entries, id to loss\n",
      "dtypes: float64(15), int64(1), object(116)\n",
      "memory usage: 189.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels)),False\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat)),False\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n",
      "[-1  0  1]\n",
      "[0 1 2]\n",
      "[0 1 1]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'A':[np.nan,'type1','type2'],\n",
    "                   'B':['type1','type2','type3'],\n",
    "                   'C':['type1','type3','type3']})\n",
    "print pd.factorize(df['A'].values, sort=True)[0]\n",
    "print pd.factorize(df['A'].values)[0]\n",
    "print pd.factorize(df['B'].values, sort=True)[0]\n",
    "print pd.factorize(df['C'].values, sort=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: 'np.nan' if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "lgtrain = lgb.Dataset(X, label=y,categorical_feature=cat_features,free_raw_data=False)\n",
    "lgtest = lgb.Dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/lightgbm/basic.py:1002: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    }
   ],
   "source": [
    "#1148.9639894 {'reg_alpha': 0.13614510960026047, 'colsample_bytree': 0.48613283826428166, 'scale_pos_weight': 1, 'learning_rate': 0.018415349849039475, 'nthread': 10, 'min_child_weight': 3, 'subsample': 0.8045758877474857, 'max_depth': 16, 'gamma': 3.738381824865164}\n",
    "RANDOM_STATE = 0\n",
    "'''params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}'''\n",
    "params={'colsample_bytree': 0.6, 'learning_rate': 0.01, \n",
    "             'min_child_weight': 6, #'n_estimators': 100, \n",
    "            'nthread': 10,\n",
    "            'subsample': 0.9, 'objective': 'regression', \n",
    "             'max_depth': 9, 'min_split_gain': 0.4,'reg_alpha': 0.0001,'seed':0}\n",
    "model = lgb.train(params, lgtrain, 10, feval=evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eta_list  = [0.1]*100 + [0.05]*200 + [0.02]*400\n",
    "#model = xgb.train(params, xgtrain, 700, feval=evalerror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Xt = np.zeros((1000,100))\\nx0=np.arange(10000).reshape(10000,1)\\nx1=np.arange(10000,20000).reshape(10000,1)\\nx =np.concatenate((x0,x1),axis=1)\\ny=np.arange(10000)\\nyt=np.concatenate((np.zeros(500),np.ones(500)))\\nlgtrain = lgb.Dataset(x, label=y)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Xt = np.zeros((1000,100))\n",
    "x0=np.arange(10000).reshape(10000,1)\n",
    "x1=np.arange(10000,20000).reshape(10000,1)\n",
    "x =np.concatenate((x0,x1),axis=1)\n",
    "y=np.arange(10000)\n",
    "yt=np.concatenate((np.zeros(500),np.ones(500)))\n",
    "lgtrain = lgb.Dataset(x, label=y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params={'colsample_bytree': 0.6, 'learning_rate': 0.01, \n",
    "            'min_child_weight': 6,\n",
    "            'nthread': 5, \n",
    "            'subsample': 0.9, 'objective':'regression',\n",
    "             'max_depth': 9, 'min_split_gain': 0.4,'reg_alpha': 0.0001,'seed':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_params={ 'nthread': 10, \n",
    "            'num_leaves':120,'min_data_in_leaf':100,'max_depth':9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1412.44216116\n",
      "('\\nBest num_boost_round:', 10)\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "cv_result_lgb = lgb.cv(lgb_params, lgtrain, num_boost_round=10, nfold=5, seed=0, stratified=False,\n",
    "                    feval=evalerror, early_stopping_rounds=None)\n",
    "print cv_result_lgb['mae-mean'][-1]\n",
    "print('\\nBest num_boost_round:', len(cv_result_lgb['mae-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1192.46133299\n",
      "('\\nBest num_boost_round:', 3000)\n"
     ]
    }
   ],
   "source": [
    "print cv_result_lgb['mae-mean'][-1]\n",
    "print('\\nBest num_boost_round:', len(cv_result_lgb['mae-mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "\n",
    "ax1.set_title('100 rounds of training')\n",
    "ax1.set_xlabel('Rounds')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.grid(True)\n",
    "ax1.plot(bst_cv1[['train-mae-mean', 'test-mae-mean']])\n",
    "ax1.legend(['Training Loss', 'Test Loss'])\n",
    "\n",
    "ax2.set_title('60 last rounds of training')\n",
    "ax2.set_xlabel('Rounds')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.grid(True)\n",
    "ax2.plot(bst_cv1.iloc[1750:][['train-mae-mean', 'test-mae-mean']])\n",
    "ax2.legend(['Training Loss', 'Test Loss'])\n",
    "fig.set_size_inches(16,4)\n",
    "#fig.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "Xt = np.zeros((1000,100))\n",
    "t = np.ones((1000,100))\n",
    "yt=np.concatenate((np.zeros(500),np.ones(500)))\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "for train_index, test_index in skf.split(Xt, yt):\n",
    "    t[test_index] = 0\n",
    "np.where(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1402.25946661\n",
      "{'num_leaves': 100, 'max_depth': 9, 'min_data_in_leaf': 10, 'num_threads': 10}\n",
      "CPU times: user 1min 9s, sys: 5.8 s, total: 1min 15s\n",
      "Wall time: 13.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bins = range(10,30,10)\n",
    "lgb_params = {\n",
    "    'min_data_in_leaf': bins,\n",
    "    'num_leaves':[100],\n",
    "     'max_depth':[9],\n",
    "    'num_threads':[10],\n",
    "}\n",
    "clf=lgb.LGBMRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=lgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIhKkkBARkaD/D5fDgpivLocwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e021356d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plottrend(grid=grid,bins=bins):    \n",
    "    test_scores_mean = grid.cv_results_['mean_test_score']\n",
    "    test_scores_std = grid.cv_results_['std_test_score']\n",
    "    plt.grid()\n",
    "    plt.fill_between(, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,color=\"r\")\n",
    "    plt.plot(, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1156.26686109\n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.5, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 43min 4s, sys: 23.3 s, total: 43min 27s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[ 0.1 * i for i in range(0,5)],\n",
    "    'colsample_bytree': [0.5],\n",
    "    'subsample': [0.5],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 9h 6min 51s, sys: 4min 47s, total: 9h 11min 39s\n",
      "Wall time: 57min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[i/10.0 for i in range(1,10)],\n",
    "     'colsample_bytree':[i/10.0 for i in range(1,10)],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1150.47117641\n",
      "{'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 500, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 11min 42s, sys: 37 s, total: 1h 12min 19s\n",
      "Wall time: 7min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.5,0.4,0.3,0.2,0.1,0.075,0.05,0.04,0.03],\n",
    "    'n_estimators':[500],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1149.84640685\n",
      "{'reg_alpha': 0.0001, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'nthread': 10, 'min_child_weight': 6, 'n_estimators': 100, 'subsample': 0.9, 'objective': 'reg:linear', 'num_boost_round': 150, 'max_depth': 9, 'gamma': 0.4}\n",
      "CPU times: user 1h 5min 45s, sys: 34.6 s, total: 1h 6min 19s\n",
      "Wall time: 6min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
    "xgb_params = {\n",
    "    'learning_rate': [0.1],\n",
    "    'reg_alpha':[1e-5,1e-4,1e-3, 1e-2, 0.1, 1,10,100],\n",
    "    'n_estimators':[100],\n",
    "     'gamma':[0.4],\n",
    "    'subsample':[0.9],\n",
    "     'colsample_bytree':[0.6],\n",
    "    'objective': ['reg:linear'],\n",
    "    'max_depth': [9],\n",
    "    'min_child_weight': [6],\n",
    "    'nthread':[10],\n",
    "    'num_boost_round':[150]\n",
    "}\n",
    "clf=XGBoostRegressor()\n",
    "grid = GridSearchCV(clf,param_grid=xgb_params, cv=3, scoring=mae_scorer)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print grid.best_score_\n",
    "print grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phe002/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'Vladimir Iglovikov'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import pickle\n",
    "import hyperopt.pyll.stochastic\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114.model                                                params.txt\r\n",
      "Santhosh SharmaExploratory study on ML algorithms?.ipynb  sub_v.csv\r\n",
      "Vladimir Iglovikovxgb 1114?.py                            submission.csv\r\n",
      "\u001b[0m\u001b[01;34mallstate_capstone-master\u001b[0m/                                 test.csv\r\n",
      "handtune.ipynb                                            train.csv\r\n",
      "hyperopt.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socre:1156.8227052, params:{'reg_alpha': 0.26995003848906524, 'colsample_bytree': 0.2266549861816051, 'scale_pos_weight': 1, 'learning_rate': 0.05344032085694122, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.48379887781040276, 'seed': 20, 'max_depth': 16, 'gamma': 0.402588613598941}socre:1149.3825198, params:{'reg_alpha': 0.9999978085959014, 'colsample_bytree': 0.2502484001654734, 'scale_pos_weight': 1, 'learning_rate': 0.03509717328153762, 'nthread': 10, 'min_child_weight': 4, 'subsample': 0.6409135720554807, 'seed': 20, 'max_depth': 16, 'gamma': 0.1306661498079924}"
     ]
    }
   ],
   "source": [
    "%cat params.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "test['loss'] = np.nan\n",
    "joined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in list(train.select_dtypes(include=['object']).columns):\n",
    "    if train[column].nunique() != test[column].nunique():\n",
    "        set_train = set(train[column].unique())\n",
    "        set_test = set(test[column].unique())\n",
    "        remove_train = set_train - set_test\n",
    "        remove_test = set_test - set_train\n",
    "\n",
    "        remove = (remove_train|remove_test)\n",
    "        def filter_cat(x):\n",
    "            if x in remove:\n",
    "                return np.nan\n",
    "            return x\n",
    "\n",
    "        joined[column] = joined[column].apply(lambda x: np.nan if x in remove else x, 1)\n",
    "\n",
    "    joined[column] = pd.factorize(joined[column].values, sort=True)[0]\n",
    "\n",
    "train = joined[joined['loss'].notnull()]\n",
    "test = joined[joined['loss'].isnull()]\n",
    "\n",
    "shift = 200\n",
    "y = np.log(train['loss'] + shift)\n",
    "ids = test['id']\n",
    "X = train.drop(['loss', 'id'], 1)\n",
    "X_test = test.drop(['loss', 'id'], 1)\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time0= time.time()\n",
    "cv = StratifiedKFold(n_splits=5,random_state=42)\n",
    "space4xgb = {\n",
    "    'max_depth': hp.choice('max_depth', range(3,20)),\n",
    "    'min_child_weight':hp.choice('min_child_weight',range(1,10)),\n",
    "    \n",
    "    'learning_rate': hp.loguniform('learning_rate', -2.5*np.log(10), -1*np.log(10)),\n",
    "    \n",
    "    'scale_pos_weight': hp.uniform('scale_pos_weight', 0,10), \n",
    "    'gamma': hp.uniform('gamma',0,1),\n",
    "    \n",
    "    \n",
    "    'subsample': hp.uniform('subsample',0.1,0.9),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree',0.1,1),\n",
    "    'reg_alpha':hp.uniform('reg_alpha',0,1000),\n",
    "    \n",
    "    'nthread': hp.choice('nthread', [10])\n",
    "}\n",
    "minacc=1160\n",
    "#{'reg_alpha': 0.8673861702351379, 'colsample_bytree': 0.8759854865376723, 'scale_pos_weight': 1, 'learning_rate': 0.06925571303753118, 'nthread': 20, 'min_child_weight': 1, 'subsample': 0.629375884543008, 'max_depth': 7, 'gamma': 0.19254932932610697}\n",
    "def optf(params): \n",
    "    params['nthread']=10\n",
    "    params['seed']=20\n",
    "    #clf = xgb.XGBRegressor(**params)\n",
    "    #acc = cross_val_score(clf, X, y,cv=cv,n_jobs=1,scoring=evalerror).mean()\n",
    "    bst = xgb.cv(params, xgtrain, num_boost_round=500, nfold=5, seed=7, \n",
    "                    feval=evalerror,early_stopping_rounds=10)\n",
    "    acc = bst.iloc[-1,:]['test-mae-mean']\n",
    "    print time.time()-time0\n",
    "    print acc\n",
    "    global minacc\n",
    "    if acc < minacc:\n",
    "        minacc = acc\n",
    "        print 'new best:', minacc, params\n",
    "        \n",
    "        with open(\"params2.txt\", \"a\") as text_file:\n",
    "            text_file.write('socre:{}, params:{}\\n'.format(minacc,params))\n",
    "    return {'loss': -acc, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning from 457 trials to 458 (+1) trials\n",
      "109.290174961\n",
      "1157.5361086\n",
      "new best: 1157.5361086 {'reg_alpha': 0.991470826095777, 'colsample_bytree': 0.1235200182991481, 'scale_pos_weight': 1, 'learning_rate': 0.04127155920388758, 'nthread': 10, 'min_child_weight': 6, 'subsample': 0.24989254385528198, 'seed': 20, 'max_depth': 7, 'gamma': 0.47772585814974006}\n",
      "Rerunning from 458 trials to 459 (+1) trials\n",
      "201.662240982\n",
      "2049.5875246\n",
      "Rerunning from 459 trials to 460 (+1) trials\n",
      "291.468131065\n",
      "1684.0019042\n",
      "Rerunning from 460 trials to 461 (+1) trials\n",
      "582.61702013\n",
      "1150.8644044\n",
      "new best: 1150.8644044 {'reg_alpha': 0.9999174896084708, 'colsample_bytree': 0.15010562804817196, 'scale_pos_weight': 1, 'learning_rate': 0.061547110425257914, 'nthread': 10, 'min_child_weight': 6, 'subsample': 0.3332350811823883, 'seed': 20, 'max_depth': 7, 'gamma': 0.49966763825465166}\n",
      "Rerunning from 463 trials to 464 (+1) trials\n",
      "654.76593399\n",
      "2474.997754\n",
      "Rerunning from 464 trials to 465 (+1) trials\n",
      "752.932347059\n",
      "1153.4624024\n",
      "Rerunning from 465 trials to 466 (+1) trials\n",
      "829.886413097\n",
      "2371.8280762\n",
      "Rerunning from 466 trials to 467 (+1) trials\n",
      "933.901291132\n",
      "2584.1302246\n",
      "Rerunning from 467 trials to 468 (+1) trials\n"
     ]
    }
   ],
   "source": [
    "def run_trials():\n",
    "\n",
    "    trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "    max_trials = 1  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "    \n",
    "    try:  # try to load an already saved trials object, and increase the max\n",
    "        trials = pickle.load(open(\"/home/phe002/shicheng/dataset/hyperoptModel\", \"rb\"))\n",
    "        max_trials = len(trials.trials) + trials_step\n",
    "        print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "    except:  # create a new trials object and start searching\n",
    "        trials = Trials()\n",
    "\n",
    "    best = fmin(fn=optf, space=space4xgb, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "    # save the trials object\n",
    "    with open(\"/home/phe002/shicheng/dataset/hyperoptModel\", \"wb\") as f:\n",
    "        pickle.dump(trials, f)\n",
    "\n",
    "# loop indefinitely and stop whenever you like\n",
    "while True:\n",
    "    run_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1148.9639894 {'reg_alpha': 0.13614510960026047, 'colsample_bytree': 0.48613283826428166, 'scale_pos_weight': 1, 'learning_rate': 0.018415349849039475, 'nthread': 10, 'min_child_weight': 3, 'subsample': 0.8045758877474857, 'max_depth': 16, 'gamma': 3.738381824865164}\n",
    "'''RANDOM_STATE = 2016\n",
    "params = {\n",
    "    'min_child_weight': 1,\n",
    "    'eta': 0.01,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'max_depth': 12,\n",
    "    'subsample': 0.8,\n",
    "    'alpha': 1,\n",
    "    'gamma': 1,\n",
    "    'silent': 1,\n",
    "    'verbose_eval': True,\n",
    "    'seed': RANDOM_STATE,\n",
    "    'nthread':10\n",
    "}\n",
    "\n",
    "xgtrain = xgb.DMatrix(X, label=y)\n",
    "xgtest = xgb.DMatrix(X_test)\n",
    "\n",
    "model = xgb.train(params, xgtrain, int(2012 / 0.9), feval=evalerror)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_model('1114.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.exp(model.predict(xgtest)) - shift\n",
    "submission = pd.DataFrame()\n",
    "submission['loss'] = prediction\n",
    "submission['id'] = ids\n",
    "submission.to_csv('sub_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print \"a+b\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

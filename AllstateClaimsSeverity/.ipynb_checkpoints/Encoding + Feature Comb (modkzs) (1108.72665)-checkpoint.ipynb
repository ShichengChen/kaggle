{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift = 200\n",
    "COMB_FEATURE = 'cat80,cat87,cat57,cat12,cat79,cat10,cat7,cat89,cat2,cat72,' \\\n",
    "               'cat81,cat11,cat1,cat13,cat9,cat3,cat16,cat90,cat23,cat36,' \\\n",
    "               'cat73,cat103,cat40,cat28,cat111,cat6,cat76,cat50,cat5,' \\\n",
    "               'cat4,cat14,cat38,cat24,cat82,cat25'.split(',')\n",
    "\n",
    "def encode(charcode):\n",
    "    r = 0\n",
    "    ln = len(str(charcode))\n",
    "    for i in range(ln):\n",
    "        r += (ord(str(charcode)[i]) - ord('A') + 1) * 26 ** (ln - i - 1)\n",
    "    return r\n",
    "\n",
    "fair_constant = 2\n",
    "def fair_obj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    x = (preds - labels)\n",
    "    den = abs(x) + fair_constant\n",
    "    grad = fair_constant * x / (den)\n",
    "    hess = fair_constant * fair_constant / (den * den)\n",
    "    return grad, hess\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y)-shift,\n",
    "                                      np.exp(yhat)-shift)\n",
    "def mungeskewed(train, test, numeric_feats):\n",
    "    ntrain = train.shape[0]\n",
    "    test['loss'] = 0\n",
    "    train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "    skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna()))\n",
    "    skewed_feats = skewed_feats[skewed_feats > 0.25]\n",
    "    skewed_feats = skewed_feats.index\n",
    "\n",
    "    for feats in skewed_feats:\n",
    "        train_test[feats] = train_test[feats] + 1\n",
    "        train_test[feats], lam = boxcox(train_test[feats])\n",
    "    return train_test, ntrain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "numeric_feats = [x for x in train.columns[1:-1] if 'cont' in x]\n",
    "categorical_feats = [x for x in train.columns[1:-1] if 'cat' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_test, ntrain = mungeskewed(train, test, numeric_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print('')\n",
    "for comb in itertools.combinations(COMB_FEATURE, 2):\n",
    "    feat = comb[0] + \"_\" + comb[1]\n",
    "    train_test[feat] = train_test[comb[0]] + train_test[comb[1]]\n",
    "    train_test[feat] = train_test[feat].apply(encode)\n",
    "    print('Analyzing Columns:', feat)\n",
    "\n",
    "categorical_feats = [x for x in train_test.columns[1:] if 'cat' in x]\n",
    "\n",
    "print('')\n",
    "for col in categorical_feats:\n",
    "    print('Analyzing Column:', col)\n",
    "    train_test[col] = train_test[col].apply(encode)\n",
    "\n",
    "print(train_test[categorical_feats])\n",
    "\n",
    "ss = StandardScaler()\n",
    "train_test[numeric_feats] = \\\n",
    "    ss.fit_transform(train_test[numeric_feats].values)\n",
    "\n",
    "train = train_test.iloc[:ntrain, :].copy()\n",
    "test = train_test.iloc[ntrain:, :].copy()\n",
    "\n",
    "print('\\nMedian Loss:', train.loss.median())\n",
    "print('Mean Loss:', train.loss.mean())\n",
    "\n",
    "ids = pd.read_csv('input/test.csv')['id']\n",
    "train_y = np.log(train['loss'] + shift)\n",
    "train_x = train.drop(['loss','id'], axis=1)\n",
    "test_x = test.drop(['loss','id'], axis=1)\n",
    "\n",
    "n_folds = 10\n",
    "cv_sum = 0\n",
    "early_stopping = 100\n",
    "fpred = []\n",
    "xgb_rounds = []\n",
    "\n",
    "d_train_full = xgb.DMatrix(train_x, label=train_y)\n",
    "d_test = xgb.DMatrix(test_x)\n",
    "\n",
    "kf = KFold(train.shape[0], n_folds=n_folds)\n",
    "for i, (train_index, test_index) in enumerate(kf):\n",
    "    print('\\n Fold %d' % (i+1))\n",
    "    X_train, X_val = train_x.iloc[train_index], train_x.iloc[test_index]\n",
    "    y_train, y_val = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "\n",
    "    rand_state = 2016\n",
    "\n",
    "    params = {\n",
    "        'seed': 0,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'silent': 1,\n",
    "        'subsample': 0.7,\n",
    "        'learning_rate': 0.03,\n",
    "        'objective': 'reg:linear',\n",
    "        'max_depth': 12,\n",
    "        'min_child_weight': 100,\n",
    "        'booster': 'gbtree'}\n",
    "\n",
    "    d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "    d_valid = xgb.DMatrix(X_val, label=y_val)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'eval')]\n",
    "\n",
    "    clf = xgb.train(params,\n",
    "                    d_train,\n",
    "                    100000,\n",
    "                    watchlist,\n",
    "                    early_stopping_rounds=50,\n",
    "                    obj=fair_obj,\n",
    "                    feval=xg_eval_mae)\n",
    "\n",
    "    xgb_rounds.append(clf.best_iteration)\n",
    "    scores_val = clf.predict(d_valid, ntree_limit=clf.best_ntree_limit)\n",
    "    cv_score = mean_absolute_error(np.exp(y_val), np.exp(scores_val))\n",
    "    print('eval-MAE: %.6f' % cv_score)\n",
    "    y_pred = np.exp(clf.predict(d_test, ntree_limit=clf.best_ntree_limit)) - shift\n",
    "\n",
    "    if i > 0:\n",
    "        fpred = pred + y_pred\n",
    "    else:\n",
    "        fpred = y_pred\n",
    "    pred = fpred\n",
    "    cv_sum = cv_sum + cv_score\n",
    "\n",
    "mpred = pred / n_folds\n",
    "score = cv_sum / n_folds\n",
    "print('Average eval-MAE: %.6f' % score)\n",
    "n_rounds = int(np.mean(xgb_rounds))\n",
    "\n",
    "print(\"Writing results\")\n",
    "result = pd.DataFrame(mpred, columns=['loss'])\n",
    "result[\"id\"] = ids\n",
    "result = result.set_index(\"id\")\n",
    "print(\"%d-fold average prediction:\" % n_folds)\n",
    "\n",
    "now = datetime.now()\n",
    "score = str(round((cv_sum / n_folds), 6))\n",
    "sub_file = 'output/submission_5fold-average-xgb_fairobj_' + str(score) + '_' + str(\n",
    "    now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "print(\"Writing submission: %s\" % sub_file)\n",
    "result.to_csv(sub_file, index=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3, Multilayer Perceptron Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import h5py\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.cross_validation import KFold, train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from keras import backend as K\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "'''gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))'''\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 1153)\n",
      "(188318,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((188318, 1153), (188318,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "cat_names = [c for c in train.columns if 'cat' in c]\n",
    "\n",
    "train = pd.get_dummies(data=train, columns=cat_names)\n",
    "\n",
    "features = [x for x in train.columns if x not in ['id','loss']]\n",
    "\n",
    "train_x = np.array(train[features])\n",
    "\n",
    "ntrain = train_x.shape[0]\n",
    "\n",
    "train_y = np.log(train['loss'] + 200)\n",
    "\n",
    "print (train_x.shape)\n",
    "print (train_y.shape)\n",
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtr, xte, ytr, yte = train_test_split(train_x, train_y, test_size=0.25, random_state=31337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cdn.rawgit.com/dnkirill/allstate_capstone/master/images/mlp3.svg\"></td>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(preds), np.exp(labels))\n",
    "\n",
    "def xg_eval_mae(yhat, dtrain):\n",
    "    y = dtrain.get_label()\n",
    "    return 'mae', mean_absolute_error(np.exp(y), np.exp(yhat))\n",
    "\n",
    "def mae_score(y_true, y_pred):\n",
    "    return mean_absolute_error(np.exp(y_true), np.exp(y_pred))\n",
    "\n",
    "mae_scorer = make_scorer(mae_score, greater_is_better=False)\n",
    "\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true) - K.exp(y_pred)))\n",
    "\n",
    "def mean_pred_metrics(y_true, y_pred):\n",
    "    return K.mean(K.abs(K.exp(y_true) - K.exp(y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_validate_mlp(mlp_func, nfolds=3):\n",
    "    folds = KFold(len(train_y), n_folds=nfolds, shuffle=True, random_state = 31337)\n",
    "    val_scores = np.zeros((nfolds,))\n",
    "    for k,(train_index, test_index) in enumerate(folds):\n",
    "        xtr = train_x[train_index]\n",
    "        ytr = train_y[train_index]\n",
    "        xte = train_x[test_index]\n",
    "        yte = train_y[test_index]\n",
    "        mlp = mlp_func()\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "        fit = mlp.fit(xtr, ytr, validation_split=0.2, batch_size=128, \n",
    "                      nb_epoch=100, verbose=1, callbacks=[early_stopping])\n",
    "        pred = mlp.predict(xte, batch_size=256)\n",
    "        score = mean_absolute_error(yte, pred)\n",
    "        val_scores[k] += score\n",
    "        print ('Fold {}, MAE: {}'.format(k, score))\n",
    "    avg_score = np.sum(val_scores) / float(nfolds)\n",
    "    print ('{}-fold CV score: {}'.format(nfolds, avg_score))\n",
    "    return avg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hyper_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(351, input_dim=train_x.shape[1], init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.578947))\n",
    "    \n",
    "    model.add(Dense(293, init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.26666))\n",
    "    \n",
    "    model.add(Dense(46, init='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.188888))\n",
    "    \n",
    "    model.add(Dense(1, init='he_normal'))\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=mean_pred,metrics=[mean_pred_metrics])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100436 samples, validate on 25109 samples\n",
      "Epoch 1/100\n",
      "100436/100436 [==============================] - 9s - loss: 3210.1322 - mean_pred_metrics: 3210.1322 - val_loss: 3095.4986 - val_mean_pred_metrics: 3095.4986\n",
      "Epoch 2/100\n",
      "100436/100436 [==============================] - 7s - loss: 2724.3428 - mean_pred_metrics: 2724.3428 - val_loss: 1932.3458 - val_mean_pred_metrics: 1932.3458\n",
      "Epoch 3/100\n",
      "100436/100436 [==============================] - 7s - loss: 2205.4983 - mean_pred_metrics: 2205.4983 - val_loss: 1854.8780 - val_mean_pred_metrics: 1854.8780\n",
      "Epoch 4/100\n",
      "100436/100436 [==============================] - 7s - loss: 2081.3217 - mean_pred_metrics: 2081.3217 - val_loss: 1695.6310 - val_mean_pred_metrics: 1695.6310\n",
      "Epoch 5/100\n",
      "100436/100436 [==============================] - 8s - loss: 1942.1458 - mean_pred_metrics: 1942.1458 - val_loss: 1565.2848 - val_mean_pred_metrics: 1565.2848\n",
      "Epoch 6/100\n",
      "100436/100436 [==============================] - 7s - loss: 1860.2303 - mean_pred_metrics: 1860.2303 - val_loss: 1476.8009 - val_mean_pred_metrics: 1476.8009\n",
      "Epoch 7/100\n",
      "100436/100436 [==============================] - 7s - loss: 1808.3640 - mean_pred_metrics: 1808.3640 - val_loss: 1599.0924 - val_mean_pred_metrics: 1599.0924\n",
      "Epoch 8/100\n",
      "100436/100436 [==============================] - 7s - loss: 1772.5211 - mean_pred_metrics: 1772.5211 - val_loss: 1449.6119 - val_mean_pred_metrics: 1449.6119\n",
      "Epoch 9/100\n",
      "100436/100436 [==============================] - 7s - loss: 1753.5202 - mean_pred_metrics: 1753.5202 - val_loss: 1401.8683 - val_mean_pred_metrics: 1401.8683\n",
      "Epoch 10/100\n",
      "100436/100436 [==============================] - 7s - loss: 1716.8362 - mean_pred_metrics: 1716.8362 - val_loss: 1407.0938 - val_mean_pred_metrics: 1407.0938\n",
      "Epoch 11/100\n",
      "100436/100436 [==============================] - 7s - loss: 1677.5695 - mean_pred_metrics: 1677.5695 - val_loss: 1359.0393 - val_mean_pred_metrics: 1359.0393\n",
      "Epoch 12/100\n",
      "100436/100436 [==============================] - 7s - loss: 1659.6933 - mean_pred_metrics: 1659.6933 - val_loss: 1248.7220 - val_mean_pred_metrics: 1248.7220\n",
      "Epoch 13/100\n",
      "100436/100436 [==============================] - 7s - loss: 1635.1861 - mean_pred_metrics: 1635.1861 - val_loss: 1393.8967 - val_mean_pred_metrics: 1393.8967\n",
      "Epoch 14/100\n",
      "100436/100436 [==============================] - 7s - loss: 1613.7112 - mean_pred_metrics: 1613.7112 - val_loss: 1312.2167 - val_mean_pred_metrics: 1312.2167\n",
      "Epoch 15/100\n",
      "100436/100436 [==============================] - 7s - loss: 1590.5231 - mean_pred_metrics: 1590.5231 - val_loss: 1372.2427 - val_mean_pred_metrics: 1372.2427\n",
      "Epoch 16/100\n",
      "100436/100436 [==============================] - 7s - loss: 1573.6608 - mean_pred_metrics: 1573.6608 - val_loss: 1373.6602 - val_mean_pred_metrics: 1373.6602\n",
      "Epoch 17/100\n",
      "100436/100436 [==============================] - 7s - loss: 1555.0730 - mean_pred_metrics: 1555.0730 - val_loss: 1325.7523 - val_mean_pred_metrics: 1325.7523\n",
      "Epoch 18/100\n",
      "100436/100436 [==============================] - 7s - loss: 1531.5387 - mean_pred_metrics: 1531.5387 - val_loss: 1262.3367 - val_mean_pred_metrics: 1262.3367\n",
      "Epoch 19/100\n",
      "100436/100436 [==============================] - 7s - loss: 1504.8109 - mean_pred_metrics: 1504.8109 - val_loss: 1314.9789 - val_mean_pred_metrics: 1314.9789\n",
      "Epoch 20/100\n",
      "100436/100436 [==============================] - 7s - loss: 1489.2571 - mean_pred_metrics: 1489.2571 - val_loss: 1201.5892 - val_mean_pred_metrics: 1201.5892\n",
      "Epoch 21/100\n",
      "100436/100436 [==============================] - 7s - loss: 1471.5419 - mean_pred_metrics: 1471.5419 - val_loss: 1204.9153 - val_mean_pred_metrics: 1204.9153\n",
      "Epoch 22/100\n",
      "100436/100436 [==============================] - 7s - loss: 1443.9332 - mean_pred_metrics: 1443.9332 - val_loss: 1282.6272 - val_mean_pred_metrics: 1282.6272\n",
      "Epoch 23/100\n",
      "100436/100436 [==============================] - 7s - loss: 1428.9428 - mean_pred_metrics: 1428.9428 - val_loss: 1255.3266 - val_mean_pred_metrics: 1255.3266\n",
      "Epoch 24/100\n",
      "100436/100436 [==============================] - 7s - loss: 1407.5693 - mean_pred_metrics: 1407.5693 - val_loss: 1202.6771 - val_mean_pred_metrics: 1202.6771\n",
      "Epoch 25/100\n",
      "100436/100436 [==============================] - 7s - loss: 1397.3190 - mean_pred_metrics: 1397.3190 - val_loss: 1255.9866 - val_mean_pred_metrics: 1255.9866\n",
      "Epoch 26/100\n",
      "100436/100436 [==============================] - 7s - loss: 1384.8554 - mean_pred_metrics: 1384.8554 - val_loss: 1227.0145 - val_mean_pred_metrics: 1227.0145\n",
      "Epoch 27/100\n",
      "100436/100436 [==============================] - 7s - loss: 1358.4705 - mean_pred_metrics: 1358.4705 - val_loss: 1174.7189 - val_mean_pred_metrics: 1174.7189\n",
      "Epoch 28/100\n",
      "100436/100436 [==============================] - 7s - loss: 1345.4836 - mean_pred_metrics: 1345.4836 - val_loss: 1183.3940 - val_mean_pred_metrics: 1183.3940\n",
      "Epoch 29/100\n",
      "100436/100436 [==============================] - 7s - loss: 1332.1338 - mean_pred_metrics: 1332.1338 - val_loss: 1209.9642 - val_mean_pred_metrics: 1209.9642\n",
      "Epoch 30/100\n",
      "100436/100436 [==============================] - 7s - loss: 1314.2266 - mean_pred_metrics: 1314.2266 - val_loss: 1171.0790 - val_mean_pred_metrics: 1171.0790\n",
      "Epoch 31/100\n",
      "100436/100436 [==============================] - 7s - loss: 1298.9838 - mean_pred_metrics: 1298.9838 - val_loss: 1179.3215 - val_mean_pred_metrics: 1179.3215\n",
      "Epoch 32/100\n",
      "100436/100436 [==============================] - 7s - loss: 1280.6861 - mean_pred_metrics: 1280.6861 - val_loss: 1237.2707 - val_mean_pred_metrics: 1237.2707\n",
      "Epoch 33/100\n",
      "100436/100436 [==============================] - 7s - loss: 1274.4782 - mean_pred_metrics: 1274.4782 - val_loss: 1144.3932 - val_mean_pred_metrics: 1144.3932\n",
      "Epoch 34/100\n",
      "100436/100436 [==============================] - 7s - loss: 1259.8631 - mean_pred_metrics: 1259.8631 - val_loss: 1156.7561 - val_mean_pred_metrics: 1156.7561\n",
      "Epoch 35/100\n",
      "100436/100436 [==============================] - 7s - loss: 1247.4042 - mean_pred_metrics: 1247.4042 - val_loss: 1150.5423 - val_mean_pred_metrics: 1150.5423\n",
      "Epoch 36/100\n",
      "100436/100436 [==============================] - 7s - loss: 1233.3850 - mean_pred_metrics: 1233.3850 - val_loss: 1180.5249 - val_mean_pred_metrics: 1180.5249\n",
      "Epoch 37/100\n",
      "100436/100436 [==============================] - 7s - loss: 1222.7030 - mean_pred_metrics: 1222.7030 - val_loss: 1148.9286 - val_mean_pred_metrics: 1148.9286\n",
      "Epoch 38/100\n",
      "100436/100436 [==============================] - 7s - loss: 1212.3901 - mean_pred_metrics: 1212.3901 - val_loss: 1146.4709 - val_mean_pred_metrics: 1146.4709\n",
      "Epoch 39/100\n",
      "100436/100436 [==============================] - 7s - loss: 1203.6436 - mean_pred_metrics: 1203.6436 - val_loss: 1156.2996 - val_mean_pred_metrics: 1156.2996\n",
      "Epoch 40/100\n",
      "100436/100436 [==============================] - 7s - loss: 1196.9744 - mean_pred_metrics: 1196.9744 - val_loss: 1140.7932 - val_mean_pred_metrics: 1140.7932\n",
      "Epoch 41/100\n",
      "100436/100436 [==============================] - 7s - loss: 1184.9413 - mean_pred_metrics: 1184.9413 - val_loss: 1143.3520 - val_mean_pred_metrics: 1143.3520\n",
      "Epoch 42/100\n",
      "100436/100436 [==============================] - 7s - loss: 1175.2839 - mean_pred_metrics: 1175.2839 - val_loss: 1147.1644 - val_mean_pred_metrics: 1147.1644\n",
      "Epoch 43/100\n",
      "100436/100436 [==============================] - 7s - loss: 1167.6440 - mean_pred_metrics: 1167.6440 - val_loss: 1158.1981 - val_mean_pred_metrics: 1158.1981\n",
      "Epoch 44/100\n",
      "100436/100436 [==============================] - 7s - loss: 1161.5907 - mean_pred_metrics: 1161.5907 - val_loss: 1144.6931 - val_mean_pred_metrics: 1144.6931\n",
      "Epoch 45/100\n",
      "100436/100436 [==============================] - 7s - loss: 1152.7022 - mean_pred_metrics: 1152.7022 - val_loss: 1151.9788 - val_mean_pred_metrics: 1151.9788\n",
      "Epoch 46/100\n",
      "100436/100436 [==============================] - 7s - loss: 1148.7159 - mean_pred_metrics: 1148.7159 - val_loss: 1144.6867 - val_mean_pred_metrics: 1144.6867\n",
      "Epoch 47/100\n",
      "100436/100436 [==============================] - 7s - loss: 1140.9877 - mean_pred_metrics: 1140.9877 - val_loss: 1142.9985 - val_mean_pred_metrics: 1142.9985\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100436/100436 [==============================] - 7s - loss: 1136.6872 - mean_pred_metrics: 1136.6872 - val_loss: 1151.2071 - val_mean_pred_metrics: 1151.2071\n",
      "Epoch 49/100\n",
      "100436/100436 [==============================] - 7s - loss: 1125.8715 - mean_pred_metrics: 1125.8715 - val_loss: 1160.0568 - val_mean_pred_metrics: 1160.0568\n",
      "Epoch 50/100\n",
      "100436/100436 [==============================] - 7s - loss: 1124.8675 - mean_pred_metrics: 1124.8675 - val_loss: 1157.1427 - val_mean_pred_metrics: 1157.1427\n",
      "Epoch 51/100\n",
      "100436/100436 [==============================] - 7s - loss: 1116.8743 - mean_pred_metrics: 1116.8743 - val_loss: 1147.1448 - val_mean_pred_metrics: 1147.1448\n",
      "Fold 0, MAE: 0.37658946331957105\n",
      "Train on 100436 samples, validate on 25109 samples\n",
      "Epoch 1/100\n",
      "100436/100436 [==============================] - 9s - loss: 3213.2251 - mean_pred_metrics: 3213.2251 - val_loss: 3130.6405 - val_mean_pred_metrics: 3130.6405\n",
      "Epoch 2/100\n",
      "100436/100436 [==============================] - 7s - loss: 2734.1874 - mean_pred_metrics: 2734.1874 - val_loss: 2595.9772 - val_mean_pred_metrics: 2595.9772\n",
      "Epoch 3/100\n",
      "100436/100436 [==============================] - 7s - loss: 2384.1952 - mean_pred_metrics: 2384.1952 - val_loss: 2119.2749 - val_mean_pred_metrics: 2119.2749\n",
      "Epoch 4/100\n",
      "100436/100436 [==============================] - 7s - loss: 2212.3364 - mean_pred_metrics: 2212.3364 - val_loss: 1901.8821 - val_mean_pred_metrics: 1901.8821\n",
      "Epoch 5/100\n",
      "100436/100436 [==============================] - 7s - loss: 2072.5000 - mean_pred_metrics: 2072.5000 - val_loss: 1668.1689 - val_mean_pred_metrics: 1668.1689\n",
      "Epoch 6/100\n",
      "100436/100436 [==============================] - 7s - loss: 1984.5311 - mean_pred_metrics: 1984.5311 - val_loss: 1642.0227 - val_mean_pred_metrics: 1642.0227\n",
      "Epoch 7/100\n",
      "100436/100436 [==============================] - 7s - loss: 1926.0909 - mean_pred_metrics: 1926.0909 - val_loss: 1432.0780 - val_mean_pred_metrics: 1432.0780\n",
      "Epoch 8/100\n",
      "100436/100436 [==============================] - 7s - loss: 1879.3539 - mean_pred_metrics: 1879.3539 - val_loss: 1596.1522 - val_mean_pred_metrics: 1596.1522\n",
      "Epoch 9/100\n",
      "100436/100436 [==============================] - 7s - loss: 1843.2504 - mean_pred_metrics: 1843.2504 - val_loss: 1451.9196 - val_mean_pred_metrics: 1451.9196\n",
      "Epoch 10/100\n",
      "100436/100436 [==============================] - 7s - loss: 1800.1520 - mean_pred_metrics: 1800.1520 - val_loss: 1460.6583 - val_mean_pred_metrics: 1460.6583\n",
      "Epoch 11/100\n",
      "100436/100436 [==============================] - 7s - loss: 1759.4222 - mean_pred_metrics: 1759.4222 - val_loss: 1443.7795 - val_mean_pred_metrics: 1443.7795\n",
      "Epoch 12/100\n",
      "100436/100436 [==============================] - 7s - loss: 1727.9528 - mean_pred_metrics: 1727.9528 - val_loss: 1470.5793 - val_mean_pred_metrics: 1470.5793\n",
      "Epoch 13/100\n",
      "100436/100436 [==============================] - 7s - loss: 1694.7601 - mean_pred_metrics: 1694.7601 - val_loss: 1321.6277 - val_mean_pred_metrics: 1321.6277\n",
      "Epoch 14/100\n",
      "100436/100436 [==============================] - 7s - loss: 1677.6900 - mean_pred_metrics: 1677.6900 - val_loss: 1407.0700 - val_mean_pred_metrics: 1407.0700\n",
      "Epoch 15/100\n",
      "100436/100436 [==============================] - 7s - loss: 1642.4341 - mean_pred_metrics: 1642.4341 - val_loss: 1352.5068 - val_mean_pred_metrics: 1352.5068\n",
      "Epoch 16/100\n",
      "100436/100436 [==============================] - 7s - loss: 1626.6786 - mean_pred_metrics: 1626.6786 - val_loss: 1314.4664 - val_mean_pred_metrics: 1314.4664\n",
      "Epoch 17/100\n",
      "100436/100436 [==============================] - 7s - loss: 1593.4556 - mean_pred_metrics: 1593.4556 - val_loss: 1244.4776 - val_mean_pred_metrics: 1244.4776\n",
      "Epoch 18/100\n",
      "100436/100436 [==============================] - 7s - loss: 1575.8056 - mean_pred_metrics: 1575.8056 - val_loss: 1372.9465 - val_mean_pred_metrics: 1372.9465\n",
      "Epoch 19/100\n",
      "100436/100436 [==============================] - 7s - loss: 1553.7421 - mean_pred_metrics: 1553.7421 - val_loss: 1278.4182 - val_mean_pred_metrics: 1278.4182\n",
      "Epoch 20/100\n",
      "100436/100436 [==============================] - 7s - loss: 1526.3857 - mean_pred_metrics: 1526.3857 - val_loss: 1282.1802 - val_mean_pred_metrics: 1282.1802\n",
      "Epoch 21/100\n",
      "100436/100436 [==============================] - 7s - loss: 1501.2586 - mean_pred_metrics: 1501.2586 - val_loss: 1250.5146 - val_mean_pred_metrics: 1250.5146\n",
      "Epoch 22/100\n",
      "100436/100436 [==============================] - 7s - loss: 1482.8639 - mean_pred_metrics: 1482.8639 - val_loss: 1202.8865 - val_mean_pred_metrics: 1202.8865\n",
      "Epoch 23/100\n",
      "100436/100436 [==============================] - 7s - loss: 1459.8491 - mean_pred_metrics: 1459.8491 - val_loss: 1183.0911 - val_mean_pred_metrics: 1183.0911\n",
      "Epoch 24/100\n",
      "100436/100436 [==============================] - 7s - loss: 1442.0085 - mean_pred_metrics: 1442.0085 - val_loss: 1216.7193 - val_mean_pred_metrics: 1216.7193\n",
      "Epoch 25/100\n",
      "100436/100436 [==============================] - 7s - loss: 1415.5680 - mean_pred_metrics: 1415.5680 - val_loss: 1220.7145 - val_mean_pred_metrics: 1220.7145\n",
      "Epoch 26/100\n",
      "100436/100436 [==============================] - 7s - loss: 1402.0632 - mean_pred_metrics: 1402.0632 - val_loss: 1207.2496 - val_mean_pred_metrics: 1207.2496\n",
      "Epoch 27/100\n",
      "100436/100436 [==============================] - 7s - loss: 1378.3878 - mean_pred_metrics: 1378.3878 - val_loss: 1163.7796 - val_mean_pred_metrics: 1163.7796\n",
      "Epoch 28/100\n",
      "100436/100436 [==============================] - 7s - loss: 1363.3142 - mean_pred_metrics: 1363.3142 - val_loss: 1190.0052 - val_mean_pred_metrics: 1190.0052\n",
      "Epoch 29/100\n",
      "100436/100436 [==============================] - 7s - loss: 1337.9867 - mean_pred_metrics: 1337.9867 - val_loss: 1153.0151 - val_mean_pred_metrics: 1153.0151\n",
      "Epoch 30/100\n",
      "100436/100436 [==============================] - 7s - loss: 1326.5103 - mean_pred_metrics: 1326.5103 - val_loss: 1179.0950 - val_mean_pred_metrics: 1179.0950\n",
      "Epoch 31/100\n",
      "100436/100436 [==============================] - 7s - loss: 1308.7931 - mean_pred_metrics: 1308.7931 - val_loss: 1181.0552 - val_mean_pred_metrics: 1181.0552\n",
      "Epoch 32/100\n",
      "100436/100436 [==============================] - 7s - loss: 1292.1094 - mean_pred_metrics: 1292.1094 - val_loss: 1177.7163 - val_mean_pred_metrics: 1177.7163\n",
      "Epoch 33/100\n",
      "100436/100436 [==============================] - 7s - loss: 1278.1987 - mean_pred_metrics: 1278.1987 - val_loss: 1145.6265 - val_mean_pred_metrics: 1145.6265\n",
      "Epoch 34/100\n",
      "100436/100436 [==============================] - 7s - loss: 1261.9277 - mean_pred_metrics: 1261.9277 - val_loss: 1152.3613 - val_mean_pred_metrics: 1152.3613\n",
      "Epoch 35/100\n",
      "100436/100436 [==============================] - 7s - loss: 1248.8796 - mean_pred_metrics: 1248.8796 - val_loss: 1148.4832 - val_mean_pred_metrics: 1148.4832\n",
      "Epoch 36/100\n",
      "100436/100436 [==============================] - 7s - loss: 1233.6191 - mean_pred_metrics: 1233.6191 - val_loss: 1139.7905 - val_mean_pred_metrics: 1139.7905\n",
      "Epoch 37/100\n",
      "100436/100436 [==============================] - 7s - loss: 1227.4770 - mean_pred_metrics: 1227.4770 - val_loss: 1138.7469 - val_mean_pred_metrics: 1138.7469\n",
      "Epoch 38/100\n",
      "100436/100436 [==============================] - 7s - loss: 1219.2977 - mean_pred_metrics: 1219.2977 - val_loss: 1158.2665 - val_mean_pred_metrics: 1158.2665\n",
      "Epoch 39/100\n",
      "100436/100436 [==============================] - 6s - loss: 1202.2825 - mean_pred_metrics: 1202.2825 - val_loss: 1138.0802 - val_mean_pred_metrics: 1138.0802\n",
      "Epoch 40/100\n",
      "100436/100436 [==============================] - 6s - loss: 1196.8004 - mean_pred_metrics: 1196.8004 - val_loss: 1184.1114 - val_mean_pred_metrics: 1184.1114\n",
      "Epoch 41/100\n",
      "100436/100436 [==============================] - 6s - loss: 1185.2667 - mean_pred_metrics: 1185.2667 - val_loss: 1138.8475 - val_mean_pred_metrics: 1138.8475\n",
      "Epoch 42/100\n",
      "100436/100436 [==============================] - 6s - loss: 1181.0093 - mean_pred_metrics: 1181.0093 - val_loss: 1144.4251 - val_mean_pred_metrics: 1144.4251\n",
      "Epoch 43/100\n",
      "100436/100436 [==============================] - 6s - loss: 1168.9901 - mean_pred_metrics: 1168.9901 - val_loss: 1142.4293 - val_mean_pred_metrics: 1142.4293\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100436/100436 [==============================] - 6s - loss: 1162.7145 - mean_pred_metrics: 1162.7145 - val_loss: 1141.0320 - val_mean_pred_metrics: 1141.0320\n",
      "Epoch 45/100\n",
      "100436/100436 [==============================] - 6s - loss: 1152.8343 - mean_pred_metrics: 1152.8343 - val_loss: 1141.9597 - val_mean_pred_metrics: 1141.9597\n",
      "Epoch 46/100\n",
      "100436/100436 [==============================] - 6s - loss: 1146.4018 - mean_pred_metrics: 1146.4018 - val_loss: 1143.4258 - val_mean_pred_metrics: 1143.4258\n",
      "Epoch 47/100\n",
      "100436/100436 [==============================] - 6s - loss: 1135.1554 - mean_pred_metrics: 1135.1554 - val_loss: 1146.0390 - val_mean_pred_metrics: 1146.0390\n",
      "Epoch 48/100\n",
      "100436/100436 [==============================] - 6s - loss: 1133.1676 - mean_pred_metrics: 1133.1676 - val_loss: 1142.4095 - val_mean_pred_metrics: 1142.4095\n",
      "Epoch 49/100\n",
      "100436/100436 [==============================] - 6s - loss: 1127.3076 - mean_pred_metrics: 1127.3076 - val_loss: 1147.7889 - val_mean_pred_metrics: 1147.7889\n",
      "Epoch 50/100\n",
      "100436/100436 [==============================] - 6s - loss: 1120.7744 - mean_pred_metrics: 1120.7744 - val_loss: 1146.1406 - val_mean_pred_metrics: 1146.1406\n",
      "Fold 1, MAE: 0.3765862143452659\n",
      "Train on 100436 samples, validate on 25110 samples\n",
      "Epoch 1/100\n",
      "100436/100436 [==============================] - 8s - loss: 2902.3228 - mean_pred_metrics: 2902.3228 - val_loss: 2223.8122 - val_mean_pred_metrics: 2223.8122\n",
      "Epoch 2/100\n",
      "100436/100436 [==============================] - 6s - loss: 2123.5234 - mean_pred_metrics: 2123.5234 - val_loss: 1690.4882 - val_mean_pred_metrics: 1690.4882\n",
      "Epoch 3/100\n",
      "100436/100436 [==============================] - 6s - loss: 1984.2888 - mean_pred_metrics: 1984.2888 - val_loss: 1609.6049 - val_mean_pred_metrics: 1609.6049\n",
      "Epoch 4/100\n",
      "100436/100436 [==============================] - 6s - loss: 1920.0652 - mean_pred_metrics: 1920.0652 - val_loss: 1534.6062 - val_mean_pred_metrics: 1534.6062\n",
      "Epoch 5/100\n",
      "100436/100436 [==============================] - 6s - loss: 1874.8589 - mean_pred_metrics: 1874.8589 - val_loss: 1503.4772 - val_mean_pred_metrics: 1503.4772\n",
      "Epoch 6/100\n",
      "100436/100436 [==============================] - 6s - loss: 1821.5298 - mean_pred_metrics: 1821.5298 - val_loss: 1540.9977 - val_mean_pred_metrics: 1540.9977\n",
      "Epoch 7/100\n",
      "100436/100436 [==============================] - 6s - loss: 1775.2193 - mean_pred_metrics: 1775.2193 - val_loss: 1451.8208 - val_mean_pred_metrics: 1451.8208\n",
      "Epoch 8/100\n",
      "100436/100436 [==============================] - 6s - loss: 1734.7795 - mean_pred_metrics: 1734.7795 - val_loss: 1500.2708 - val_mean_pred_metrics: 1500.2708\n",
      "Epoch 9/100\n",
      "100436/100436 [==============================] - 6s - loss: 1696.9892 - mean_pred_metrics: 1696.9892 - val_loss: 1360.2473 - val_mean_pred_metrics: 1360.2473\n",
      "Epoch 10/100\n",
      "100436/100436 [==============================] - 6s - loss: 1672.8470 - mean_pred_metrics: 1672.8470 - val_loss: 1370.4835 - val_mean_pred_metrics: 1370.4835\n",
      "Epoch 11/100\n",
      "100436/100436 [==============================] - 6s - loss: 1634.1106 - mean_pred_metrics: 1634.1106 - val_loss: 1294.5571 - val_mean_pred_metrics: 1294.5571\n",
      "Epoch 12/100\n",
      "100436/100436 [==============================] - 6s - loss: 1610.7867 - mean_pred_metrics: 1610.7867 - val_loss: 1289.7414 - val_mean_pred_metrics: 1289.7414\n",
      "Epoch 13/100\n",
      "100436/100436 [==============================] - 6s - loss: 1571.0746 - mean_pred_metrics: 1571.0746 - val_loss: 1253.1364 - val_mean_pred_metrics: 1253.1364\n",
      "Epoch 14/100\n",
      "100436/100436 [==============================] - 6s - loss: 1553.3554 - mean_pred_metrics: 1553.3554 - val_loss: 1226.0576 - val_mean_pred_metrics: 1226.0576\n",
      "Epoch 15/100\n",
      "100436/100436 [==============================] - 6s - loss: 1518.7110 - mean_pred_metrics: 1518.7110 - val_loss: 1283.9163 - val_mean_pred_metrics: 1283.9163\n",
      "Epoch 16/100\n",
      "100436/100436 [==============================] - 6s - loss: 1491.9825 - mean_pred_metrics: 1491.9825 - val_loss: 1239.3411 - val_mean_pred_metrics: 1239.3411\n",
      "Epoch 17/100\n",
      "100436/100436 [==============================] - 6s - loss: 1474.0383 - mean_pred_metrics: 1474.0383 - val_loss: 1240.7251 - val_mean_pred_metrics: 1240.7251\n",
      "Epoch 18/100\n",
      "100436/100436 [==============================] - 6s - loss: 1449.5413 - mean_pred_metrics: 1449.5413 - val_loss: 1211.4488 - val_mean_pred_metrics: 1211.4488\n",
      "Epoch 19/100\n",
      "100436/100436 [==============================] - 6s - loss: 1419.8147 - mean_pred_metrics: 1419.8147 - val_loss: 1200.8089 - val_mean_pred_metrics: 1200.8089\n",
      "Epoch 20/100\n",
      "100436/100436 [==============================] - 6s - loss: 1396.4460 - mean_pred_metrics: 1396.4460 - val_loss: 1170.8017 - val_mean_pred_metrics: 1170.8017\n",
      "Epoch 21/100\n",
      "100436/100436 [==============================] - 6s - loss: 1381.7543 - mean_pred_metrics: 1381.7543 - val_loss: 1170.4527 - val_mean_pred_metrics: 1170.4527\n",
      "Epoch 22/100\n",
      "100436/100436 [==============================] - 6s - loss: 1363.4591 - mean_pred_metrics: 1363.4591 - val_loss: 1210.8599 - val_mean_pred_metrics: 1210.8599\n",
      "Epoch 23/100\n",
      "100436/100436 [==============================] - 6s - loss: 1348.5135 - mean_pred_metrics: 1348.5135 - val_loss: 1201.4748 - val_mean_pred_metrics: 1201.4748\n",
      "Epoch 24/100\n",
      "100436/100436 [==============================] - 6s - loss: 1329.7250 - mean_pred_metrics: 1329.7250 - val_loss: 1169.6318 - val_mean_pred_metrics: 1169.6318\n",
      "Epoch 25/100\n",
      "100436/100436 [==============================] - 6s - loss: 1316.4640 - mean_pred_metrics: 1316.4640 - val_loss: 1261.7528 - val_mean_pred_metrics: 1261.7528\n",
      "Epoch 26/100\n",
      "100436/100436 [==============================] - 6s - loss: 1300.0172 - mean_pred_metrics: 1300.0172 - val_loss: 1173.3877 - val_mean_pred_metrics: 1173.3877\n",
      "Epoch 27/100\n",
      "100436/100436 [==============================] - 6s - loss: 1282.5220 - mean_pred_metrics: 1282.5220 - val_loss: 1198.0617 - val_mean_pred_metrics: 1198.0617\n",
      "Epoch 28/100\n",
      "100436/100436 [==============================] - 6s - loss: 1273.4313 - mean_pred_metrics: 1273.4313 - val_loss: 1155.0296 - val_mean_pred_metrics: 1155.0296\n",
      "Epoch 29/100\n",
      "100436/100436 [==============================] - 6s - loss: 1265.3906 - mean_pred_metrics: 1265.3906 - val_loss: 1156.8373 - val_mean_pred_metrics: 1156.8373\n",
      "Epoch 30/100\n",
      "100436/100436 [==============================] - 6s - loss: 1253.2444 - mean_pred_metrics: 1253.2444 - val_loss: 1164.3546 - val_mean_pred_metrics: 1164.3546\n",
      "Epoch 31/100\n",
      "100436/100436 [==============================] - 6s - loss: 1242.3700 - mean_pred_metrics: 1242.3700 - val_loss: 1151.3072 - val_mean_pred_metrics: 1151.3072\n",
      "Epoch 32/100\n",
      "100436/100436 [==============================] - 6s - loss: 1227.3591 - mean_pred_metrics: 1227.3591 - val_loss: 1147.7174 - val_mean_pred_metrics: 1147.7174\n",
      "Epoch 33/100\n",
      "100436/100436 [==============================] - 7s - loss: 1218.2284 - mean_pred_metrics: 1218.2284 - val_loss: 1160.6936 - val_mean_pred_metrics: 1160.6936\n",
      "Epoch 34/100\n",
      "100436/100436 [==============================] - 6s - loss: 1202.8821 - mean_pred_metrics: 1202.8821 - val_loss: 1148.7022 - val_mean_pred_metrics: 1148.7022\n",
      "Epoch 35/100\n",
      "100436/100436 [==============================] - 6s - loss: 1198.5602 - mean_pred_metrics: 1198.5602 - val_loss: 1151.3442 - val_mean_pred_metrics: 1151.3442\n",
      "Epoch 36/100\n",
      "100436/100436 [==============================] - 6s - loss: 1186.5893 - mean_pred_metrics: 1186.5893 - val_loss: 1155.5804 - val_mean_pred_metrics: 1155.5804\n",
      "Epoch 37/100\n",
      "100436/100436 [==============================] - 6s - loss: 1178.7782 - mean_pred_metrics: 1178.7782 - val_loss: 1149.8229 - val_mean_pred_metrics: 1149.8229\n",
      "Epoch 38/100\n",
      "100436/100436 [==============================] - 6s - loss: 1173.4765 - mean_pred_metrics: 1173.4765 - val_loss: 1148.5505 - val_mean_pred_metrics: 1148.5505\n",
      "Epoch 39/100\n",
      "100436/100436 [==============================] - 6s - loss: 1166.1170 - mean_pred_metrics: 1166.1170 - val_loss: 1151.5271 - val_mean_pred_metrics: 1151.5271\n",
      "Epoch 40/100\n",
      "100436/100436 [==============================] - 6s - loss: 1156.3728 - mean_pred_metrics: 1156.3728 - val_loss: 1156.4786 - val_mean_pred_metrics: 1156.4786\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100436/100436 [==============================] - 6s - loss: 1148.9452 - mean_pred_metrics: 1148.9452 - val_loss: 1152.0684 - val_mean_pred_metrics: 1152.0684\n",
      "Epoch 42/100\n",
      "100436/100436 [==============================] - 6s - loss: 1149.1742 - mean_pred_metrics: 1149.1742 - val_loss: 1152.5814 - val_mean_pred_metrics: 1152.5814\n",
      "Epoch 43/100\n",
      "100436/100436 [==============================] - 6s - loss: 1140.7909 - mean_pred_metrics: 1140.7909 - val_loss: 1159.4557 - val_mean_pred_metrics: 1159.4557\n",
      "Fold 2, MAE: 0.37785441310995893\n",
      "3-fold CV score: 0.3770100302582653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('CV score for the final model:', 0.37701003025826529)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score = cross_validate_mlp(hyper_model)\n",
    "(\"CV score for the final model:\", cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22, 37], [10, 16], [25, 26], [39, 16], [45], [29], [8, 26], [6, 10], [8, 16], [47, 25, 37, 36]]\n",
      "[[22 37  0  0]\n",
      " [10 16  0  0]\n",
      " [25 26  0  0]\n",
      " [39 16  0  0]\n",
      " [45  0  0  0]\n",
      " [29  0  0  0]\n",
      " [ 8 26  0  0]\n",
      " [ 6 10  0  0]\n",
      " [ 8 16  0  0]\n",
      " [47 25 37 36]]\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_3 (Embedding)          (None, 4, 8)          400         embedding_input_3[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 32)            0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_135 (Dense)                (None, 1)             33          flatten_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Accuracy: 89.999998\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "# define documents\n",
    "docs = ['Well done!',\n",
    "\t\t'Good work',\n",
    "\t\t'Great effort',\n",
    "\t\t'nice work',\n",
    "\t\t'Excellent!',\n",
    "\t\t'Weak',\n",
    "\t\t'Poor effort!',\n",
    "\t\t'not good',\n",
    "\t\t'poor work',\n",
    "\t\t'Could have done better.']\n",
    "# define class labels\n",
    "labels = [1,1,1,1,1,0,0,0,0,0]\n",
    "# integer encode the documents\n",
    "vocab_size = 50\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "print(encoded_docs)\n",
    "# pad documents to a max length of 4 words\n",
    "max_length = 4\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
    "print(padded_docs)\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "# fit the model\n",
    "model.fit(padded_docs, labels, nb_epoch=100, verbose=0)\n",
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though this model is not adapted for mere 30 epochs of training, nor for 3-fold CV (I used 5-fold on Kaggle), even though this is a single unbagged model which has been cross-validated on three folds only, we see a very good score:\n",
    "`CV = 1150` (your score may vary a little).\n",
    "\n",
    "By the way, this single model, bagged, 5-fold CVed, scored 1116.28 on Kaggle LB.\n",
    "\n",
    "As we see, this model is considerably better than any other models we had so far. We now take it as the second part of our final ensemble."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

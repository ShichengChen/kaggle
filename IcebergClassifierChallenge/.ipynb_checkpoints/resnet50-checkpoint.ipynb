{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/home/coder.chenshicheng/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: cttsai\n",
    "To extract features by ResNet50 then can be further trained by XGBoost or others\n",
    "original idea forked and refactored from\n",
    "https://www.kaggle.com/kelexu/pretrained-resnet-feature-xgb\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "from tqdm import tqdm\n",
    "#\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import datetime as dt\n",
    "#import for image processing\n",
    "import cv2\n",
    "from keras.applications import ResNet50\n",
    "#evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_jason(file, loc=''):\n",
    "\n",
    "    df = pd.read_json('{}{}'.format(loc, file))\n",
    "    #df = df[:100]\n",
    "    df['inc_angle'] = df['inc_angle'].replace('na', -1).astype(float)\n",
    "    #print(df['inc_angle'].value_counts())\n",
    "    \n",
    "    band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_1\"]])\n",
    "    band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in df[\"band_2\"]])\n",
    "    df = df.drop(['band_1', 'band_2'], axis=1)\n",
    "    \n",
    "    bands = np.stack((band1, band2,  0.5 * (band1 + band2)), axis=-1)\n",
    "    del band1, band2\n",
    "    \n",
    "    return df, bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(df, bands, output='tmp'):\n",
    "\n",
    "    w, h = 197, 197\n",
    "    model = ResNet50(include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_shape=(h, w, 3),\n",
    "                     pooling='avg') # or 'max' min= 139\n",
    "                  \n",
    "    bands = 0.5 + bands / 100.            \n",
    "    X = []\n",
    "    \n",
    "    for i in tqdm(bands, miniters=100):\n",
    "        \n",
    "        x = cv2.resize(i, (w, h)).astype(np.float32)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        \n",
    "        preds = model.predict(x, verbose=2)\n",
    "        features_reduce = preds.squeeze()\n",
    "        X.append(features_reduce)\n",
    "    \n",
    "    X = np.array(X)\n",
    "\n",
    "    feats = ['f{:04d}'.format(f+1) for f in range(X.shape[1])]\n",
    "    transResNet = pd.DataFrame(X, columns=feats)\n",
    "    transResNet['id'] = df['id'].values\n",
    "    transResNet.to_csv('{}ResNet.csv'.format(output), index=False)\n",
    "    \n",
    "    X = np.concatenate([X, df['inc_angle'].values[:, np.newaxis]], axis=-1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1017)\n",
    "target = 'is_iceberg'\n",
    "\n",
    "#Load data\n",
    "train, train_bands = read_jason(file='train.json', loc='../input/')\n",
    "test, test_bands = read_jason(file='test.json', loc='../input/')\n",
    "\n",
    "train_X = process(df=train, bands=train_bands, output='train')\n",
    "train_y = train[target].values\n",
    "\n",
    "test_X = process(df=test, bands=test_bands, output='test')\n",
    "\n",
    "#training\n",
    "print('evaluating performance...')\n",
    "split_seed = 25\n",
    "\n",
    "tmp = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M\")    \n",
    "x1, x2, y1, y2 = train_test_split(train_X, train_y, test_size=0.1, random_state=split_seed)\n",
    "print('splitted: {0}, {1}'.format(x1.shape, x2.shape), flush=True)\n",
    "\n",
    "#XGB\n",
    "watchlist = [(xgb.DMatrix(x1, y1), 'train'), (xgb.DMatrix(x2, y2), 'valid')]\n",
    "params = {'eta': 0.02, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, 'objective': 'binary:logistic', 'seed': 99, 'silent': True}\n",
    "params['eta'] = 0.05\n",
    "params['max_depth'] = 4\n",
    "params['subsample'] = 0.9\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['colsample_bytree'] = 0.7\n",
    "params['colsample_bylevel'] = 0.7\n",
    "params['max_delta_step'] = 1\n",
    "#params['gamma'] = 1\n",
    "#params['labmda'] = 1\n",
    "params['scale_pos_weight'] = 1.0\n",
    "params['seed'] = split_seed + 1\n",
    "nr_round = 2000\n",
    "min_round = 100\n",
    "\n",
    "model1 = xgb.train(params, \n",
    "                   xgb.DMatrix(x1, y1), \n",
    "                   nr_round,  \n",
    "                   watchlist, \n",
    "                   verbose_eval=50, \n",
    "                   early_stopping_rounds=min_round)\n",
    "\n",
    "pred_xgb = model1.predict(xgb.DMatrix(test_X), ntree_limit=model1.best_ntree_limit+45)\n",
    "\n",
    "#\n",
    "subm = pd.DataFrame({'id': test['id'].values, target: pred_xgb})\n",
    "file = 'subm_{}_xgb.csv'.format(tmp)\n",
    "subm.to_csv(file, index=False, float_format='%.6f')\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
